{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# from models import Model\n",
    "from models import save_model\n",
    "from dataset import get_dataset, get_dataloader\n",
    "from metrics import recall,mean_rank, mean_reciprocal_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " @Date  : \n",
    " @Author: liuyouyuan\n",
    " @mail  : liuyouyuan@lizhi.fm\n",
    "'''\n",
    "'''\n",
    "定义模型主体结构\n",
    "'''\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"gpu\")\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, n_head, dropout, n_block):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([TextBlock(d_model, d_ff, n_head, dropout) for _ in range(n_block)])\n",
    "        self.norm = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class CommentDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, n_head, dropout, n_block):\n",
    "        super(CommentDecoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([DecoderBlock(d_model, d_ff, n_head, dropout) for _ in range(n_block)])\n",
    "        self.norm = LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, m, mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, m, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class TextBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, n_head, dropout):\n",
    "        super(TextBlock, self).__init__()\n",
    "        self.self_attn = MultiHeadedAttention(n_head, d_model)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.sublayer = nn.ModuleList([SublayerConnection(d_model, dropout) for _ in range(2)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x))\n",
    "        return self.sublayer[1](x, self.feed_forward)\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, d_ff, n_head, dropout):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.self_attn = MultiHeadedAttention(n_head, d_model)\n",
    "        self.text_attn = MultiHeadedAttention(n_head, d_model)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.sublayer = nn.ModuleList([SublayerConnection(d_model, dropout) for _ in range(3)])\n",
    "\n",
    "    def forward(self, x, m, mask):\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.text_attn(x, m, m))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(4)])\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def attention(self, query, key, value, mask=None, dropout=None):\n",
    "        \"Compute 'Scaled Dot Product Attention'\"\n",
    "        d_k = query.size(-1)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        p_attn = F.softmax(scores, dim=-1)\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = self.attention(query, key, value, mask=mask,\n",
    "                                 dropout=self.dropout)\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "\n",
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x)\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)],requires_grad=False).cuda()\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class PositionalEmb(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEmb, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        self.pe = torch.nn.Embedding(max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe(Variable(torch.range(1,x.size(1))).long().cuda()).unsqueeze(0)\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "\n",
    "\n",
    "def subsequent_mask(batch, size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (batch, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_emb, n_hidden, vocab_size, dropout, d_ff, n_head, n_block):\n",
    "        super(Model, self).__init__()\n",
    "        self.n_emb = n_emb\n",
    "        self.n_hidden = n_hidden\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Sequential(Embeddings(n_hidden, vocab_size), PositionalEncoding(n_hidden, dropout))\n",
    "        self.text_encoder = TextEncoder(n_hidden, d_ff, n_head, dropout, n_block)\n",
    "        self.comment_decoder = CommentDecoder(n_hidden, d_ff, n_head, dropout, n_block)\n",
    "        self.output_layer = nn.Linear(self.n_hidden, self.vocab_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduce=False, size_average=False, ignore_index=0)\n",
    "\n",
    "    def encode_text(self, T):\n",
    "        x = self.embedding(T)\n",
    "        out = self.text_encoder(x)\n",
    "        return out\n",
    "\n",
    "    def decode(self, Y, T, mask):\n",
    "        embs = self.embedding(Y)\n",
    "        out = self.comment_decoder(embs, T, mask)\n",
    "        out = self.output_layer(out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, Y, T):\n",
    "        enc_text = self.encode_text(T)\n",
    "        print(\"encode text:\", enc_text)\n",
    "        print(enc_text.size())\n",
    "        mask = Variable(subsequent_mask(Y.size(0), Y.size(1)-1), requires_grad=False).cuda()\n",
    "        print(\"mask:\", mask, mask.size())\n",
    "        print(Y.size(0), Y.size(1)-1)\n",
    "        outs = self.decode(Y[:,:-1], enc_text, mask)\n",
    "        print(\"outs:\", outs, outs.size())\n",
    "        Y = Y.t()\n",
    "        print(\"Y.t()\", Y)\n",
    "        print(Y.size())\n",
    "        print(\"-\"*20)\n",
    "        outs = outs.transpose(0, 1)\n",
    "        print(\"outs.tr\", outs)\n",
    "        print(outs.size())\n",
    "        print(\"-\"*20)\n",
    "        print(\"OSIZE:\", outs.contiguous().view(-1, self.vocab_size).size())\n",
    "        print(\"YSIZE:\", Y[1:].contiguous().view(-1).size())\n",
    "        loss = self.criterion(outs.contiguous().view(-1, self.vocab_size),\n",
    "                              Y[1:].contiguous().view(-1))\n",
    "        print(\"Loss:\", loss, loss.size())\n",
    "        return torch.mean(loss)\n",
    "\n",
    "    def ranking(self, Y, T):\n",
    "        nums = len(Y)\n",
    "        out_text = self.encode_text(T.unsqueeze(0))\n",
    "        out_text = out_text.repeat(nums, 1, 1)\n",
    "\n",
    "        mask = Variable(subsequent_mask(Y.size(0), Y.size(1) - 1), requires_grad=False).cuda()\n",
    "        outs = self.decode(Y[:, :-1], out_text, mask)\n",
    "\n",
    "        Y = Y.t()\n",
    "        outs = outs.transpose(0, 1)\n",
    "\n",
    "        loss = self.criterion(outs.contiguous().view(-1, self.vocab_size),\n",
    "                              Y[1:].contiguous().view(-1))\n",
    "\n",
    "        loss = loss.view(-1, nums).sum(0)\n",
    "        return torch.sort(loss, dim=0, descending=True)[1]\n",
    "\n",
    "\n",
    "def save_model(path, model):\n",
    "    model_state_dict = model.state_dict()\n",
    "    torch.save(model_state_dict, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parser():\n",
    "    parser = argparse.ArgumentParser(description='train.py')\n",
    "\n",
    "    parser.add_argument('--n_emb', type=int, default=512, help=\"Embedding size\")\n",
    "    parser.add_argument('--n_hidden', type=int, default=512, help=\"Hidden size\")\n",
    "    parser.add_argument('--d_ff', type=int, default=2048, help=\"Hidden size of Feedforward\")\n",
    "    parser.add_argument('--n_head', type=int, default=8, help=\"Number of head\")\n",
    "    parser.add_argument('--n_block', type=int, default=6, help=\"Number of block\")\n",
    "    parser.add_argument('--batch_size', type=int, default=64, help=\"Batch size\")\n",
    "    parser.add_argument('--vocab_size', type=int, default=30000, help=\"Vocabulary size\")\n",
    "    parser.add_argument('--epoch', type=int, default=50, help=\"Number of epoch\")\n",
    "    parser.add_argument('--report', type=int, default=500, help=\"Number of report interval\")\n",
    "    parser.add_argument('--lr', type=float, default=3e-4, help=\"Learning rate\")\n",
    "    parser.add_argument('--dropout', type=float, default=0.1, help=\"Dropout rate\")\n",
    "    parser.add_argument('--restore', type=str, default='', help=\"Restoring model path\")\n",
    "    parser.add_argument('--mode', type=str, default='train', help=\"Train or test\")\n",
    "    parser.add_argument('--dir', type=str, default='ckpt', help=\"Checkpoint directory\")\n",
    "    parser.add_argument('--max_len', type=int, default=20, help=\"Limited length for text\")\n",
    "    parser.add_argument('--n_com', type=int, default=5, help=\"Number of input comments\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "class Args(object):\n",
    "    def __init__(self, mode=\"train\"):\n",
    "        self.n_emb = 512\n",
    "        self.n_hidden = 512\n",
    "        self.d_ff = 2048\n",
    "        self.n_head = 8\n",
    "        self.n_block = 6\n",
    "        self.batch_size = 64\n",
    "        self.vocab_size = 30000\n",
    "        self.epoch = 50\n",
    "        self.report = 500\n",
    "        self.lr = 3e-4\n",
    "        self.dropout = 0.1\n",
    "        self.restore = ''\n",
    "        self.mode = mode\n",
    "        self.dir = \"./test_dir\"\n",
    "        self.max_len = 20\n",
    "        self.n_com = 5\n",
    "\n",
    "class Config(object):\n",
    "\n",
    "    def __init__(self, args, data_path=\"data\"):\n",
    "        self.args = args\n",
    "        self.data_path = data_path\n",
    "        self.train_path = os.path.join(data_path, \"train-context.json\")\n",
    "        self.dev_path = os.path.join(data_path, \"dev-candidate.json\")\n",
    "        self.test_path = os.path.join(data_path, \"test-candidate.json\")\n",
    "        self.vocab_path = os.path.join(data_path, \"dicts-30000.json\")\n",
    "        self.w2i_vocabs = json.load(open(self.vocab_path, \n",
    "                                        'r', encoding='utf8'))['word2id']\n",
    "        self.i2v_vocabs = json.load(open(self.vocab_path, \n",
    "                                        'r', encoding='utf8'))['id2word']\n",
    "        self.args.vocab_size = len(self.w2i_vocabs)\n",
    "        if not os.path.exists(self.args.dir):\n",
    "            os.mkdir(self.args.dir)\n",
    "\n",
    "def train(config):\n",
    "    # train_path:train-context.json\n",
    "    args = config.args\n",
    "    train_set = get_dataset(config.train_path, config.w2i_vocabs, config, is_train=True)\n",
    "    dev_set = get_dataset(config.dev_path, config.w2i_vocabs, config, is_train=False)\n",
    "    # X:img,torch.stack;\n",
    "    train_batch = get_dataloader(train_set, args.batch_size, is_train=True)\n",
    "    model = Model(n_emb=args.n_emb, n_hidden=args.n_hidden, vocab_size=args.vocab_size,\n",
    "                  dropout=args.dropout, d_ff=args.d_ff, n_head=args.n_head, n_block=args.n_block)\n",
    "    if args.restore != '':\n",
    "        model_dict = torch.load(args.restore)\n",
    "        model.load_state_dict(model_dict)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad,model.parameters()), lr=args.lr)\n",
    "    best_score = -1000000\n",
    "\n",
    "    for i in range(args.epoch):\n",
    "        model.train()\n",
    "        report_loss, start_time, n_samples = 0, time.time(), 0\n",
    "        count, total = 0, len(train_set) // args.batch_size + 1\n",
    "        n = 0\n",
    "        for batch in train_batch:\n",
    "            Y, T = batch\n",
    "            print(\"-------Y:\", Y)\n",
    "            print(\"Y[63]:\", Y[63])\n",
    "            print(\"-------T:\", T)\n",
    "            print(\"T[63]:\", T[63])\n",
    "            Y = Y.to(device)\n",
    "            T = T.to(device)\n",
    "            print(\"Y size:\", Y.size())\n",
    "            print(\"T size:\", T.size())\n",
    "            optimizer.zero_grad()\n",
    "            loss = model(Y, T)\n",
    "            print(\"-----loss:\", loss)\n",
    "            print(\"*\"*30)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            report_loss += loss.item()\n",
    "            #break\n",
    "            n_samples += len(Y.data)\n",
    "            print(\"n_samples:\", n_samples)\n",
    "            n += 1\n",
    "            if n ==10:\n",
    "                break\n",
    "            count += 1\n",
    "            if count % args.report == 0 or count == total:\n",
    "                print('%d/%d, epoch: %d, report_loss: %.3f, time: %.2f'\n",
    "                      % (count, total, i+1, report_loss / n_samples, time.time() - start_time))\n",
    "                score = eval(model, dev_set, args.batch_size)\n",
    "                model.train()\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    save_model(os.path.join(args.dir, 'best_checkpoint.pt'), model)\n",
    "                else:\n",
    "                    save_model(os.path.join(args.dir, 'checkpoint.pt'), model)\n",
    "                report_loss, start_time, n_samples = 0, time.time(), 0\n",
    "        if i == 0:\n",
    "            break\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def eval(model, dev_set, batch_size):\n",
    "    print(\"starting evaluating...\")\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    # predictions, references = [], []\n",
    "    dev_batch = get_dataloader(dev_set, batch_size, is_train=False)\n",
    "\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dev_batch:\n",
    "            Y, T = batch\n",
    "            Y = Y.to(device)\n",
    "            T = T.to(device)\n",
    "            loss += model(Y, T).item()\n",
    "    print(loss)\n",
    "    print(\"evaluting time:\", time.time() - start_time)\n",
    "\n",
    "    return -loss\n",
    "\n",
    "\n",
    "def test(test_set, model):\n",
    "    print(\"starting testing...\")\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    predictions, references = [], []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_set)):\n",
    "            Y, T, data = test_set.get_candidate(i)\n",
    "            print(\"-------Y:\", Y)\n",
    "            print(\"Y[10]:\", Y[10])\n",
    "            print(\"-------T:\", T)\n",
    "            print(\"T[10]:\", T[10])\n",
    "            print(\"data:\", data)\n",
    "            print(\"*\"*40)\n",
    "            Y = Y.to(device)\n",
    "            T = T.to(device)\n",
    "            ids = model.ranking(Y, T).data\n",
    "            print(\"ids:\", ids)\n",
    "            print(\"ids size\", ids.size())\n",
    "\n",
    "            candidate = []\n",
    "            comments = list(data['candidate'].keys())\n",
    "            print(\"comments:\", comments)\n",
    "            for id in ids:\n",
    "                print(\"comments[id]:\", comments[id])\n",
    "                candidate.append(comments[id])\n",
    "            predictions.append(candidate)\n",
    "            print(\"prediction candidate:\", candidate)\n",
    "            references.append(data['candidate'])\n",
    "            print(\"data candidate:\", data['candidate'])\n",
    "            break\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "\n",
    "    recall_1 = recall(predictions, references, 1)\n",
    "    recall_5 = recall(predictions, references, 5)\n",
    "    recall_10 = recall(predictions, references, 10)\n",
    "    mr = mean_rank(predictions, references)\n",
    "    mrr = mean_reciprocal_rank(predictions, references)\n",
    "    s = \"r1={}, r5={}, r10={}, mr={}, mrr={}\"\n",
    "    print(s.format(recall_1, recall_5, recall_10, mr, mrr))\n",
    "\n",
    "    print(\"testing time:\", time.time() - start_time)\n",
    "    # for ref, pre in zip(references, predictions):\n",
    "    #     print(ref)\n",
    "    #     print(\"-\"*20)  \n",
    "    #     print(pre)\n",
    "    #     print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: train\n",
      "starting load...\n",
      "loading time: 3.001723051071167\n",
      "starting load...\n",
      "loading time: 0.10674905776977539\n",
      "-------Y: tensor([[   1, 1301, 3641,  ...,    0,    0,    0],\n",
      "        [   1,    3,   16,  ...,    0,    0,    0],\n",
      "        [   1, 4890,  340,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  676, 3329,  ...,    0,    0,    0],\n",
      "        [   1, 6615,  285,  ...,    0,    0,    0],\n",
      "        [   1,    9,   48,  ...,    0,    0,    0]])\n",
      "Y[63]: tensor([   1,    9,   48, 4483,    5,   78, 2083,  227,  227,  227,    2,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "-------T: tensor([[   1,   71, 7314,  ...,    0,    0,    0],\n",
      "        [   1,  501,    4,  ...,    0,    0,    0],\n",
      "        [   1,    3,    4,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  173,  434,  ...,    0,    0,    0],\n",
      "        [   1,    3,  145,  ...,    0,    0,    0],\n",
      "        [   1,  225,   13,  ...,    0,    0,    0]])\n",
      "T[63]: tensor([    1,   225,    13,   146,    89,     7,     4,  4483, 10134,    14,\n",
      "            4,   366,   359,   366,   359,   366,   359,   366,   359,   366,\n",
      "          359,   366,   359,   366,   359,   366,   359,   366,   359,   366,\n",
      "          359,   366,   359,     4,  3403,     4,    24,  4643,  3403,    14,\n",
      "            4,    22,    22,     4,   444,     4,   188,     7,   188,     7,\n",
      "           48,    69,  1443,   359,     7,     2,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[-2.0356, -1.2437, -0.6556,  ...,  0.9989,  0.3780,  0.1779],\n",
      "         [ 2.5148,  0.8220,  0.0426,  ..., -1.6159, -1.0612, -0.4655],\n",
      "         [ 0.5960, -1.9747,  0.1135,  ..., -0.6907, -0.1843,  1.7652],\n",
      "         ...,\n",
      "         [ 0.2069, -0.0269, -0.7746,  ..., -1.4364, -0.8100,  0.7562],\n",
      "         [-0.4488,  0.9028, -0.3454,  ..., -1.1402, -0.2937,  0.5626],\n",
      "         [ 0.3287,  1.0530,  0.0941,  ..., -1.4827, -0.5544,  0.7612]],\n",
      "\n",
      "        [[-1.4430, -1.7945, -1.1092,  ...,  0.5207, -0.5356, -0.1684],\n",
      "         [-0.3173, -0.3051, -1.5037,  ...,  0.3214, -0.8065,  1.4096],\n",
      "         [ 0.2190, -2.5668, -1.2224,  ...,  0.1728, -0.5218,  0.6676],\n",
      "         ...,\n",
      "         [ 0.3799, -0.3953, -0.2145,  ..., -1.4071, -1.0904,  1.3588],\n",
      "         [-0.0092, -0.4990, -0.6470,  ..., -0.8442, -0.6339,  0.3640],\n",
      "         [-0.6886, -0.0328, -0.1817,  ..., -1.5213, -0.5307,  1.0901]],\n",
      "\n",
      "        [[-1.2089, -1.9099, -1.3422,  ...,  0.6250, -0.2241,  0.0770],\n",
      "         [ 0.3262, -0.7124, -0.6130,  ...,  0.4724,  1.4122,  0.9139],\n",
      "         [ 0.4905, -2.6466, -0.2824,  ...,  0.6377, -0.6794,  1.5229],\n",
      "         ...,\n",
      "         [ 0.2602, -0.1234, -1.1349,  ..., -0.6370, -0.3820,  1.0877],\n",
      "         [ 0.3613, -0.5545, -0.5686,  ..., -1.0888, -0.0476,  1.1642],\n",
      "         [-0.2284,  0.1400, -0.0903,  ..., -1.5627, -1.0583,  1.3787]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6533, -1.0891, -0.9626,  ...,  0.8817, -0.0803,  0.0950],\n",
      "         [ 0.3836, -0.5909, -0.0224,  ..., -0.7477, -1.4600,  1.0409],\n",
      "         [-0.1371, -1.1462, -0.5659,  ..., -1.0401, -0.7366,  3.1965],\n",
      "         ...,\n",
      "         [ 0.3522,  0.1417, -0.2476,  ..., -0.9370, -0.5263,  1.1045],\n",
      "         [-0.1834,  0.0085, -0.6769,  ..., -1.1002, -0.3285,  1.1833],\n",
      "         [ 0.6814,  1.1585,  0.0407,  ..., -1.5303, -0.1806,  1.5265]],\n",
      "\n",
      "        [[-1.1064, -1.5703, -0.7192,  ...,  0.5565, -0.0722, -0.0135],\n",
      "         [ 0.5134,  0.6355, -0.6896,  ...,  0.3875, -0.7771,  1.1507],\n",
      "         [-0.8085, -0.5319, -0.3096,  ...,  0.4298,  0.7041, -0.3109],\n",
      "         ...,\n",
      "         [ 0.3348,  0.3245, -0.8252,  ..., -1.2965, -0.5421,  0.8804],\n",
      "         [-0.3364,  0.0337, -0.2602,  ..., -1.3902, -0.4058,  0.8324],\n",
      "         [-1.1164,  0.7813, -0.2583,  ..., -1.0184, -0.4264,  1.0528]],\n",
      "\n",
      "        [[ 0.1530, -1.5394, -0.9496,  ...,  0.8949,  0.2393, -0.4152],\n",
      "         [ 0.2471,  0.2900, -0.4939,  ...,  1.0366,  0.1424,  1.7926],\n",
      "         [ 0.0258, -0.9362,  0.4085,  ..., -0.4466, -1.5207, -0.4593],\n",
      "         ...,\n",
      "         [ 0.2940, -0.1520, -1.0259,  ..., -0.2997, -0.8242,  1.0688],\n",
      "         [ 0.9985,  0.3198, -0.6494,  ..., -1.1927, -0.4097,  0.9088],\n",
      "         [-0.3649,  1.0607, -0.0660,  ..., -1.3096, -0.6831,  1.3617]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n",
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[ 0.7030, -0.4805,  0.5400,  ..., -0.1906, -0.7496,  0.3430],\n",
      "         [ 0.6695, -0.1954, -0.5768,  ...,  1.0173,  0.2118,  0.8079],\n",
      "         [ 0.6593, -0.4256,  0.9042,  ...,  0.8581, -0.0634, -0.0973],\n",
      "         ...,\n",
      "         [-0.6211, -0.7650,  0.6955,  ..., -0.8236, -0.9928,  0.1569],\n",
      "         [-0.3982, -0.5084,  0.9339,  ..., -0.7302, -0.8530, -0.1037],\n",
      "         [-0.4434, -0.5093,  0.5603,  ..., -0.5323, -0.9795, -0.5112]],\n",
      "\n",
      "        [[ 0.3052,  0.0879,  0.2838,  ..., -0.6523, -0.9702,  0.1908],\n",
      "         [ 0.1219,  0.0592, -0.0607,  ...,  1.2508, -0.4211,  0.1326],\n",
      "         [ 0.8777,  0.5459, -0.1095,  ...,  0.6208, -0.2975, -0.3479],\n",
      "         ...,\n",
      "         [-0.4891, -0.4394,  0.9158,  ..., -0.6968, -0.6574, -0.3571],\n",
      "         [-0.2975, -0.3230,  1.1397,  ..., -0.6170, -0.8410, -0.0988],\n",
      "         [-0.3005, -0.0757,  0.9187,  ...,  0.1600, -0.7925,  0.1078]],\n",
      "\n",
      "        [[ 0.0373, -0.1900,  0.1614,  ..., -0.3116, -0.5760,  0.2814],\n",
      "         [ 0.6548,  0.1961, -0.8053,  ...,  0.2787, -0.3840,  0.6212],\n",
      "         [ 0.2765,  0.5730, -0.4813,  ..., -0.0634,  0.9069,  1.0092],\n",
      "         ...,\n",
      "         [ 0.2710, -0.2889,  0.4946,  ..., -0.6845, -0.2603, -0.1641],\n",
      "         [ 0.0708, -0.5612,  0.6731,  ..., -0.6256, -0.3760, -0.5276],\n",
      "         [-0.0636,  0.1194,  0.3952,  ..., -0.6629, -0.7033, -0.1072]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1124,  0.0360,  0.0865,  ...,  0.0020, -0.3929,  0.7360],\n",
      "         [-0.1409, -0.3290, -0.3193,  ...,  0.4420, -0.4849,  0.0032],\n",
      "         [-0.5385, -0.4916,  0.2405,  ...,  0.2282, -0.6032, -0.6815],\n",
      "         ...,\n",
      "         [-0.3848, -0.2205,  0.6826,  ..., -0.3982, -0.5291, -0.0057],\n",
      "         [-0.3609, -0.1939,  0.8830,  ..., -0.6016, -0.4870, -0.3115],\n",
      "         [-0.4951, -0.4416,  0.8720,  ..., -0.2313, -0.6010, -0.3282]],\n",
      "\n",
      "        [[-0.0458, -0.1647,  0.7215,  ..., -0.3561, -0.8176,  0.0514],\n",
      "         [ 0.6757, -0.4460, -0.4227,  ...,  0.3650,  0.2310, -0.3567],\n",
      "         [ 0.9226, -0.6344, -0.5426,  ...,  0.2849, -0.5524,  0.4435],\n",
      "         ...,\n",
      "         [-0.3499, -0.2941,  0.6053,  ..., -0.5942, -0.8707, -0.3734],\n",
      "         [-0.2764, -0.0961,  0.5642,  ..., -0.7174, -0.9742, -0.1164],\n",
      "         [-0.4082,  0.1764,  0.9147,  ..., -0.4201, -0.8181, -0.3507]],\n",
      "\n",
      "        [[ 0.3224,  0.1452,  0.1754,  ..., -0.2537,  0.0020,  0.1559],\n",
      "         [ 0.2435,  0.4576, -0.4429,  ..., -0.1383,  0.6133,  0.4758],\n",
      "         [-0.3076, -0.1260,  0.0167,  ..., -0.3836, -0.4359, -0.0909],\n",
      "         ...,\n",
      "         [-0.0261, -0.5435,  0.6781,  ..., -0.3165, -0.4340, -0.2162],\n",
      "         [ 0.2235, -0.8022,  0.5329,  ..., -0.8379, -0.6258, -0.5116],\n",
      "         [ 0.0207, -0.6730,  1.2383,  ..., -0.3374, -0.8361, -0.0879]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [1301,    3, 4890,  ...,  676, 6615,    9],\n",
      "        [3641,   16,  340,  ..., 3329,  285,   48],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs.tr tensor([[[ 0.7030, -0.4805,  0.5400,  ..., -0.1906, -0.7496,  0.3430],\n",
      "         [ 0.3052,  0.0879,  0.2838,  ..., -0.6523, -0.9702,  0.1908],\n",
      "         [ 0.0373, -0.1900,  0.1614,  ..., -0.3116, -0.5760,  0.2814],\n",
      "         ...,\n",
      "         [-0.1124,  0.0360,  0.0865,  ...,  0.0020, -0.3929,  0.7360],\n",
      "         [-0.0458, -0.1647,  0.7215,  ..., -0.3561, -0.8176,  0.0514],\n",
      "         [ 0.3224,  0.1452,  0.1754,  ..., -0.2537,  0.0020,  0.1559]],\n",
      "\n",
      "        [[ 0.6695, -0.1954, -0.5768,  ...,  1.0173,  0.2118,  0.8079],\n",
      "         [ 0.1219,  0.0592, -0.0607,  ...,  1.2508, -0.4211,  0.1326],\n",
      "         [ 0.6548,  0.1961, -0.8053,  ...,  0.2787, -0.3840,  0.6212],\n",
      "         ...,\n",
      "         [-0.1409, -0.3290, -0.3193,  ...,  0.4420, -0.4849,  0.0032],\n",
      "         [ 0.6757, -0.4460, -0.4227,  ...,  0.3650,  0.2310, -0.3567],\n",
      "         [ 0.2435,  0.4576, -0.4429,  ..., -0.1383,  0.6133,  0.4758]],\n",
      "\n",
      "        [[ 0.6593, -0.4256,  0.9042,  ...,  0.8581, -0.0634, -0.0973],\n",
      "         [ 0.8777,  0.5459, -0.1095,  ...,  0.6208, -0.2975, -0.3479],\n",
      "         [ 0.2765,  0.5730, -0.4813,  ..., -0.0634,  0.9069,  1.0092],\n",
      "         ...,\n",
      "         [-0.5385, -0.4916,  0.2405,  ...,  0.2282, -0.6032, -0.6815],\n",
      "         [ 0.9226, -0.6344, -0.5426,  ...,  0.2849, -0.5524,  0.4435],\n",
      "         [-0.3076, -0.1260,  0.0167,  ..., -0.3836, -0.4359, -0.0909]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.6211, -0.7650,  0.6955,  ..., -0.8236, -0.9928,  0.1569],\n",
      "         [-0.4891, -0.4394,  0.9158,  ..., -0.6968, -0.6574, -0.3571],\n",
      "         [ 0.2710, -0.2889,  0.4946,  ..., -0.6845, -0.2603, -0.1641],\n",
      "         ...,\n",
      "         [-0.3848, -0.2205,  0.6826,  ..., -0.3982, -0.5291, -0.0057],\n",
      "         [-0.3499, -0.2941,  0.6053,  ..., -0.5942, -0.8707, -0.3734],\n",
      "         [-0.0261, -0.5435,  0.6781,  ..., -0.3165, -0.4340, -0.2162]],\n",
      "\n",
      "        [[-0.3982, -0.5084,  0.9339,  ..., -0.7302, -0.8530, -0.1037],\n",
      "         [-0.2975, -0.3230,  1.1397,  ..., -0.6170, -0.8410, -0.0988],\n",
      "         [ 0.0708, -0.5612,  0.6731,  ..., -0.6256, -0.3760, -0.5276],\n",
      "         ...,\n",
      "         [-0.3609, -0.1939,  0.8830,  ..., -0.6016, -0.4870, -0.3115],\n",
      "         [-0.2764, -0.0961,  0.5642,  ..., -0.7174, -0.9742, -0.1164],\n",
      "         [ 0.2235, -0.8022,  0.5329,  ..., -0.8379, -0.6258, -0.5116]],\n",
      "\n",
      "        [[-0.4434, -0.5093,  0.5603,  ..., -0.5323, -0.9795, -0.5112],\n",
      "         [-0.3005, -0.0757,  0.9187,  ...,  0.1600, -0.7925,  0.1078],\n",
      "         [-0.0636,  0.1194,  0.3952,  ..., -0.6629, -0.7033, -0.1072],\n",
      "         ...,\n",
      "         [-0.4951, -0.4416,  0.8720,  ..., -0.2313, -0.6010, -0.3282],\n",
      "         [-0.4082,  0.1764,  0.9147,  ..., -0.4201, -0.8181, -0.3507],\n",
      "         [ 0.0207, -0.6730,  1.2383,  ..., -0.3374, -0.8361, -0.0879]]],\n",
      "       device='cuda:0', grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([11.4694, 10.6807, 10.3750,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0', grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(3.8705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n",
      "n_samples: 64\n",
      "-------Y: tensor([[    1,   104,   104,  ..., 28336,    21,     2],\n",
      "        [    1,   172,    23,  ...,   113,  7243,     2],\n",
      "        [    1,     3,     2,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,   636,    18,  ...,     0,     0,     0],\n",
      "        [    1,  1472,  5524,  ...,     0,     0,     0],\n",
      "        [    1,  3298, 16669,  ...,     0,     0,     0]])\n",
      "Y[63]: tensor([    1,  3298, 16669,   558,    75,     6,  9534,     6,    41,  4961,\n",
      "            2,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "-------T: tensor([[    1,   148,  1363,  ...,     0,     0,     0],\n",
      "        [    1,   151,  7858,  ...,     0,     0,     0],\n",
      "        [    1,    45,  2832,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1, 15845,   152,  ...,     0,     0,     0],\n",
      "        [    1,    72,  8600,  ...,     0,     0,     0],\n",
      "        [    1,  2874,     6,  ...,     0,     0,     0]])\n",
      "T[63]: tensor([    1,  2874,     6,    74,    12,   826,     7,     4,   189,   558,\n",
      "          459,  6988,    25,     4,  1154,     7,     6,  3298,  3821,    12,\n",
      "           12,  4299,     5, 14383,     6,   219,   895,    49, 21174,  2828,\n",
      "         3821,   717,     4, 21203,     4,  9814,     5,    71,    13,   387,\n",
      "            9,    68,    13,  2935,  3278,  4752,     4,   293,  3821,    96,\n",
      "          153,     4,     3,    38, 25704,    15,   108,     4,  2477,  1218,\n",
      "           12,  1832,     7,     6,   320,  8935,  5762,     5,  3821,    10,\n",
      "            2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[-5.1557e-01, -2.0521e+00,  1.7178e-01,  ...,  5.5275e-01,\n",
      "          -1.1736e+00,  1.1416e+00],\n",
      "         [ 4.2396e-01, -2.0005e+00, -4.9789e-01,  ..., -3.7929e-01,\n",
      "          -7.5559e-01,  3.1918e+00],\n",
      "         [ 4.6729e-01, -3.5515e+00,  2.7115e-01,  ..., -7.9559e-01,\n",
      "           1.8011e-03,  1.0976e+00],\n",
      "         ...,\n",
      "         [ 6.9558e-02, -1.4254e+00,  6.4145e-02,  ..., -6.7108e-01,\n",
      "          -1.0161e+00,  1.2515e+00],\n",
      "         [-2.6522e-01, -1.0075e+00,  6.2159e-01,  ..., -4.9609e-01,\n",
      "          -9.5519e-01,  1.6386e+00],\n",
      "         [-3.6508e-01, -7.6589e-01,  1.0759e+00,  ..., -8.0701e-01,\n",
      "          -1.0109e+00,  1.9366e+00]],\n",
      "\n",
      "        [[-9.9385e-01, -1.9284e+00,  1.5881e-02,  ..., -7.0136e-01,\n",
      "          -9.8844e-01,  9.0508e-01],\n",
      "         [ 6.9114e-01, -1.4368e+00,  4.5991e-01,  ..., -5.0419e-01,\n",
      "          -1.0125e+00,  1.0175e+00],\n",
      "         [ 2.9258e-01, -2.5622e+00,  1.3350e+00,  ..., -8.4725e-01,\n",
      "          -1.2941e+00,  8.7561e-01],\n",
      "         ...,\n",
      "         [ 2.1146e-01, -8.3553e-01,  2.8001e-01,  ..., -2.1803e-01,\n",
      "          -1.1455e+00,  1.8846e+00],\n",
      "         [-3.1226e-01, -8.5563e-01,  6.1531e-01,  ..., -1.0073e+00,\n",
      "          -7.0413e-01,  1.7982e+00],\n",
      "         [ 5.0730e-01, -7.3164e-01,  8.9619e-01,  ..., -9.8389e-01,\n",
      "          -1.2957e+00,  1.9774e+00]],\n",
      "\n",
      "        [[-8.6569e-01, -2.3210e+00, -6.7495e-02,  ...,  3.7317e-01,\n",
      "          -1.0160e+00,  1.0956e+00],\n",
      "         [ 7.3154e-01, -1.8157e+00,  1.1092e+00,  ..., -3.7389e-01,\n",
      "          -9.6993e-01,  2.5120e+00],\n",
      "         [ 7.3488e-01, -1.6513e+00, -1.5342e-01,  ..., -1.6002e+00,\n",
      "          -1.3578e+00,  1.5018e+00],\n",
      "         ...,\n",
      "         [ 2.4809e-01, -6.5307e-01,  1.8242e-01,  ..., -3.2342e-01,\n",
      "          -1.0135e+00,  1.4890e+00],\n",
      "         [ 1.6042e-02, -8.6118e-01,  5.7843e-01,  ..., -5.0575e-01,\n",
      "          -5.5541e-01,  1.4845e+00],\n",
      "         [-2.1102e-01, -7.2913e-01,  1.0096e+00,  ..., -8.9485e-01,\n",
      "          -1.2422e+00,  1.4690e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0876e+00, -2.2729e+00, -1.9107e-02,  ...,  5.5045e-01,\n",
      "          -1.1402e+00,  1.0183e+00],\n",
      "         [ 1.2398e+00, -1.9232e+00, -2.5646e-01,  ...,  2.3229e-01,\n",
      "          -1.3093e+00,  1.4858e+00],\n",
      "         [ 6.0306e-01, -3.3631e+00,  1.2099e+00,  ...,  1.1624e+00,\n",
      "          -1.7349e+00,  2.1053e+00],\n",
      "         ...,\n",
      "         [-1.0002e-01, -7.4638e-01, -4.8578e-01,  ..., -4.6395e-01,\n",
      "          -6.9999e-01,  9.8889e-01],\n",
      "         [-3.4601e-01, -1.1938e+00,  2.6598e-01,  ..., -5.9253e-01,\n",
      "          -7.3691e-01,  1.9154e+00],\n",
      "         [-3.0380e-01, -6.1399e-01,  8.4768e-01,  ..., -2.9088e-01,\n",
      "          -6.5914e-01,  1.9598e+00]],\n",
      "\n",
      "        [[-7.5680e-01, -2.3251e+00, -1.5267e-01,  ..., -8.6253e-01,\n",
      "          -1.1288e+00,  1.2760e+00],\n",
      "         [-1.1049e-01, -1.0875e+00,  5.9723e-03,  ...,  3.0749e-01,\n",
      "           1.3408e-02,  1.7215e+00],\n",
      "         [-2.0375e-01, -2.9582e+00,  1.0312e+00,  ..., -7.8029e-01,\n",
      "          -7.9713e-01,  1.1697e+00],\n",
      "         ...,\n",
      "         [ 3.1445e-01, -1.4015e+00, -8.5942e-02,  ..., -6.9509e-01,\n",
      "          -1.0074e+00,  1.7101e+00],\n",
      "         [-1.1752e-01, -1.6891e+00,  2.3304e-01,  ..., -4.8235e-01,\n",
      "          -8.1081e-01,  1.6960e+00],\n",
      "         [-3.9438e-01, -1.2120e+00,  6.7540e-01,  ..., -2.8606e-01,\n",
      "          -1.1578e+00,  1.9495e+00]],\n",
      "\n",
      "        [[ 3.0669e-01, -2.2702e+00,  1.7928e-01,  ...,  8.0192e-01,\n",
      "          -8.0577e-01,  9.9325e-01],\n",
      "         [ 3.9833e-01, -1.5995e+00, -5.7926e-01,  ..., -5.5640e-01,\n",
      "          -2.3881e+00,  1.1267e+00],\n",
      "         [ 4.8610e-01, -3.0128e+00, -1.9758e-01,  ..., -1.5081e-01,\n",
      "          -1.3687e+00,  1.7135e+00],\n",
      "         ...,\n",
      "         [ 3.3211e-01, -4.4214e-01,  5.2026e-01,  ..., -6.5036e-01,\n",
      "          -8.2563e-01,  1.8093e+00],\n",
      "         [-1.1361e-01, -4.0660e-01,  4.4409e-01,  ..., -6.3172e-01,\n",
      "          -5.7607e-01,  1.5081e+00],\n",
      "         [-5.3069e-01, -5.2101e-01,  9.6920e-01,  ..., -8.2736e-01,\n",
      "          -6.3237e-01,  1.9048e+00]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[-7.0830e-01,  3.4507e-01,  7.7397e+00,  ..., -8.3835e-01,\n",
      "          -2.1066e-01, -1.0763e-01],\n",
      "         [-5.0210e-01,  1.0529e+00,  8.1549e+00,  ..., -2.8949e-01,\n",
      "          -2.3570e-02,  5.9031e-03],\n",
      "         [-5.7440e-01,  1.3026e+00,  8.1227e+00,  ..., -2.0170e-01,\n",
      "          -1.6368e-01, -3.1540e-01],\n",
      "         ...,\n",
      "         [-6.9905e-01, -4.6177e-01,  7.6889e+00,  ..., -5.5605e-01,\n",
      "          -6.4362e-01, -3.6022e-01],\n",
      "         [-6.7617e-01,  2.9998e-02,  8.1910e+00,  ..., -4.7042e-01,\n",
      "          -2.5442e-02, -4.7015e-01],\n",
      "         [-5.4246e-01, -2.4803e-01,  8.0461e+00,  ..., -2.4917e-01,\n",
      "          -8.0500e-02, -2.4779e-01]],\n",
      "\n",
      "        [[-6.5851e-01,  3.4695e-01,  7.6331e+00,  ..., -8.8101e-01,\n",
      "          -2.7591e-01,  4.9795e-02],\n",
      "         [-4.8385e-01,  2.6591e-01,  8.1595e+00,  ..., -5.4885e-01,\n",
      "          -3.0811e-01, -4.5133e-01],\n",
      "         [-2.4664e-01,  2.2899e-01,  8.1980e+00,  ..., -5.3360e-01,\n",
      "          -5.4850e-01, -6.7456e-02],\n",
      "         ...,\n",
      "         [-6.3216e-01,  1.3530e-01,  7.5372e+00,  ..., -9.1712e-01,\n",
      "           2.7549e-01, -4.0238e-01],\n",
      "         [-2.7532e-01, -5.7213e-02,  7.7137e+00,  ..., -1.7777e-01,\n",
      "          -5.3931e-01, -7.3183e-01],\n",
      "         [-3.6734e-01,  3.1393e-01,  8.1463e+00,  ..., -4.1296e-01,\n",
      "           6.0167e-02, -7.9163e-01]],\n",
      "\n",
      "        [[-5.1954e-01,  2.1804e-01,  7.9597e+00,  ..., -9.7491e-01,\n",
      "          -4.0731e-01, -1.3313e-01],\n",
      "         [-5.7292e-01,  1.1454e-01,  8.0370e+00,  ..., -2.5539e-01,\n",
      "          -1.4581e-01,  4.1377e-02],\n",
      "         [-1.8871e-01,  3.3856e-01,  8.1412e+00,  ..., -3.1053e-01,\n",
      "           4.7734e-01,  1.2926e-01],\n",
      "         ...,\n",
      "         [-8.9448e-01,  4.4041e-04,  8.0688e+00,  ..., -8.0274e-01,\n",
      "          -4.5425e-01, -3.9136e-01],\n",
      "         [-6.6257e-01,  3.6059e-01,  8.0541e+00,  ..., -8.5624e-01,\n",
      "          -5.5321e-01, -6.0080e-01],\n",
      "         [-8.9936e-01,  1.7410e-01,  7.9032e+00,  ..., -8.9607e-01,\n",
      "          -3.7829e-01, -4.1747e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.2972e-01,  2.7680e-01,  7.6859e+00,  ..., -9.1694e-01,\n",
      "          -2.2302e-01, -2.9961e-01],\n",
      "         [-1.9482e-01, -5.4588e-02,  7.8278e+00,  ..., -1.8334e-01,\n",
      "          -2.6373e-01, -3.6353e-01],\n",
      "         [-5.4539e-01,  1.8308e-01,  8.0044e+00,  ..., -6.9038e-01,\n",
      "          -2.0432e-01, -1.8612e-01],\n",
      "         ...,\n",
      "         [-7.6376e-01, -2.6541e-02,  8.0184e+00,  ..., -9.2207e-01,\n",
      "          -3.2910e-01, -6.1851e-01],\n",
      "         [-4.3542e-01, -7.2339e-02,  8.1482e+00,  ..., -5.3808e-01,\n",
      "          -1.9032e-01, -2.4843e-01],\n",
      "         [-4.7316e-01, -1.0008e-01,  7.9545e+00,  ..., -8.3257e-01,\n",
      "          -6.3841e-01, -4.4578e-01]],\n",
      "\n",
      "        [[-6.1827e-01,  8.8657e-02,  7.9743e+00,  ..., -6.0724e-01,\n",
      "          -4.3851e-01, -3.0363e-01],\n",
      "         [-6.4629e-01, -2.2282e-01,  8.1325e+00,  ..., -5.1206e-01,\n",
      "           5.3680e-02, -2.6260e-01],\n",
      "         [-4.3268e-01,  1.7553e-02,  8.1230e+00,  ..., -2.5021e-01,\n",
      "           2.7653e-01, -5.0917e-01],\n",
      "         ...,\n",
      "         [-8.0295e-01, -2.8337e-02,  8.1253e+00,  ..., -7.2335e-01,\n",
      "          -2.8968e-01, -2.0329e-01],\n",
      "         [-4.9858e-01,  6.7740e-03,  8.0544e+00,  ..., -7.4942e-01,\n",
      "          -2.5592e-01, -6.5650e-01],\n",
      "         [-7.0169e-01, -1.8174e-01,  8.0921e+00,  ..., -7.6337e-01,\n",
      "          -4.2016e-01, -3.5257e-01]],\n",
      "\n",
      "        [[-7.6869e-01,  3.7737e-01,  7.5117e+00,  ..., -6.7504e-01,\n",
      "          -3.8026e-01,  4.1331e-02],\n",
      "         [-5.7073e-01,  8.3055e-02,  7.9384e+00,  ..., -4.7684e-01,\n",
      "          -3.0538e-02,  3.9704e-02],\n",
      "         [-4.4690e-01,  3.9882e-01,  7.9820e+00,  ..., -4.9793e-01,\n",
      "          -2.6709e-01,  7.7716e-02],\n",
      "         ...,\n",
      "         [-7.6346e-01, -2.4537e-01,  7.9643e+00,  ..., -8.5910e-01,\n",
      "          -2.1799e-02, -5.1755e-01],\n",
      "         [-7.0050e-01, -1.6737e-01,  7.9385e+00,  ..., -7.5780e-01,\n",
      "          -6.8739e-01, -5.1722e-01],\n",
      "         [-5.7035e-01, -1.6174e-02,  8.1588e+00,  ..., -5.8700e-01,\n",
      "          -3.4097e-01, -9.5667e-01]]], device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [  104,   172,     3,  ...,   636,  1472,  3298],\n",
      "        [  104,    23,     2,  ...,    18,  5524, 16669],\n",
      "        ...,\n",
      "        [28336,   113,     0,  ...,     0,     0,     0],\n",
      "        [   21,  7243,     0,  ...,     0,     0,     0],\n",
      "        [    2,     2,     0,  ...,     0,     0,     0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n",
      "outs.tr tensor([[[-7.0830e-01,  3.4507e-01,  7.7397e+00,  ..., -8.3835e-01,\n",
      "          -2.1066e-01, -1.0763e-01],\n",
      "         [-6.5851e-01,  3.4695e-01,  7.6331e+00,  ..., -8.8101e-01,\n",
      "          -2.7591e-01,  4.9795e-02],\n",
      "         [-5.1954e-01,  2.1804e-01,  7.9597e+00,  ..., -9.7491e-01,\n",
      "          -4.0731e-01, -1.3313e-01],\n",
      "         ...,\n",
      "         [-6.2972e-01,  2.7680e-01,  7.6859e+00,  ..., -9.1694e-01,\n",
      "          -2.2302e-01, -2.9961e-01],\n",
      "         [-6.1827e-01,  8.8657e-02,  7.9743e+00,  ..., -6.0724e-01,\n",
      "          -4.3851e-01, -3.0363e-01],\n",
      "         [-7.6869e-01,  3.7737e-01,  7.5117e+00,  ..., -6.7504e-01,\n",
      "          -3.8026e-01,  4.1331e-02]],\n",
      "\n",
      "        [[-5.0210e-01,  1.0529e+00,  8.1549e+00,  ..., -2.8949e-01,\n",
      "          -2.3570e-02,  5.9031e-03],\n",
      "         [-4.8385e-01,  2.6591e-01,  8.1595e+00,  ..., -5.4885e-01,\n",
      "          -3.0811e-01, -4.5133e-01],\n",
      "         [-5.7292e-01,  1.1454e-01,  8.0370e+00,  ..., -2.5539e-01,\n",
      "          -1.4581e-01,  4.1377e-02],\n",
      "         ...,\n",
      "         [-1.9482e-01, -5.4588e-02,  7.8278e+00,  ..., -1.8334e-01,\n",
      "          -2.6373e-01, -3.6353e-01],\n",
      "         [-6.4629e-01, -2.2282e-01,  8.1325e+00,  ..., -5.1206e-01,\n",
      "           5.3680e-02, -2.6260e-01],\n",
      "         [-5.7073e-01,  8.3055e-02,  7.9384e+00,  ..., -4.7684e-01,\n",
      "          -3.0538e-02,  3.9704e-02]],\n",
      "\n",
      "        [[-5.7440e-01,  1.3026e+00,  8.1227e+00,  ..., -2.0170e-01,\n",
      "          -1.6368e-01, -3.1540e-01],\n",
      "         [-2.4664e-01,  2.2899e-01,  8.1980e+00,  ..., -5.3360e-01,\n",
      "          -5.4850e-01, -6.7456e-02],\n",
      "         [-1.8871e-01,  3.3856e-01,  8.1412e+00,  ..., -3.1053e-01,\n",
      "           4.7734e-01,  1.2926e-01],\n",
      "         ...,\n",
      "         [-5.4539e-01,  1.8308e-01,  8.0044e+00,  ..., -6.9038e-01,\n",
      "          -2.0432e-01, -1.8612e-01],\n",
      "         [-4.3268e-01,  1.7553e-02,  8.1230e+00,  ..., -2.5021e-01,\n",
      "           2.7653e-01, -5.0917e-01],\n",
      "         [-4.4690e-01,  3.9882e-01,  7.9820e+00,  ..., -4.9793e-01,\n",
      "          -2.6709e-01,  7.7716e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.9905e-01, -4.6177e-01,  7.6889e+00,  ..., -5.5605e-01,\n",
      "          -6.4362e-01, -3.6022e-01],\n",
      "         [-6.3216e-01,  1.3530e-01,  7.5372e+00,  ..., -9.1712e-01,\n",
      "           2.7549e-01, -4.0238e-01],\n",
      "         [-8.9448e-01,  4.4041e-04,  8.0688e+00,  ..., -8.0274e-01,\n",
      "          -4.5425e-01, -3.9136e-01],\n",
      "         ...,\n",
      "         [-7.6376e-01, -2.6541e-02,  8.0184e+00,  ..., -9.2207e-01,\n",
      "          -3.2910e-01, -6.1851e-01],\n",
      "         [-8.0295e-01, -2.8337e-02,  8.1253e+00,  ..., -7.2335e-01,\n",
      "          -2.8968e-01, -2.0329e-01],\n",
      "         [-7.6346e-01, -2.4537e-01,  7.9643e+00,  ..., -8.5910e-01,\n",
      "          -2.1799e-02, -5.1755e-01]],\n",
      "\n",
      "        [[-6.7617e-01,  2.9998e-02,  8.1910e+00,  ..., -4.7042e-01,\n",
      "          -2.5442e-02, -4.7015e-01],\n",
      "         [-2.7532e-01, -5.7213e-02,  7.7137e+00,  ..., -1.7777e-01,\n",
      "          -5.3931e-01, -7.3183e-01],\n",
      "         [-6.6257e-01,  3.6059e-01,  8.0541e+00,  ..., -8.5624e-01,\n",
      "          -5.5321e-01, -6.0080e-01],\n",
      "         ...,\n",
      "         [-4.3542e-01, -7.2339e-02,  8.1482e+00,  ..., -5.3808e-01,\n",
      "          -1.9032e-01, -2.4843e-01],\n",
      "         [-4.9858e-01,  6.7740e-03,  8.0544e+00,  ..., -7.4942e-01,\n",
      "          -2.5592e-01, -6.5650e-01],\n",
      "         [-7.0050e-01, -1.6737e-01,  7.9385e+00,  ..., -7.5780e-01,\n",
      "          -6.8739e-01, -5.1722e-01]],\n",
      "\n",
      "        [[-5.4246e-01, -2.4803e-01,  8.0461e+00,  ..., -2.4917e-01,\n",
      "          -8.0500e-02, -2.4779e-01],\n",
      "         [-3.6734e-01,  3.1393e-01,  8.1463e+00,  ..., -4.1296e-01,\n",
      "           6.0167e-02, -7.9163e-01],\n",
      "         [-8.9936e-01,  1.7410e-01,  7.9032e+00,  ..., -8.9607e-01,\n",
      "          -3.7829e-01, -4.1747e-01],\n",
      "         ...,\n",
      "         [-4.7316e-01, -1.0008e-01,  7.9545e+00,  ..., -8.3257e-01,\n",
      "          -6.3841e-01, -4.4578e-01],\n",
      "         [-7.0169e-01, -1.8174e-01,  8.0921e+00,  ..., -7.6337e-01,\n",
      "          -4.2016e-01, -3.5257e-01],\n",
      "         [-5.7035e-01, -1.6174e-02,  8.1588e+00,  ..., -5.8700e-01,\n",
      "          -3.4097e-01, -9.5667e-01]]], device='cuda:0',\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([11.1727, 10.2847,  8.9282,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0', grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(3.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 128\n",
      "-------Y: tensor([[    1,   455,   455,  ...,     2,     0,     0],\n",
      "        [    1,  2070,  4025,  ...,     0,     0,     0],\n",
      "        [    1, 11583,     5,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  1451,   276,  ...,     0,     0,     0],\n",
      "        [    1,    33,    12,  ...,     0,     0,     0],\n",
      "        [    1,     3,     3,  ...,     0,     0,     0]])\n",
      "Y[63]: tensor([1, 3, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "-------T: tensor([[   1,  455,  455,  ...,  455,  455,    2],\n",
      "        [   1,   24,  339,  ...,    0,    0,    0],\n",
      "        [   1,  902, 1766,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,   85,   83,  ...,    0,    0,    0],\n",
      "        [   1,  119,   85,  ...,    0,    0,    0],\n",
      "        [   1,  257, 4717,  ...,    0,    0,    0]])\n",
      "T[63]: tensor([    1,   257,  4717,   479,     5,     4,   303,    26,  8920,    24,\n",
      "          743,   163,     4,   912,     4,   629,  1924,    30,    29,    10,\n",
      "            4,   317,  1851,  1241,     6,   942,     6,     3,  5243,     5,\n",
      "          293,     9,  4495,     3,    61,   751,   315,   751,    58,  3248,\n",
      "            6,   856,     3,  1360,  1851, 29171,    61,   437,   505, 16607,\n",
      "          505,   437,    58,   617,     3,     4,   257,  2864,     4, 19727,\n",
      "            4,     3,     2,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[-6.8198e-01, -2.3302e+00,  6.8106e-01,  ...,  3.8667e-01,\n",
      "          -1.3022e+00,  3.9074e-01],\n",
      "         [-1.1874e-01, -1.6413e+00,  1.1450e+00,  ...,  5.1544e-01,\n",
      "          -7.8636e-01,  3.5075e-01],\n",
      "         [ 4.7156e-02, -1.2442e+00,  9.3004e-01,  ...,  2.2589e-01,\n",
      "          -4.7146e-01,  8.4586e-02],\n",
      "         ...,\n",
      "         [ 1.9901e-01, -2.1437e+00,  7.1548e-01,  ...,  4.2866e-01,\n",
      "          -8.4918e-01,  3.1804e-01],\n",
      "         [-1.4535e-01, -1.4783e+00,  1.2117e+00,  ...,  7.2148e-01,\n",
      "          -8.6173e-01,  3.6709e-01],\n",
      "         [-3.9755e-01, -2.0819e+00,  1.3562e+00,  ...,  2.4069e-01,\n",
      "          -4.5407e-01,  8.6412e-01]],\n",
      "\n",
      "        [[-5.3998e-01, -2.6613e+00,  2.8298e-01,  ...,  5.0684e-01,\n",
      "          -1.7441e+00,  1.1989e+00],\n",
      "         [ 1.0173e+00, -2.4866e+00,  3.7667e-01,  ..., -2.3792e-01,\n",
      "          -1.7043e+00,  1.3736e+00],\n",
      "         [ 1.6458e+00, -2.0006e+00,  6.9007e-01,  ...,  3.1082e-01,\n",
      "          -1.9912e+00,  1.3043e+00],\n",
      "         ...,\n",
      "         [ 6.8152e-01, -1.3681e+00,  2.1399e-01,  ..., -6.5364e-01,\n",
      "          -1.4503e+00,  1.2112e+00],\n",
      "         [ 2.3603e-01, -2.2944e+00,  5.1151e-01,  ..., -1.4969e-01,\n",
      "          -1.3726e+00,  1.5284e+00],\n",
      "         [ 3.3247e-02, -1.2889e+00,  7.7227e-01,  ..., -4.6363e-01,\n",
      "          -1.2973e+00,  1.5984e+00]],\n",
      "\n",
      "        [[-1.4397e-01, -2.3658e+00,  2.8800e-01,  ...,  6.7262e-01,\n",
      "          -1.4917e+00,  1.2960e+00],\n",
      "         [ 6.6015e-02, -1.5523e+00,  1.1170e+00,  ...,  3.0946e-01,\n",
      "          -2.0263e+00,  2.7393e+00],\n",
      "         [ 1.5261e+00, -1.7304e+00,  1.7344e+00,  ...,  3.5714e-02,\n",
      "          -1.9159e+00,  2.1360e+00],\n",
      "         ...,\n",
      "         [ 4.8527e-01, -1.3282e+00, -1.5737e-01,  ..., -2.3381e-01,\n",
      "          -1.3464e+00,  1.0891e+00],\n",
      "         [ 4.4904e-02, -1.1097e+00,  7.4342e-01,  ...,  3.5945e-02,\n",
      "          -1.0559e+00,  1.8613e+00],\n",
      "         [ 7.6374e-02, -1.0405e+00,  7.2277e-01,  ..., -2.9603e-01,\n",
      "          -1.4788e+00,  1.5987e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.3880e-01, -2.5110e+00,  3.4268e-01,  ...,  4.8650e-01,\n",
      "          -1.1914e+00,  8.8920e-01],\n",
      "         [ 1.4601e+00, -2.2891e+00,  8.4572e-01,  ...,  5.0471e-01,\n",
      "          -9.9555e-01,  1.8267e+00],\n",
      "         [ 7.0045e-02, -2.3034e+00, -7.3742e-02,  ...,  1.5615e-01,\n",
      "          -1.5371e+00,  8.9834e-01],\n",
      "         ...,\n",
      "         [ 2.5751e-01, -1.4803e+00,  2.4946e-01,  ..., -5.3304e-01,\n",
      "          -1.4030e+00,  1.4711e+00],\n",
      "         [ 6.0377e-02, -1.6209e+00,  2.3326e-01,  ..., -1.2663e-01,\n",
      "          -1.4562e+00,  1.4008e+00],\n",
      "         [ 8.0166e-02, -1.3874e+00,  8.3421e-01,  ..., -1.5032e-01,\n",
      "          -1.4678e+00,  1.5327e+00]],\n",
      "\n",
      "        [[-4.5229e-01, -2.3576e+00, -1.8247e-02,  ...,  5.9485e-01,\n",
      "          -1.1679e+00,  9.1882e-01],\n",
      "         [ 4.0536e-01, -1.7849e+00,  1.4846e-01,  ..., -2.6802e-01,\n",
      "          -1.2936e+00,  1.3743e+00],\n",
      "         [ 1.0773e+00, -2.3037e+00,  8.7948e-01,  ...,  8.7099e-01,\n",
      "          -1.5139e+00,  1.6743e+00],\n",
      "         ...,\n",
      "         [ 2.4958e-01, -1.4130e+00, -1.3282e-01,  ..., -1.4073e-01,\n",
      "          -1.2296e+00,  1.8067e+00],\n",
      "         [ 6.1347e-01, -1.1159e+00,  4.6898e-01,  ..., -2.8898e-01,\n",
      "          -1.6737e+00,  1.3056e+00],\n",
      "         [ 1.4127e-01, -1.1854e+00,  7.9168e-01,  ..., -3.0342e-01,\n",
      "          -1.3448e+00,  1.6542e+00]],\n",
      "\n",
      "        [[-3.4343e-01, -2.1624e+00,  3.3486e-02,  ...,  4.2349e-01,\n",
      "          -1.5319e+00,  7.9282e-01],\n",
      "         [ 3.0767e-01, -2.1717e+00,  1.3248e+00,  ...,  1.0575e-01,\n",
      "          -1.4732e+00,  8.1995e-01],\n",
      "         [ 1.0279e+00, -2.3928e+00,  8.8128e-01,  ...,  1.4142e+00,\n",
      "          -1.2179e+00,  1.7186e+00],\n",
      "         ...,\n",
      "         [ 6.5183e-01, -1.1742e+00,  2.3348e-01,  ..., -2.2318e-03,\n",
      "          -1.1130e+00,  1.2360e+00],\n",
      "         [ 3.0970e-01, -2.0759e+00,  7.4708e-01,  ..., -3.0614e-01,\n",
      "          -1.3092e+00,  1.7157e+00],\n",
      "         [ 2.3295e-01, -7.7575e-01,  8.7174e-01,  ..., -6.6250e-01,\n",
      "          -1.2795e+00,  1.6080e+00]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n",
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[-0.5599, -0.0340,  8.0108,  ..., -0.3983, -0.0898, -0.7315],\n",
      "         [-0.5007, -0.5252,  8.5991,  ...,  0.0204, -0.2445, -0.5814],\n",
      "         [-0.4441, -0.5829,  8.7403,  ...,  0.1422, -0.3530, -0.6025],\n",
      "         ...,\n",
      "         [-0.8140, -0.5089,  8.7345,  ..., -0.1378, -0.5341, -0.7472],\n",
      "         [-0.3739, -0.1065,  8.4526,  ..., -0.2218,  0.1160, -0.1083],\n",
      "         [-0.5510, -0.6451,  8.6553,  ..., -0.0117, -0.4143, -1.0060]],\n",
      "\n",
      "        [[-0.6652, -0.2180,  8.4186,  ..., -0.4036, -0.2755, -0.5956],\n",
      "         [-0.4123, -0.1236,  8.8284,  ..., -0.3509,  0.0114, -0.4810],\n",
      "         [-0.5871, -0.0339,  8.7270,  ..., -0.2255, -0.2803, -0.8254],\n",
      "         ...,\n",
      "         [-0.8859, -0.3313,  8.7644,  ..., -0.4130, -0.3913, -0.6879],\n",
      "         [-0.7938, -0.3240,  9.0158,  ..., -0.5221, -0.2173, -0.6196],\n",
      "         [-0.7892, -0.4706,  8.8926,  ..., -0.4145, -0.5101, -0.6357]],\n",
      "\n",
      "        [[-0.6804, -0.1674,  8.2724,  ..., -0.2529, -0.4348, -0.4464],\n",
      "         [-0.3814, -0.0496,  8.7528,  ..., -0.5115, -0.1267, -0.6292],\n",
      "         [-0.7167, -0.3991,  8.7048,  ..., -0.6585, -0.2189, -0.8288],\n",
      "         ...,\n",
      "         [-0.7578, -0.6305,  8.8007,  ..., -0.5728, -0.1084, -0.5155],\n",
      "         [-0.8735, -0.3573,  8.9484,  ..., -0.7835, -0.2321, -0.6381],\n",
      "         [-0.9372, -0.3985,  8.8152,  ..., -0.4914, -0.4738, -0.5962]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5859, -0.1681,  8.3683,  ..., -0.3181, -0.1877, -0.7049],\n",
      "         [-0.3221, -0.3641,  8.5654,  ..., -0.1025, -0.1975, -0.7960],\n",
      "         [-0.6110, -0.1529,  8.8046,  ..., -0.0761,  0.1579, -0.4222],\n",
      "         ...,\n",
      "         [-0.8490, -0.5168,  8.8682,  ..., -0.3284, -0.2710, -0.6594],\n",
      "         [-0.7743, -0.3207,  8.7529,  ..., -0.3712, -0.3472, -0.8572],\n",
      "         [-0.6529, -0.7510,  8.8091,  ..., -0.3547, -0.2814, -0.5914]],\n",
      "\n",
      "        [[-0.8621, -0.1218,  8.4116,  ..., -0.6865, -0.3321, -0.5952],\n",
      "         [-0.4785, -0.3198,  8.7589,  ..., -0.2232, -0.1424, -0.4703],\n",
      "         [-0.7185, -0.1185,  8.5997,  ..., -0.1826, -0.0195, -0.4553],\n",
      "         ...,\n",
      "         [-0.9224, -0.3670,  8.9169,  ..., -0.5223, -0.3550, -0.4747],\n",
      "         [-0.7202, -0.4534,  8.8952,  ..., -0.1808, -0.4625, -0.5711],\n",
      "         [-0.7637, -0.3556,  8.9792,  ..., -0.4494, -0.1556, -0.7117]],\n",
      "\n",
      "        [[-0.5632, -0.0843,  8.2205,  ..., -0.5197, -0.0678, -0.8492],\n",
      "         [-0.6885, -0.3132,  8.9689,  ...,  0.1262, -0.2491, -0.1828],\n",
      "         [-0.8571, -0.1330,  8.6956,  ...,  0.0651, -0.1831, -0.4963],\n",
      "         ...,\n",
      "         [-0.7332, -0.2373,  8.6590,  ..., -0.5542, -0.2284, -0.6467],\n",
      "         [-0.8626, -0.2594,  8.8727,  ..., -0.4989, -0.2366, -0.7453],\n",
      "         [-0.6531, -0.3295,  8.8509,  ..., -0.3017, -0.5316, -0.8308]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [  455,  2070, 11583,  ...,  1451,    33,     3],\n",
      "        [  455,  4025,     5,  ...,   276,    12,     3],\n",
      "        ...,\n",
      "        [    2,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs.tr tensor([[[-0.5599, -0.0340,  8.0108,  ..., -0.3983, -0.0898, -0.7315],\n",
      "         [-0.6652, -0.2180,  8.4186,  ..., -0.4036, -0.2755, -0.5956],\n",
      "         [-0.6804, -0.1674,  8.2724,  ..., -0.2529, -0.4348, -0.4464],\n",
      "         ...,\n",
      "         [-0.5859, -0.1681,  8.3683,  ..., -0.3181, -0.1877, -0.7049],\n",
      "         [-0.8621, -0.1218,  8.4116,  ..., -0.6865, -0.3321, -0.5952],\n",
      "         [-0.5632, -0.0843,  8.2205,  ..., -0.5197, -0.0678, -0.8492]],\n",
      "\n",
      "        [[-0.5007, -0.5252,  8.5991,  ...,  0.0204, -0.2445, -0.5814],\n",
      "         [-0.4123, -0.1236,  8.8284,  ..., -0.3509,  0.0114, -0.4810],\n",
      "         [-0.3814, -0.0496,  8.7528,  ..., -0.5115, -0.1267, -0.6292],\n",
      "         ...,\n",
      "         [-0.3221, -0.3641,  8.5654,  ..., -0.1025, -0.1975, -0.7960],\n",
      "         [-0.4785, -0.3198,  8.7589,  ..., -0.2232, -0.1424, -0.4703],\n",
      "         [-0.6885, -0.3132,  8.9689,  ...,  0.1262, -0.2491, -0.1828]],\n",
      "\n",
      "        [[-0.4441, -0.5829,  8.7403,  ...,  0.1422, -0.3530, -0.6025],\n",
      "         [-0.5871, -0.0339,  8.7270,  ..., -0.2255, -0.2803, -0.8254],\n",
      "         [-0.7167, -0.3991,  8.7048,  ..., -0.6585, -0.2189, -0.8288],\n",
      "         ...,\n",
      "         [-0.6110, -0.1529,  8.8046,  ..., -0.0761,  0.1579, -0.4222],\n",
      "         [-0.7185, -0.1185,  8.5997,  ..., -0.1826, -0.0195, -0.4553],\n",
      "         [-0.8571, -0.1330,  8.6956,  ...,  0.0651, -0.1831, -0.4963]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8140, -0.5089,  8.7345,  ..., -0.1378, -0.5341, -0.7472],\n",
      "         [-0.8859, -0.3313,  8.7644,  ..., -0.4130, -0.3913, -0.6879],\n",
      "         [-0.7578, -0.6305,  8.8007,  ..., -0.5728, -0.1084, -0.5155],\n",
      "         ...,\n",
      "         [-0.8490, -0.5168,  8.8682,  ..., -0.3284, -0.2710, -0.6594],\n",
      "         [-0.9224, -0.3670,  8.9169,  ..., -0.5223, -0.3550, -0.4747],\n",
      "         [-0.7332, -0.2373,  8.6590,  ..., -0.5542, -0.2284, -0.6467]],\n",
      "\n",
      "        [[-0.3739, -0.1065,  8.4526,  ..., -0.2218,  0.1160, -0.1083],\n",
      "         [-0.7938, -0.3240,  9.0158,  ..., -0.5221, -0.2173, -0.6196],\n",
      "         [-0.8735, -0.3573,  8.9484,  ..., -0.7835, -0.2321, -0.6381],\n",
      "         ...,\n",
      "         [-0.7743, -0.3207,  8.7529,  ..., -0.3712, -0.3472, -0.8572],\n",
      "         [-0.7202, -0.4534,  8.8952,  ..., -0.1808, -0.4625, -0.5711],\n",
      "         [-0.8626, -0.2594,  8.8727,  ..., -0.4989, -0.2366, -0.7453]],\n",
      "\n",
      "        [[-0.5510, -0.6451,  8.6553,  ..., -0.0117, -0.4143, -1.0060],\n",
      "         [-0.7892, -0.4706,  8.8926,  ..., -0.4145, -0.5101, -0.6357],\n",
      "         [-0.9372, -0.3985,  8.8152,  ..., -0.4914, -0.4738, -0.5962],\n",
      "         ...,\n",
      "         [-0.6529, -0.7510,  8.8091,  ..., -0.3547, -0.2814, -0.5914],\n",
      "         [-0.7637, -0.3556,  8.9792,  ..., -0.4494, -0.1556, -0.7117],\n",
      "         [-0.6531, -0.3295,  8.8509,  ..., -0.3017, -0.5316, -0.8308]]],\n",
      "       device='cuda:0', grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([ 9.8302, 11.2870, 10.2229,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0', grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(2.9529, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n",
      "n_samples: 192\n",
      "-------Y: tensor([[   1,  334,    2,  ...,    0,    0,    0],\n",
      "        [   1, 1744,    2,  ...,    0,    0,    0],\n",
      "        [   1,    9,   56,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1, 2330,   25,  ...,    0,    0,    0],\n",
      "        [   1,  542,  124,  ...,    0,    0,    0],\n",
      "        [   1, 2186, 1228,  ...,    0,    0,    0]])\n",
      "Y[63]: tensor([   1, 2186, 1228,    7,  270,   92,    2,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "-------T: tensor([[    1, 22885, 12412,  ...,     0,     0,     0],\n",
      "        [    1,  1619,     4,  ...,     0,     0,     0],\n",
      "        [    1,     3,  2023,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  4521,    61,  ...,     0,     0,     0],\n",
      "        [    1,   149,   235,  ...,     0,     0,     0],\n",
      "        [    1, 28255,     7,  ...,     0,     0,     0]])\n",
      "T[63]: tensor([    1, 28255,     7,   847,  1482,   566,     5,   101,    21,  5053,\n",
      "            7,   250, 16902,     5, 11864,     4,    61,   302,   759,   302,\n",
      "           58,    22,     4,     3,   276,    51,   101,   672,  9515,     4,\n",
      "          141,    12,     3,     4,    16,   153,     5,   554,     4,  3217,\n",
      "            9,   110,    45,    32,    24,     4, 20824,     7,     4,   141,\n",
      "           12,  1678,   556,  2375,    83,  6563,     2,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[-0.0584, -2.0870,  0.2466,  ...,  0.6018, -1.8012,  0.9073],\n",
      "         [ 0.8213, -1.9598,  0.1153,  ...,  0.3257, -1.6965,  1.3913],\n",
      "         [ 0.3948, -1.9942,  1.1822,  ..., -0.0330, -2.0964,  1.0060],\n",
      "         ...,\n",
      "         [ 0.5165, -1.3918,  0.1572,  ..., -0.0297, -1.7616,  0.8531],\n",
      "         [ 0.1550, -1.2975,  0.0832,  ..., -0.1923, -1.7166,  1.1885],\n",
      "         [ 0.0784, -0.7614,  0.6565,  ..., -0.0243, -1.6669,  1.1762]],\n",
      "\n",
      "        [[-0.0955, -2.0821,  0.1437,  ...,  0.5562, -1.5745,  0.5779],\n",
      "         [ 0.7586, -1.4382,  0.1986,  ...,  0.1072, -1.5134,  1.1515],\n",
      "         [ 0.8750, -2.4445,  0.5743,  ...,  0.7467, -1.5116,  1.2423],\n",
      "         ...,\n",
      "         [ 0.2810, -0.9467, -0.0392,  ..., -0.0797, -1.6603,  1.0437],\n",
      "         [ 0.2089, -1.3596,  0.5150,  ...,  0.1441, -1.7164,  0.8166],\n",
      "         [ 0.1336, -0.7466,  0.5585,  ..., -0.0384, -1.7145,  1.3018]],\n",
      "\n",
      "        [[ 0.6795, -2.5240,  0.2225,  ..., -0.0470, -1.8147,  0.8244],\n",
      "         [ 0.6985, -1.0988,  0.0879,  ...,  0.3883, -0.7572,  0.8740],\n",
      "         [ 0.8466, -2.1404,  0.2485,  ...,  0.8549, -0.7962,  1.2830],\n",
      "         ...,\n",
      "         [ 0.4702, -1.5822,  0.1522,  ..., -0.0657, -1.6501,  0.9504],\n",
      "         [ 0.2773, -1.1787,  0.4137,  ..., -0.3221, -1.7517,  1.2535],\n",
      "         [ 0.0286, -1.2039,  0.1290,  ...,  0.0675, -1.2728,  0.8612]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0593, -2.3223,  0.1204,  ...,  0.4112, -1.6720,  0.7720],\n",
      "         [ 0.9647, -1.9282,  0.2170,  ..., -0.4089, -1.4050,  1.3106],\n",
      "         [ 1.2289, -2.3825,  0.8329,  ...,  0.5936, -2.5521,  1.3666],\n",
      "         ...,\n",
      "         [ 0.6093, -1.3134,  0.4035,  ..., -0.0601, -1.7366,  1.3527],\n",
      "         [ 0.0724, -1.1885,  0.4925,  ..., -0.4569, -1.6023,  1.2395],\n",
      "         [ 0.1708, -0.9373,  0.5825,  ..., -0.0998, -1.5826,  1.3933]],\n",
      "\n",
      "        [[ 0.1135, -2.1138,  0.2609,  ...,  0.5793, -1.6855,  1.0318],\n",
      "         [ 0.5398, -2.0494,  0.6799,  ...,  0.0645, -2.1730,  1.1227],\n",
      "         [ 1.2889, -2.2872,  0.1637,  ...,  0.1818, -2.4188,  1.6075],\n",
      "         ...,\n",
      "         [ 0.2747, -1.3132,  0.1284,  ..., -0.0670, -1.6297,  1.3138],\n",
      "         [ 0.0144, -1.0919,  0.2668,  ..., -0.5651, -1.6637,  1.4566],\n",
      "         [ 0.3368, -0.9025,  0.6868,  ..., -0.1200, -1.6810,  1.0708]],\n",
      "\n",
      "        [[-0.1258, -2.0346,  0.3438,  ...,  0.5620, -1.7472,  0.8943],\n",
      "         [ 1.1999, -1.8812,  0.8968,  ..., -0.2740, -1.4860,  1.6074],\n",
      "         [ 0.2269, -1.6098,  0.6490,  ..., -0.6141, -1.3922,  1.6554],\n",
      "         ...,\n",
      "         [ 0.5471, -1.2480,  0.1377,  ...,  0.0354, -1.5290,  0.7228],\n",
      "         [ 0.4609, -0.9229,  0.4117,  ..., -0.0819, -1.8224,  0.6711],\n",
      "         [ 0.0735, -0.7348,  0.9685,  ..., -0.3148, -1.8567,  1.5085]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n",
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[-7.0789e-01, -3.3763e-01,  7.4684e+00,  ..., -4.7808e-02,\n",
      "          -2.3631e-01, -9.0275e-01],\n",
      "         [-8.9303e-01, -5.2885e-01,  7.8553e+00,  ...,  5.4307e-01,\n",
      "          -4.3712e-01, -8.2020e-01],\n",
      "         [-3.2756e-01, -1.2159e-01,  7.7641e+00,  ...,  1.8289e-01,\n",
      "           2.8256e-01, -4.6121e-01],\n",
      "         ...,\n",
      "         [-8.4876e-01, -5.5147e-01,  7.9892e+00,  ..., -1.2168e-01,\n",
      "          -2.4409e-01, -7.8144e-01],\n",
      "         [-7.1750e-01, -4.8559e-01,  7.9183e+00,  ...,  6.8195e-03,\n",
      "          -3.9457e-01, -1.0392e+00],\n",
      "         [-7.1167e-01, -2.2608e-01,  7.9990e+00,  ..., -2.1757e-01,\n",
      "          -1.5637e-01, -1.0982e+00]],\n",
      "\n",
      "        [[-5.1336e-01, -3.0271e-02,  7.5239e+00,  ..., -2.8536e-01,\n",
      "          -3.8818e-01, -9.1280e-01],\n",
      "         [-3.2141e-01, -3.7350e-01,  7.9409e+00,  ...,  4.7193e-02,\n",
      "           1.5336e-01, -1.1159e+00],\n",
      "         [-3.2592e-01, -4.3496e-01,  7.8593e+00,  ...,  2.9420e-01,\n",
      "           2.2354e-01, -4.9476e-01],\n",
      "         ...,\n",
      "         [-9.1316e-01, -5.7935e-01,  8.0146e+00,  ..., -1.9799e-01,\n",
      "          -1.7656e-01, -6.9932e-01],\n",
      "         [-6.6696e-01, -4.0004e-01,  7.9239e+00,  ..., -1.8979e-01,\n",
      "          -1.6053e-01, -1.0218e+00],\n",
      "         [-6.7368e-01, -3.7614e-01,  7.9250e+00,  ..., -4.6615e-02,\n",
      "          -2.5173e-01, -8.7726e-01]],\n",
      "\n",
      "        [[-3.9732e-01, -3.7480e-01,  7.2771e+00,  ..., -1.6193e-01,\n",
      "          -1.7415e-01, -1.0615e+00],\n",
      "         [-6.3934e-01, -3.8216e-01,  7.8821e+00,  ..., -1.9809e-02,\n",
      "           9.5603e-02, -6.4535e-01],\n",
      "         [-5.0995e-01, -3.7717e-01,  7.9125e+00,  ..., -1.0156e-01,\n",
      "           2.4323e-01, -7.8641e-01],\n",
      "         ...,\n",
      "         [-7.8922e-01, -5.0830e-01,  7.8807e+00,  ..., -2.2670e-02,\n",
      "          -2.8969e-01, -1.0106e+00],\n",
      "         [-7.3871e-01, -2.9892e-01,  7.9757e+00,  ..., -1.2351e-01,\n",
      "          -3.1799e-01, -8.2536e-01],\n",
      "         [-7.0523e-01, -3.6761e-01,  7.9635e+00,  ..., -1.2743e-01,\n",
      "          -1.8602e-01, -6.7612e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.9846e-01, -3.2175e-01,  7.2506e+00,  ..., -2.2809e-01,\n",
      "          -2.2195e-01, -1.1279e+00],\n",
      "         [-3.8625e-02, -4.5540e-01,  7.5556e+00,  ..., -6.1331e-02,\n",
      "          -1.6088e-01, -9.2833e-01],\n",
      "         [-4.0763e-01, -5.9060e-01,  7.6370e+00,  ...,  3.1418e-01,\n",
      "          -5.4540e-02, -1.0893e+00],\n",
      "         ...,\n",
      "         [-7.0848e-01, -5.2751e-01,  7.9536e+00,  ..., -8.7372e-02,\n",
      "          -3.3578e-01, -7.3179e-01],\n",
      "         [-6.5523e-01, -4.5744e-01,  8.0251e+00,  ..., -1.1656e-01,\n",
      "          -1.9019e-01, -9.7948e-01],\n",
      "         [-6.7974e-01, -3.6321e-01,  7.9456e+00,  ...,  3.4861e-02,\n",
      "          -2.7877e-01, -1.0529e+00]],\n",
      "\n",
      "        [[-6.2322e-01, -3.2996e-01,  7.2651e+00,  ..., -2.8500e-01,\n",
      "          -3.4086e-01, -9.9605e-01],\n",
      "         [-5.6703e-01, -4.4717e-01,  7.3818e+00,  ...,  7.5631e-02,\n",
      "          -7.7578e-02, -9.1591e-01],\n",
      "         [-7.4200e-01, -1.7189e-01,  7.6454e+00,  ..., -3.8156e-02,\n",
      "          -1.7879e-01, -8.7994e-01],\n",
      "         ...,\n",
      "         [-9.0049e-01, -4.6422e-01,  7.8304e+00,  ..., -1.0133e-01,\n",
      "          -2.1675e-01, -8.9643e-01],\n",
      "         [-7.0813e-01, -5.1108e-01,  7.8853e+00,  ..., -1.9562e-01,\n",
      "          -1.0453e-01, -9.1492e-01],\n",
      "         [-7.3993e-01, -3.5451e-01,  7.9678e+00,  ..., -5.7583e-02,\n",
      "           1.0203e-01, -1.0331e+00]],\n",
      "\n",
      "        [[-6.5649e-01, -2.0827e-01,  7.1392e+00,  ..., -2.1996e-01,\n",
      "          -9.6384e-02, -9.4005e-01],\n",
      "         [-7.4273e-01, -4.0614e-02,  7.8964e+00,  ..., -2.1529e-01,\n",
      "           4.7385e-02, -6.8736e-01],\n",
      "         [-4.7646e-01, -2.5534e-01,  7.9400e+00,  ...,  1.4734e-01,\n",
      "          -2.2382e-01, -7.1234e-01],\n",
      "         ...,\n",
      "         [-8.2961e-01, -5.2210e-01,  7.7849e+00,  ..., -2.6181e-01,\n",
      "          -1.4639e-01, -8.3183e-01],\n",
      "         [-7.5983e-01, -4.9034e-01,  7.8992e+00,  ..., -2.2045e-01,\n",
      "          -3.3508e-01, -9.3348e-01],\n",
      "         [-6.0326e-01, -3.9364e-01,  7.8933e+00,  ..., -5.4121e-02,\n",
      "          -2.0290e-01, -1.0086e+00]]], device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [ 334, 1744,    9,  ..., 2330,  542, 2186],\n",
      "        [   2,    2,   56,  ...,   25,  124, 1228],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs.tr tensor([[[-7.0789e-01, -3.3763e-01,  7.4684e+00,  ..., -4.7808e-02,\n",
      "          -2.3631e-01, -9.0275e-01],\n",
      "         [-5.1336e-01, -3.0271e-02,  7.5239e+00,  ..., -2.8536e-01,\n",
      "          -3.8818e-01, -9.1280e-01],\n",
      "         [-3.9732e-01, -3.7480e-01,  7.2771e+00,  ..., -1.6193e-01,\n",
      "          -1.7415e-01, -1.0615e+00],\n",
      "         ...,\n",
      "         [-5.9846e-01, -3.2175e-01,  7.2506e+00,  ..., -2.2809e-01,\n",
      "          -2.2195e-01, -1.1279e+00],\n",
      "         [-6.2322e-01, -3.2996e-01,  7.2651e+00,  ..., -2.8500e-01,\n",
      "          -3.4086e-01, -9.9605e-01],\n",
      "         [-6.5649e-01, -2.0827e-01,  7.1392e+00,  ..., -2.1996e-01,\n",
      "          -9.6384e-02, -9.4005e-01]],\n",
      "\n",
      "        [[-8.9303e-01, -5.2885e-01,  7.8553e+00,  ...,  5.4307e-01,\n",
      "          -4.3712e-01, -8.2020e-01],\n",
      "         [-3.2141e-01, -3.7350e-01,  7.9409e+00,  ...,  4.7193e-02,\n",
      "           1.5336e-01, -1.1159e+00],\n",
      "         [-6.3934e-01, -3.8216e-01,  7.8821e+00,  ..., -1.9809e-02,\n",
      "           9.5603e-02, -6.4535e-01],\n",
      "         ...,\n",
      "         [-3.8625e-02, -4.5540e-01,  7.5556e+00,  ..., -6.1331e-02,\n",
      "          -1.6088e-01, -9.2833e-01],\n",
      "         [-5.6703e-01, -4.4717e-01,  7.3818e+00,  ...,  7.5631e-02,\n",
      "          -7.7578e-02, -9.1591e-01],\n",
      "         [-7.4273e-01, -4.0614e-02,  7.8964e+00,  ..., -2.1529e-01,\n",
      "           4.7385e-02, -6.8736e-01]],\n",
      "\n",
      "        [[-3.2756e-01, -1.2159e-01,  7.7641e+00,  ...,  1.8289e-01,\n",
      "           2.8256e-01, -4.6121e-01],\n",
      "         [-3.2592e-01, -4.3496e-01,  7.8593e+00,  ...,  2.9420e-01,\n",
      "           2.2354e-01, -4.9476e-01],\n",
      "         [-5.0995e-01, -3.7717e-01,  7.9125e+00,  ..., -1.0156e-01,\n",
      "           2.4323e-01, -7.8641e-01],\n",
      "         ...,\n",
      "         [-4.0763e-01, -5.9060e-01,  7.6370e+00,  ...,  3.1418e-01,\n",
      "          -5.4540e-02, -1.0893e+00],\n",
      "         [-7.4200e-01, -1.7189e-01,  7.6454e+00,  ..., -3.8156e-02,\n",
      "          -1.7879e-01, -8.7994e-01],\n",
      "         [-4.7646e-01, -2.5534e-01,  7.9400e+00,  ...,  1.4734e-01,\n",
      "          -2.2382e-01, -7.1234e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-8.4876e-01, -5.5147e-01,  7.9892e+00,  ..., -1.2168e-01,\n",
      "          -2.4409e-01, -7.8144e-01],\n",
      "         [-9.1316e-01, -5.7935e-01,  8.0146e+00,  ..., -1.9799e-01,\n",
      "          -1.7656e-01, -6.9932e-01],\n",
      "         [-7.8922e-01, -5.0830e-01,  7.8807e+00,  ..., -2.2670e-02,\n",
      "          -2.8969e-01, -1.0106e+00],\n",
      "         ...,\n",
      "         [-7.0848e-01, -5.2751e-01,  7.9536e+00,  ..., -8.7372e-02,\n",
      "          -3.3578e-01, -7.3179e-01],\n",
      "         [-9.0049e-01, -4.6422e-01,  7.8304e+00,  ..., -1.0133e-01,\n",
      "          -2.1675e-01, -8.9643e-01],\n",
      "         [-8.2961e-01, -5.2210e-01,  7.7849e+00,  ..., -2.6181e-01,\n",
      "          -1.4639e-01, -8.3183e-01]],\n",
      "\n",
      "        [[-7.1750e-01, -4.8559e-01,  7.9183e+00,  ...,  6.8195e-03,\n",
      "          -3.9457e-01, -1.0392e+00],\n",
      "         [-6.6696e-01, -4.0004e-01,  7.9239e+00,  ..., -1.8979e-01,\n",
      "          -1.6053e-01, -1.0218e+00],\n",
      "         [-7.3871e-01, -2.9892e-01,  7.9757e+00,  ..., -1.2351e-01,\n",
      "          -3.1799e-01, -8.2536e-01],\n",
      "         ...,\n",
      "         [-6.5523e-01, -4.5744e-01,  8.0251e+00,  ..., -1.1656e-01,\n",
      "          -1.9019e-01, -9.7948e-01],\n",
      "         [-7.0813e-01, -5.1108e-01,  7.8853e+00,  ..., -1.9562e-01,\n",
      "          -1.0453e-01, -9.1492e-01],\n",
      "         [-7.5983e-01, -4.9034e-01,  7.8992e+00,  ..., -2.2045e-01,\n",
      "          -3.3508e-01, -9.3348e-01]],\n",
      "\n",
      "        [[-7.1167e-01, -2.2608e-01,  7.9990e+00,  ..., -2.1757e-01,\n",
      "          -1.5637e-01, -1.0982e+00],\n",
      "         [-6.7368e-01, -3.7614e-01,  7.9250e+00,  ..., -4.6615e-02,\n",
      "          -2.5173e-01, -8.7726e-01],\n",
      "         [-7.0523e-01, -3.6761e-01,  7.9635e+00,  ..., -1.2743e-01,\n",
      "          -1.8602e-01, -6.7612e-01],\n",
      "         ...,\n",
      "         [-6.7974e-01, -3.6321e-01,  7.9456e+00,  ...,  3.4861e-02,\n",
      "          -2.7877e-01, -1.0529e+00],\n",
      "         [-7.3993e-01, -3.5451e-01,  7.9678e+00,  ..., -5.7583e-02,\n",
      "           1.0203e-01, -1.0331e+00],\n",
      "         [-6.0326e-01, -3.9364e-01,  7.8933e+00,  ..., -5.4121e-02,\n",
      "          -2.0290e-01, -1.0086e+00]]], device='cuda:0',\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([11.5642,  9.7778,  5.8420,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0', grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(3.0650, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n",
      "n_samples: 256\n",
      "-------Y: tensor([[    1,     9,   143,  ...,     0,     0,     0],\n",
      "        [    1,   572,    30,  ...,     0,     0,     0],\n",
      "        [    1,  1249,     6,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  1697,     3,  ...,     0,     0,     0],\n",
      "        [    1, 22711,     5,  ...,     2,     0,     0],\n",
      "        [    1,     9,    12,  ...,     0,     0,     0]])\n",
      "Y[63]: tensor([    1,     9,    12, 10992, 15159,     6,     9,   141,     3,     2,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "-------T: tensor([[   1,    3,    4,  ...,    0,    0,    0],\n",
      "        [   1,  294,  533,  ...,    0,    0,    0],\n",
      "        [   1,  570,  346,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1, 4563,    4,  ...,    0,    0,    0],\n",
      "        [   1,  103,  899,  ...,    0,    0,    0],\n",
      "        [   1, 1060,   94,  ...,    0,    0,    0]])\n",
      "T[63]: tensor([    1,  1060,    94,    42,    12,  1254,    43,    73,    49,     9,\n",
      "            3,     5,     4,   889,    30,  1254,    43,     6,    13,  1073,\n",
      "            7,  2717,    39, 22756,    23,  2700,  5495,    73,   546,  2070,\n",
      "            3,     5,     4,   143,    12, 14936,   167,   231,    21,  4396,\n",
      "            4,  2126,    94,    13,    50,   754,  3255,  1541,     4, 18121,\n",
      "         2196,    13,     4,  1663,    19,     3, 25250,    25,     6,     3,\n",
      "            3,  2491,     4,     3,    12, 17461,     3,     5,  1094,     4,\n",
      "          846,    72, 20600,   187,    20,    11,     2,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[-0.0094, -2.0483,  0.1689,  ...,  0.7889, -1.6396,  0.9335],\n",
      "         [ 0.6307, -1.1636,  0.3227,  ...,  0.4833, -1.1490,  0.9523],\n",
      "         [ 0.8163, -1.5836,  0.3646,  ...,  0.9324, -1.5826,  1.2409],\n",
      "         ...,\n",
      "         [ 0.5664, -1.0524,  0.2146,  ...,  0.2482, -1.8626,  1.0875],\n",
      "         [ 0.0973, -1.3023,  0.3083,  ...,  0.1553, -1.8964,  1.1376],\n",
      "         [ 0.0582, -1.0191,  0.3624,  ...,  0.3313, -1.6072,  0.5736]],\n",
      "\n",
      "        [[-0.0043, -2.1343,  0.0961,  ...,  0.7271, -1.4835,  0.4772],\n",
      "         [ 0.8931, -1.4131,  0.5617,  ...,  0.8176, -1.6019,  1.0934],\n",
      "         [-0.2429, -2.1318,  0.3862,  ...,  0.6395, -1.8362,  0.6418],\n",
      "         ...,\n",
      "         [ 0.5168, -0.9485,  0.1890,  ...,  0.3858, -1.5314,  1.2144],\n",
      "         [ 0.1476, -1.2945,  0.0882,  ..., -0.0904, -1.7001,  1.1580],\n",
      "         [-0.0043, -0.8063,  0.6270,  ...,  0.1210, -1.8543,  0.8474]],\n",
      "\n",
      "        [[-0.0629, -1.9610,  0.2072,  ...,  0.8464, -2.0742,  0.8223],\n",
      "         [ 0.6410, -1.9601,  0.2475,  ...,  0.8518, -2.1010,  1.1678],\n",
      "         [ 0.9087, -2.1685,  0.6451,  ...,  0.4196, -1.6147,  1.2834],\n",
      "         ...,\n",
      "         [ 0.3861, -1.3548,  0.0370,  ..., -0.2049, -1.6862,  1.1394],\n",
      "         [ 0.2332, -1.6175,  0.4306,  ...,  0.0325, -1.7963,  0.4370],\n",
      "         [ 0.2599, -0.8904,  0.2856,  ...,  0.1754, -1.6209,  1.0163]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.4307, -2.0794,  0.1178,  ...,  0.5376, -1.9261,  0.5564],\n",
      "         [ 1.0244, -1.4361,  0.1532,  ...,  0.4330, -1.6029,  1.2014],\n",
      "         [ 0.9979, -2.3574,  0.4130,  ...,  0.8484, -2.1171,  1.0908],\n",
      "         ...,\n",
      "         [ 0.4962, -1.4193,  0.2578,  ...,  0.0275, -1.6252,  0.6292],\n",
      "         [ 0.1601, -1.4844,  0.2035,  ..., -0.0363, -1.7526,  1.0312],\n",
      "         [ 0.2099, -0.9931,  0.5747,  ...,  0.1712, -1.6215,  1.1409]],\n",
      "\n",
      "        [[ 0.0786, -2.2116,  0.0058,  ...,  0.6401, -1.4918,  0.8340],\n",
      "         [ 0.4896, -1.5157,  0.3814,  ...,  0.3209, -1.8165,  0.7151],\n",
      "         [ 0.6354, -1.8805,  0.3948,  ...,  0.5566, -2.0369,  0.2968],\n",
      "         ...,\n",
      "         [ 0.5383, -1.1574,  0.1443,  ..., -0.1658, -1.7532,  1.0115],\n",
      "         [ 0.4753, -1.8009,  0.4259,  ...,  0.1060, -1.6492,  0.9459],\n",
      "         [-0.2441, -1.9340,  0.6886,  ...,  0.1045, -1.6714,  1.3359]],\n",
      "\n",
      "        [[ 0.2028, -2.0552,  0.1651,  ...,  0.7174, -1.6561,  0.7865],\n",
      "         [ 0.9164, -1.3523,  0.9073,  ...,  0.4836, -1.7233,  1.1081],\n",
      "         [ 0.2706, -2.0159,  0.3111,  ..., -0.0852, -1.7897,  0.6142],\n",
      "         ...,\n",
      "         [ 0.8807, -1.0309,  0.0396,  ...,  0.0306, -1.9183,  1.0262],\n",
      "         [ 0.5771, -1.2673,  0.5913,  ..., -0.1409, -1.6135,  1.2137],\n",
      "         [ 0.3616, -0.8817,  0.4945,  ...,  0.0271, -1.8216,  1.2985]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[-9.8468e-01, -3.7511e-01,  7.1199e+00,  ..., -3.0289e-01,\n",
      "          -2.6763e-01, -9.2987e-01],\n",
      "         [-6.2650e-01, -2.1564e-01,  7.7425e+00,  ..., -9.7867e-02,\n",
      "           1.3400e-01, -1.0163e+00],\n",
      "         [-4.3887e-01, -4.5121e-01,  7.5758e+00,  ..., -4.7280e-02,\n",
      "          -1.2906e-01, -1.1490e+00],\n",
      "         ...,\n",
      "         [-6.0577e-01, -3.6864e-01,  7.7148e+00,  ...,  7.7070e-02,\n",
      "           2.8005e-01, -8.7653e-01],\n",
      "         [-8.8333e-01, -5.1073e-01,  7.8176e+00,  ..., -4.3436e-01,\n",
      "          -1.3004e-01, -1.1494e+00],\n",
      "         [-7.7899e-01, -4.7962e-01,  7.8150e+00,  ..., -1.3929e-01,\n",
      "          -1.5982e-01, -1.0545e+00]],\n",
      "\n",
      "        [[-7.4930e-01, -4.3174e-01,  6.9782e+00,  ..., -2.3043e-01,\n",
      "          -2.1008e-01, -1.0834e+00],\n",
      "         [-6.4861e-01, -5.3552e-01,  7.4993e+00,  ..., -4.7578e-02,\n",
      "          -1.0395e-01, -1.1355e+00],\n",
      "         [-4.0247e-01, -5.5831e-01,  7.7061e+00,  ..., -1.5934e-01,\n",
      "          -7.3069e-02, -1.1298e+00],\n",
      "         ...,\n",
      "         [-8.9488e-01, -4.4714e-01,  7.6479e+00,  ..., -2.2391e-01,\n",
      "          -9.2475e-02, -1.1428e+00],\n",
      "         [-7.7970e-01, -6.2983e-01,  7.7820e+00,  ..., -1.2633e-01,\n",
      "          -1.1303e-01, -1.1365e+00],\n",
      "         [-7.0713e-01, -5.9273e-01,  7.8306e+00,  ..., -9.0362e-02,\n",
      "          -1.4893e-01, -1.0325e+00]],\n",
      "\n",
      "        [[-8.7416e-01, -3.3052e-01,  7.0394e+00,  ..., -1.9754e-01,\n",
      "          -1.3820e-01, -1.0554e+00],\n",
      "         [-6.2436e-01, -5.1701e-01,  7.3666e+00,  ..., -6.4589e-02,\n",
      "           1.5523e-01, -8.3978e-01],\n",
      "         [-5.5506e-01, -8.1297e-01,  7.2393e+00,  ..., -5.0484e-02,\n",
      "          -1.8277e-02, -1.0315e+00],\n",
      "         ...,\n",
      "         [-6.5318e-01, -6.9895e-01,  7.7660e+00,  ..., -1.8677e-01,\n",
      "          -1.3958e-01, -1.0180e+00],\n",
      "         [-8.4940e-01, -6.5438e-01,  7.6968e+00,  ..., -2.2577e-01,\n",
      "          -1.6214e-01, -1.0157e+00],\n",
      "         [-7.3677e-01, -5.5847e-01,  7.7389e+00,  ..., -5.7387e-02,\n",
      "          -7.8491e-02, -1.0568e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.7551e-01, -3.0340e-01,  7.0884e+00,  ..., -2.9874e-01,\n",
      "          -1.9044e-01, -9.6042e-01],\n",
      "         [-7.0527e-01,  8.9359e-02,  7.6340e+00,  ..., -1.3570e-01,\n",
      "          -2.2852e-01, -8.9824e-01],\n",
      "         [-7.7230e-01, -3.9601e-01,  7.8332e+00,  ...,  4.5720e-02,\n",
      "          -1.3173e-01, -8.6219e-01],\n",
      "         ...,\n",
      "         [-8.1472e-01, -5.0600e-01,  7.6374e+00,  ..., -2.6426e-01,\n",
      "           4.2470e-02, -1.1551e+00],\n",
      "         [-6.4412e-01, -6.1018e-01,  7.7407e+00,  ..., -1.3454e-01,\n",
      "          -7.2636e-02, -1.0174e+00],\n",
      "         [-6.1736e-01, -5.2349e-01,  7.7173e+00,  ..., -1.5422e-01,\n",
      "          -1.6416e-01, -1.0584e+00]],\n",
      "\n",
      "        [[-6.0006e-01, -1.9053e-01,  7.0766e+00,  ..., -2.4782e-01,\n",
      "          -5.4961e-02, -1.0876e+00],\n",
      "         [-5.7892e-01, -4.8395e-01,  7.4352e+00,  ..., -2.7720e-02,\n",
      "           3.0709e-01, -1.1388e+00],\n",
      "         [-6.6712e-01, -5.8954e-01,  7.4763e+00,  ..., -1.3016e-01,\n",
      "          -9.7624e-02, -1.0977e+00],\n",
      "         ...,\n",
      "         [-7.5983e-01, -4.2804e-01,  7.9570e+00,  ..., -2.2918e-01,\n",
      "          -6.6449e-02, -1.0824e+00],\n",
      "         [-7.7303e-01, -2.2466e-01,  7.8493e+00,  ..., -1.2946e-01,\n",
      "           1.8750e-01, -8.1969e-01],\n",
      "         [-6.7002e-01, -6.9512e-01,  7.8273e+00,  ..., -6.7725e-02,\n",
      "          -1.2976e-01, -1.0646e+00]],\n",
      "\n",
      "        [[-5.9707e-01, -4.3759e-01,  6.9014e+00,  ..., -3.2972e-01,\n",
      "          -8.9925e-02, -1.1012e+00],\n",
      "         [-7.0253e-01, -4.9150e-01,  7.6868e+00,  ..., -7.8459e-02,\n",
      "           3.3527e-01, -7.6208e-01],\n",
      "         [-7.0899e-01, -1.7901e-01,  7.3520e+00,  ...,  6.4112e-02,\n",
      "          -5.9753e-03, -1.0784e+00],\n",
      "         ...,\n",
      "         [-5.7662e-01, -6.8280e-01,  7.8827e+00,  ..., -1.7655e-01,\n",
      "          -3.5977e-01, -1.1774e+00],\n",
      "         [-6.9342e-01, -6.3786e-01,  7.6639e+00,  ..., -9.9365e-02,\n",
      "          -2.0529e-01, -1.0534e+00],\n",
      "         [-7.7550e-01, -5.6046e-01,  7.7154e+00,  ..., -2.1702e-01,\n",
      "          -1.0295e-01, -1.2445e+00]]], device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    9,   572,  1249,  ...,  1697, 22711,     9],\n",
      "        [  143,    30,     6,  ...,     3,     5,    12],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,     0,     2,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n",
      "outs.tr tensor([[[-9.8468e-01, -3.7511e-01,  7.1199e+00,  ..., -3.0289e-01,\n",
      "          -2.6763e-01, -9.2987e-01],\n",
      "         [-7.4930e-01, -4.3174e-01,  6.9782e+00,  ..., -2.3043e-01,\n",
      "          -2.1008e-01, -1.0834e+00],\n",
      "         [-8.7416e-01, -3.3052e-01,  7.0394e+00,  ..., -1.9754e-01,\n",
      "          -1.3820e-01, -1.0554e+00],\n",
      "         ...,\n",
      "         [-6.7551e-01, -3.0340e-01,  7.0884e+00,  ..., -2.9874e-01,\n",
      "          -1.9044e-01, -9.6042e-01],\n",
      "         [-6.0006e-01, -1.9053e-01,  7.0766e+00,  ..., -2.4782e-01,\n",
      "          -5.4961e-02, -1.0876e+00],\n",
      "         [-5.9707e-01, -4.3759e-01,  6.9014e+00,  ..., -3.2972e-01,\n",
      "          -8.9925e-02, -1.1012e+00]],\n",
      "\n",
      "        [[-6.2650e-01, -2.1564e-01,  7.7425e+00,  ..., -9.7867e-02,\n",
      "           1.3400e-01, -1.0163e+00],\n",
      "         [-6.4861e-01, -5.3552e-01,  7.4993e+00,  ..., -4.7578e-02,\n",
      "          -1.0395e-01, -1.1355e+00],\n",
      "         [-6.2436e-01, -5.1701e-01,  7.3666e+00,  ..., -6.4589e-02,\n",
      "           1.5523e-01, -8.3978e-01],\n",
      "         ...,\n",
      "         [-7.0527e-01,  8.9359e-02,  7.6340e+00,  ..., -1.3570e-01,\n",
      "          -2.2852e-01, -8.9824e-01],\n",
      "         [-5.7892e-01, -4.8395e-01,  7.4352e+00,  ..., -2.7720e-02,\n",
      "           3.0709e-01, -1.1388e+00],\n",
      "         [-7.0253e-01, -4.9150e-01,  7.6868e+00,  ..., -7.8459e-02,\n",
      "           3.3527e-01, -7.6208e-01]],\n",
      "\n",
      "        [[-4.3887e-01, -4.5121e-01,  7.5758e+00,  ..., -4.7280e-02,\n",
      "          -1.2906e-01, -1.1490e+00],\n",
      "         [-4.0247e-01, -5.5831e-01,  7.7061e+00,  ..., -1.5934e-01,\n",
      "          -7.3069e-02, -1.1298e+00],\n",
      "         [-5.5506e-01, -8.1297e-01,  7.2393e+00,  ..., -5.0484e-02,\n",
      "          -1.8277e-02, -1.0315e+00],\n",
      "         ...,\n",
      "         [-7.7230e-01, -3.9601e-01,  7.8332e+00,  ...,  4.5720e-02,\n",
      "          -1.3173e-01, -8.6219e-01],\n",
      "         [-6.6712e-01, -5.8954e-01,  7.4763e+00,  ..., -1.3016e-01,\n",
      "          -9.7624e-02, -1.0977e+00],\n",
      "         [-7.0899e-01, -1.7901e-01,  7.3520e+00,  ...,  6.4112e-02,\n",
      "          -5.9753e-03, -1.0784e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.0577e-01, -3.6864e-01,  7.7148e+00,  ...,  7.7070e-02,\n",
      "           2.8005e-01, -8.7653e-01],\n",
      "         [-8.9488e-01, -4.4714e-01,  7.6479e+00,  ..., -2.2391e-01,\n",
      "          -9.2475e-02, -1.1428e+00],\n",
      "         [-6.5318e-01, -6.9895e-01,  7.7660e+00,  ..., -1.8677e-01,\n",
      "          -1.3958e-01, -1.0180e+00],\n",
      "         ...,\n",
      "         [-8.1472e-01, -5.0600e-01,  7.6374e+00,  ..., -2.6426e-01,\n",
      "           4.2470e-02, -1.1551e+00],\n",
      "         [-7.5983e-01, -4.2804e-01,  7.9570e+00,  ..., -2.2918e-01,\n",
      "          -6.6449e-02, -1.0824e+00],\n",
      "         [-5.7662e-01, -6.8280e-01,  7.8827e+00,  ..., -1.7655e-01,\n",
      "          -3.5977e-01, -1.1774e+00]],\n",
      "\n",
      "        [[-8.8333e-01, -5.1073e-01,  7.8176e+00,  ..., -4.3436e-01,\n",
      "          -1.3004e-01, -1.1494e+00],\n",
      "         [-7.7970e-01, -6.2983e-01,  7.7820e+00,  ..., -1.2633e-01,\n",
      "          -1.1303e-01, -1.1365e+00],\n",
      "         [-8.4940e-01, -6.5438e-01,  7.6968e+00,  ..., -2.2577e-01,\n",
      "          -1.6214e-01, -1.0157e+00],\n",
      "         ...,\n",
      "         [-6.4412e-01, -6.1018e-01,  7.7407e+00,  ..., -1.3454e-01,\n",
      "          -7.2636e-02, -1.0174e+00],\n",
      "         [-7.7303e-01, -2.2466e-01,  7.8493e+00,  ..., -1.2946e-01,\n",
      "           1.8750e-01, -8.1969e-01],\n",
      "         [-6.9342e-01, -6.3786e-01,  7.6639e+00,  ..., -9.9365e-02,\n",
      "          -2.0529e-01, -1.0534e+00]],\n",
      "\n",
      "        [[-7.7899e-01, -4.7962e-01,  7.8150e+00,  ..., -1.3929e-01,\n",
      "          -1.5982e-01, -1.0545e+00],\n",
      "         [-7.0713e-01, -5.9273e-01,  7.8306e+00,  ..., -9.0362e-02,\n",
      "          -1.4893e-01, -1.0325e+00],\n",
      "         [-7.3677e-01, -5.5847e-01,  7.7389e+00,  ..., -5.7387e-02,\n",
      "          -7.8491e-02, -1.0568e+00],\n",
      "         ...,\n",
      "         [-6.1736e-01, -5.2349e-01,  7.7173e+00,  ..., -1.5422e-01,\n",
      "          -1.6416e-01, -1.0584e+00],\n",
      "         [-6.7002e-01, -6.9512e-01,  7.8273e+00,  ..., -6.7725e-02,\n",
      "          -1.2976e-01, -1.0646e+00],\n",
      "         [-7.7550e-01, -5.6046e-01,  7.7154e+00,  ..., -2.1702e-01,\n",
      "          -1.0295e-01, -1.2445e+00]]], device='cuda:0',\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([ 5.5054, 10.6670, 10.3479,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0', grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(2.8987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 320\n",
      "-------Y: tensor([[   1,   23, 1764,  ...,    0,    0,    0],\n",
      "        [   1, 1962, 2329,  ...,    0,    0,    0],\n",
      "        [   1,  597,   23,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,    3,    2,  ...,    0,    0,    0],\n",
      "        [   1,  103,    5,  ...,    0,    0,    0],\n",
      "        [   1,    3,    2,  ...,    0,    0,    0]])\n",
      "Y[63]: tensor([1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "-------T: tensor([[   1,   23, 1764,  ...,    0,    0,    0],\n",
      "        [   1,  999,    3,  ...,    0,    0,    0],\n",
      "        [   1,  261,    7,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,   33,    5,  ...,    0,    0,    0],\n",
      "        [   1,  818,  453,  ...,    0,    0,    0],\n",
      "        [   1,    3,    4,  ...,    0,    0,    0]])\n",
      "T[63]: tensor([   1,    3,    4, 6669,    4,    3,    4, 2435,    4,    3,    4,  328,\n",
      "           4,  151,    4,  125,    2,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[-2.7335e-02, -1.8028e+00,  1.5565e-01,  ...,  6.4320e-01,\n",
      "          -1.8979e+00,  7.6318e-01],\n",
      "         [ 9.1874e-01, -1.7519e+00,  5.1479e-01,  ...,  1.1630e+00,\n",
      "          -1.9590e+00,  4.3046e-01],\n",
      "         [ 8.3447e-01, -2.3053e+00,  4.6772e-01,  ...,  3.6635e-01,\n",
      "          -1.6308e+00,  8.3775e-01],\n",
      "         ...,\n",
      "         [ 2.9191e-01, -1.1703e+00, -3.5614e-02,  ...,  3.4354e-01,\n",
      "          -1.7389e+00,  9.0561e-01],\n",
      "         [ 3.5530e-01, -1.0122e+00,  1.6473e-01,  ...,  2.9733e-01,\n",
      "          -1.8576e+00,  1.0912e+00],\n",
      "         [ 2.3819e-01, -9.5230e-01,  3.3017e-01,  ...,  2.8873e-01,\n",
      "          -1.3601e+00,  1.0067e+00]],\n",
      "\n",
      "        [[ 1.0219e-01, -2.0616e+00,  7.4405e-03,  ...,  8.3950e-01,\n",
      "          -1.9150e+00,  6.9069e-01],\n",
      "         [ 7.0626e-01, -2.3120e+00,  2.8056e-01,  ...,  7.0071e-01,\n",
      "          -2.1125e+00,  7.6785e-01],\n",
      "         [ 7.6085e-01, -1.6917e+00,  1.3465e-01,  ...,  6.9672e-01,\n",
      "          -1.5249e+00,  8.9338e-01],\n",
      "         ...,\n",
      "         [ 5.7359e-01, -1.3279e+00, -2.2213e-01,  ...,  1.5396e-01,\n",
      "          -1.4776e+00,  1.1581e+00],\n",
      "         [ 5.3183e-01, -1.2890e+00,  1.5589e-01,  ...,  1.8216e-01,\n",
      "          -1.4719e+00,  8.5103e-01],\n",
      "         [ 2.3711e-01, -1.1719e+00,  4.6270e-01,  ...,  3.6973e-01,\n",
      "          -1.6693e+00,  1.2462e+00]],\n",
      "\n",
      "        [[ 1.2250e-01, -1.9036e+00, -1.8650e-02,  ...,  6.2049e-02,\n",
      "          -1.5853e+00,  8.2963e-01],\n",
      "         [ 1.6629e+00, -1.3463e+00,  4.2937e-01,  ...,  2.9590e-01,\n",
      "          -1.7583e+00,  7.1904e-01],\n",
      "         [ 2.3826e-01, -1.4726e+00,  2.4735e-01,  ..., -3.4845e-01,\n",
      "          -1.5159e+00,  1.4884e+00],\n",
      "         ...,\n",
      "         [ 6.3532e-01, -1.4491e+00, -1.9250e-01,  ...,  3.8682e-01,\n",
      "          -1.6298e+00,  1.0328e+00],\n",
      "         [ 2.7046e-01, -1.1549e+00,  2.9046e-01,  ...,  2.9309e-01,\n",
      "          -1.5184e+00,  8.8117e-01],\n",
      "         [ 3.2020e-01, -1.0256e+00,  4.3175e-01,  ...,  2.0393e-01,\n",
      "          -1.4526e+00,  1.1769e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.6122e-03, -2.0598e+00, -2.2565e-01,  ...,  6.7966e-01,\n",
      "          -1.6068e+00,  7.2494e-01],\n",
      "         [ 1.1327e+00, -1.4422e+00,  1.5600e-01,  ...,  1.0629e-01,\n",
      "          -1.7545e+00,  1.3658e+00],\n",
      "         [ 7.3704e-01, -1.8418e+00,  2.0884e-01,  ...,  4.3970e-01,\n",
      "          -1.5175e+00,  6.4986e-01],\n",
      "         ...,\n",
      "         [ 6.3004e-01, -1.4030e+00,  9.1870e-03,  ...,  3.0246e-01,\n",
      "          -1.7869e+00,  6.5001e-01],\n",
      "         [ 3.7385e-01, -1.2930e+00,  1.0722e-01,  ...,  7.5840e-02,\n",
      "          -1.1380e+00,  9.8218e-01],\n",
      "         [ 1.9672e-01, -1.1407e+00,  4.2257e-01,  ...,  2.7381e-01,\n",
      "          -1.4627e+00,  1.2295e+00]],\n",
      "\n",
      "        [[-5.4143e-02, -2.1208e+00,  1.3986e-01,  ...,  7.0717e-01,\n",
      "          -1.6622e+00,  5.4352e-01],\n",
      "         [ 7.9481e-01, -1.1591e+00,  5.2261e-01,  ...,  5.4801e-01,\n",
      "          -1.5087e+00,  1.0635e-01],\n",
      "         [ 8.6911e-01, -1.4338e+00,  1.9424e-01,  ...,  9.3687e-01,\n",
      "          -1.1995e+00,  1.4307e+00],\n",
      "         ...,\n",
      "         [ 3.5229e-01, -1.3027e+00,  3.1789e-01,  ...,  2.7266e-01,\n",
      "          -1.6195e+00,  8.6493e-01],\n",
      "         [ 3.0235e-01, -1.2652e+00,  3.3018e-01,  ..., -5.4420e-02,\n",
      "          -1.3834e+00,  1.0156e+00],\n",
      "         [ 2.4796e-01, -1.1071e+00,  3.9246e-01,  ...,  3.1372e-02,\n",
      "          -1.4768e+00,  9.4489e-01]],\n",
      "\n",
      "        [[ 3.2506e-02, -2.1373e+00, -1.0744e-01,  ...,  6.4069e-01,\n",
      "          -1.8825e+00,  7.6428e-01],\n",
      "         [ 9.8042e-01, -1.3843e+00, -9.9204e-02,  ...,  4.5669e-01,\n",
      "          -1.6156e+00,  9.8470e-01],\n",
      "         [ 7.9341e-01, -2.3365e+00,  8.8703e-02,  ...,  8.3488e-01,\n",
      "          -1.9293e+00,  1.1405e+00],\n",
      "         ...,\n",
      "         [ 4.9701e-01, -1.2230e+00,  6.0164e-04,  ...,  1.2291e-01,\n",
      "          -1.9222e+00,  4.1374e-01],\n",
      "         [-5.7705e-02, -1.3782e+00,  2.5260e-01,  ...,  1.5981e-01,\n",
      "          -1.2300e+00,  1.1975e+00],\n",
      "         [ 2.4693e-01, -1.2938e+00,  1.2455e-01,  ...,  2.7107e-01,\n",
      "          -1.7092e+00,  1.1394e+00]]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n",
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[-0.7017, -0.5310,  7.2711,  ..., -0.1230, -0.2783, -1.2039],\n",
      "         [-0.5966, -0.5082,  7.7879,  ...,  0.0402, -0.0161, -1.1516],\n",
      "         [-0.6172, -0.6087,  7.8301,  ..., -0.2962, -0.0505, -1.4283],\n",
      "         ...,\n",
      "         [-0.7963, -0.6653,  8.0849,  ..., -0.2980, -0.2130, -1.1345],\n",
      "         [-0.8802, -0.7365,  8.1695,  ..., -0.2810, -0.2623, -1.0804],\n",
      "         [-0.8997, -0.6548,  7.9939,  ..., -0.2287, -0.2810, -1.1462]],\n",
      "\n",
      "        [[-0.5522, -0.4688,  7.2623,  ..., -0.2889, -0.3102, -1.3352],\n",
      "         [-0.7037, -0.6040,  7.9192,  ..., -0.1253, -0.0630, -1.1228],\n",
      "         [-0.6447, -0.5318,  7.9596,  ...,  0.0455, -0.1707, -1.2146],\n",
      "         ...,\n",
      "         [-0.7695, -0.7062,  8.0989,  ..., -0.2250, -0.1996, -1.2136],\n",
      "         [-0.6652, -0.6694,  7.9934,  ...,  0.0487, -0.2447, -1.2146],\n",
      "         [-0.8022, -0.6712,  8.0088,  ..., -0.1951, -0.2619, -1.0504]],\n",
      "\n",
      "        [[-0.6510, -0.4771,  7.2141,  ..., -0.3753, -0.3174, -1.3882],\n",
      "         [-0.6123, -0.3809,  7.7536,  ...,  0.1259,  0.1516, -0.8212],\n",
      "         [-0.6350, -0.5046,  7.8544,  ..., -0.0451, -0.1602, -1.1406],\n",
      "         ...,\n",
      "         [-0.8136, -0.7372,  8.0241,  ..., -0.2878, -0.2953, -1.1045],\n",
      "         [-0.8238, -0.7577,  8.0976,  ..., -0.2013, -0.1517, -1.0415],\n",
      "         [-0.8675, -0.6870,  8.0459,  ..., -0.0763, -0.3480, -1.1142]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7982, -0.4820,  7.2374,  ..., -0.1853, -0.1657, -1.3591],\n",
      "         [-0.7939, -0.5953,  7.8853,  ...,  0.0904, -0.2879, -0.9200],\n",
      "         [-0.6696, -0.3268,  7.9792,  ...,  0.0792,  0.0848, -0.8335],\n",
      "         ...,\n",
      "         [-0.9445, -0.6567,  8.0773,  ..., -0.2969, -0.2933, -1.1891],\n",
      "         [-0.7499, -0.6607,  7.9921,  ..., -0.2380, -0.0630, -1.1028],\n",
      "         [-0.7888, -0.5804,  8.1321,  ..., -0.1624, -0.1513, -1.3096]],\n",
      "\n",
      "        [[-0.5521, -0.4899,  7.1893,  ..., -0.1516, -0.0212, -1.1911],\n",
      "         [-0.5299, -0.4509,  7.8303,  ...,  0.1261, -0.0236, -0.9113],\n",
      "         [-0.8361, -0.7131,  7.9025,  ..., -0.1907, -0.1095, -1.2252],\n",
      "         ...,\n",
      "         [-0.8988, -0.7488,  7.9970,  ..., -0.3742, -0.1525, -1.2848],\n",
      "         [-0.7880, -0.7005,  8.0208,  ..., -0.0158, -0.2317, -1.1851],\n",
      "         [-0.8380, -0.6997,  8.1109,  ..., -0.1185, -0.2700, -1.1732]],\n",
      "\n",
      "        [[-0.7913, -0.3478,  7.2788,  ..., -0.2848, -0.1305, -1.3208],\n",
      "         [-0.8235, -0.4682,  8.0287,  ...,  0.1389, -0.2113, -0.9835],\n",
      "         [-0.5740, -0.4746,  7.8991,  ..., -0.0363,  0.1880, -0.8705],\n",
      "         ...,\n",
      "         [-0.8930, -0.6870,  8.1242,  ..., -0.3821, -0.2395, -1.2340],\n",
      "         [-0.7668, -0.8042,  8.1026,  ..., -0.1685, -0.3916, -1.0911],\n",
      "         [-0.8716, -0.5599,  8.1951,  ..., -0.2182, -0.3535, -1.0809]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [  23, 1962,  597,  ...,    3,  103,    3],\n",
      "        [1764, 2329,   23,  ...,    2,    5,    2],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs.tr tensor([[[-0.7017, -0.5310,  7.2711,  ..., -0.1230, -0.2783, -1.2039],\n",
      "         [-0.5522, -0.4688,  7.2623,  ..., -0.2889, -0.3102, -1.3352],\n",
      "         [-0.6510, -0.4771,  7.2141,  ..., -0.3753, -0.3174, -1.3882],\n",
      "         ...,\n",
      "         [-0.7982, -0.4820,  7.2374,  ..., -0.1853, -0.1657, -1.3591],\n",
      "         [-0.5521, -0.4899,  7.1893,  ..., -0.1516, -0.0212, -1.1911],\n",
      "         [-0.7913, -0.3478,  7.2788,  ..., -0.2848, -0.1305, -1.3208]],\n",
      "\n",
      "        [[-0.5966, -0.5082,  7.7879,  ...,  0.0402, -0.0161, -1.1516],\n",
      "         [-0.7037, -0.6040,  7.9192,  ..., -0.1253, -0.0630, -1.1228],\n",
      "         [-0.6123, -0.3809,  7.7536,  ...,  0.1259,  0.1516, -0.8212],\n",
      "         ...,\n",
      "         [-0.7939, -0.5953,  7.8853,  ...,  0.0904, -0.2879, -0.9200],\n",
      "         [-0.5299, -0.4509,  7.8303,  ...,  0.1261, -0.0236, -0.9113],\n",
      "         [-0.8235, -0.4682,  8.0287,  ...,  0.1389, -0.2113, -0.9835]],\n",
      "\n",
      "        [[-0.6172, -0.6087,  7.8301,  ..., -0.2962, -0.0505, -1.4283],\n",
      "         [-0.6447, -0.5318,  7.9596,  ...,  0.0455, -0.1707, -1.2146],\n",
      "         [-0.6350, -0.5046,  7.8544,  ..., -0.0451, -0.1602, -1.1406],\n",
      "         ...,\n",
      "         [-0.6696, -0.3268,  7.9792,  ...,  0.0792,  0.0848, -0.8335],\n",
      "         [-0.8361, -0.7131,  7.9025,  ..., -0.1907, -0.1095, -1.2252],\n",
      "         [-0.5740, -0.4746,  7.8991,  ..., -0.0363,  0.1880, -0.8705]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7963, -0.6653,  8.0849,  ..., -0.2980, -0.2130, -1.1345],\n",
      "         [-0.7695, -0.7062,  8.0989,  ..., -0.2250, -0.1996, -1.2136],\n",
      "         [-0.8136, -0.7372,  8.0241,  ..., -0.2878, -0.2953, -1.1045],\n",
      "         ...,\n",
      "         [-0.9445, -0.6567,  8.0773,  ..., -0.2969, -0.2933, -1.1891],\n",
      "         [-0.8988, -0.7488,  7.9970,  ..., -0.3742, -0.1525, -1.2848],\n",
      "         [-0.8930, -0.6870,  8.1242,  ..., -0.3821, -0.2395, -1.2340]],\n",
      "\n",
      "        [[-0.8802, -0.7365,  8.1695,  ..., -0.2810, -0.2623, -1.0804],\n",
      "         [-0.6652, -0.6694,  7.9934,  ...,  0.0487, -0.2447, -1.2146],\n",
      "         [-0.8238, -0.7577,  8.0976,  ..., -0.2013, -0.1517, -1.0415],\n",
      "         ...,\n",
      "         [-0.7499, -0.6607,  7.9921,  ..., -0.2380, -0.0630, -1.1028],\n",
      "         [-0.7880, -0.7005,  8.0208,  ..., -0.0158, -0.2317, -1.1851],\n",
      "         [-0.7668, -0.8042,  8.1026,  ..., -0.1685, -0.3916, -1.0911]],\n",
      "\n",
      "        [[-0.8997, -0.6548,  7.9939,  ..., -0.2287, -0.2810, -1.1462],\n",
      "         [-0.8022, -0.6712,  8.0088,  ..., -0.1951, -0.2619, -1.0504],\n",
      "         [-0.8675, -0.6870,  8.0459,  ..., -0.0763, -0.3480, -1.1142],\n",
      "         ...,\n",
      "         [-0.7888, -0.5804,  8.1321,  ..., -0.1624, -0.1513, -1.3096],\n",
      "         [-0.8380, -0.6997,  8.1109,  ..., -0.1185, -0.2700, -1.1732],\n",
      "         [-0.8716, -0.5599,  8.1951,  ..., -0.2182, -0.3535, -1.0809]]],\n",
      "       device='cuda:0', grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([ 9.3351, 10.0872,  9.8631,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0', grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(2.7695, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n",
      "n_samples: 384\n",
      "-------Y: tensor([[    1,   210,    48,  ...,     0,     0,     0],\n",
      "        [    1, 19888,     2,  ...,     0,     0,     0],\n",
      "        [    1, 11228,  4666,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,   348,   483,  ...,     0,     0,     0],\n",
      "        [    1,   103, 13407,  ...,     0,     0,     0],\n",
      "        [    1,    26,   857,  ...,     0,     0,     0]])\n",
      "Y[63]: tensor([    1,    26,   857, 11186,     2,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "-------T: tensor([[   1,  143,  607,  ...,    0,    0,    0],\n",
      "        [   1,    6,    4,  ...,    0,    0,    0],\n",
      "        [   1, 2711,    3,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1, 8221,  130,  ...,    0,    0,    0],\n",
      "        [   1,  312,   94,  ...,    0,    0,    0],\n",
      "        [   1,  676,    5,  ...,    0,    0,    0]])\n",
      "T[63]: tensor([    1,   676,     5,  1193,   371,   206,    80,   368,     4,   206,\n",
      "           80,     6,     9,   612,    57,     4,     9,    55,     8,    18,\n",
      "         1034,  1403,     4,   206,    80,  1626,   258,     4,   897,  1387,\n",
      "          897,  8473,  5244,  1573,     4,   206,    80,     6,     9,   612,\n",
      "           57,     4,   246,    19,    12, 15185,    21,   129,    33,     7,\n",
      "          334,     4,  1191,  9242,    12,    35,    39,   181,    39,     2,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[ 0.5972, -1.8186,  0.0235,  ...,  1.0040, -1.7246,  0.8047],\n",
      "         [ 0.6878, -1.3434, -0.1064,  ...,  0.5868, -2.0447,  1.1174],\n",
      "         [ 0.5986, -1.3648, -0.0206,  ...,  0.4956, -1.7649,  0.9143],\n",
      "         ...,\n",
      "         [ 0.2355, -1.3817, -0.1610,  ...,  0.4510, -1.7467,  1.0809],\n",
      "         [ 0.2056, -1.2136,  0.2910,  ...,  0.3127, -1.4102,  1.1760],\n",
      "         [ 0.4947, -0.6747,  0.1127,  ...,  0.4511, -1.7464,  0.9770]],\n",
      "\n",
      "        [[ 0.1660, -1.1751, -0.0101,  ...,  0.8511, -1.7041,  0.3181],\n",
      "         [ 0.6511, -1.9618, -0.1090,  ...,  0.5346, -1.8452,  1.2765],\n",
      "         [ 0.7765, -2.1397, -0.0043,  ...,  0.9170, -2.0058,  1.1329],\n",
      "         ...,\n",
      "         [ 0.7194, -1.3814, -0.2316,  ...,  0.3993, -1.3934,  0.8448],\n",
      "         [ 0.4076, -1.3529,  0.0199,  ...,  0.2112, -1.5393,  1.0179],\n",
      "         [ 0.1472, -1.2309,  0.3327,  ...,  0.2233, -1.3873,  1.0858]],\n",
      "\n",
      "        [[ 0.1111, -1.8991,  0.0285,  ...,  0.7336, -1.6393,  0.7418],\n",
      "         [ 0.3562, -1.6056,  0.5485,  ...,  0.8792, -1.8775,  1.3999],\n",
      "         [ 0.4862, -1.5802,  0.1197,  ...,  0.6080, -1.4271,  0.7214],\n",
      "         ...,\n",
      "         [ 0.3331, -1.2433, -0.1153,  ...,  0.2783, -1.8814,  1.0242],\n",
      "         [ 0.2209, -1.0393,  0.0912,  ...,  0.3227, -1.7328,  1.0750],\n",
      "         [ 0.4377, -1.2064,  0.1547,  ...,  0.3849, -1.8689,  1.0341]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3030, -1.7063,  0.0951,  ...,  0.7772, -1.6845,  0.7773],\n",
      "         [ 0.8822, -1.5379,  0.3426,  ...,  0.3946, -1.6671,  0.9968],\n",
      "         [ 0.5638, -1.7298,  0.2063,  ...,  0.6461, -1.8695,  1.2462],\n",
      "         ...,\n",
      "         [ 0.5387, -1.2591, -0.0648,  ...,  0.3737, -1.4635,  1.0269],\n",
      "         [ 0.3737, -0.9532,  0.2622,  ...,  0.3907, -1.8177,  0.8934],\n",
      "         [-0.0685, -0.6239,  0.2927,  ...,  0.3278, -1.5704,  1.2383]],\n",
      "\n",
      "        [[ 0.1283, -1.9433, -0.1643,  ...,  0.7781, -1.9873,  0.7669],\n",
      "         [ 0.6433, -1.8299,  0.5123,  ...,  0.6988, -2.3552,  0.8871],\n",
      "         [ 0.5237, -1.8732,  0.0142,  ...,  0.1209, -1.8424,  0.7175],\n",
      "         ...,\n",
      "         [ 0.3272, -1.2659, -0.2672,  ...,  0.3487, -1.6976,  0.8750],\n",
      "         [ 0.5896, -1.1784,  0.2237,  ...,  0.2995, -1.6833,  0.8474],\n",
      "         [ 0.2877, -0.6547,  0.3396,  ...,  0.1573, -1.3920,  0.8864]],\n",
      "\n",
      "        [[ 0.0905, -1.7635,  0.0566,  ...,  0.8658, -1.6820,  0.7443],\n",
      "         [ 0.2823, -1.6417,  0.3023,  ...,  0.6288, -1.6033,  0.6280],\n",
      "         [ 0.6803, -1.4485,  0.0795,  ...,  0.6106, -1.8090,  0.4078],\n",
      "         ...,\n",
      "         [ 0.0678, -1.2136, -0.2918,  ...,  0.3456, -1.8165,  1.0428],\n",
      "         [ 0.2406, -1.1599,  0.1042,  ...,  0.1805, -1.7682,  1.0677],\n",
      "         [ 0.2337, -0.9092,  0.4248,  ...,  0.2896, -1.5700,  1.1238]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n",
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[-7.1115e-01, -5.8468e-01,  7.5689e+00,  ..., -3.8915e-01,\n",
      "          -3.2984e-01, -1.4253e+00],\n",
      "         [-8.2277e-01, -7.7271e-01,  8.1723e+00,  ..., -4.8633e-02,\n",
      "          -3.0011e-01, -1.3747e+00],\n",
      "         [-8.6104e-01, -6.6254e-01,  8.3198e+00,  ..., -2.3967e-01,\n",
      "          -3.5523e-01, -1.2415e+00],\n",
      "         ...,\n",
      "         [-9.6965e-01, -8.3657e-01,  8.3348e+00,  ..., -2.0144e-01,\n",
      "          -3.9403e-01, -1.3299e+00],\n",
      "         [-9.9744e-01, -7.0581e-01,  8.4010e+00,  ..., -2.3453e-01,\n",
      "          -4.5423e-01, -1.2452e+00],\n",
      "         [-9.1758e-01, -8.3134e-01,  8.4289e+00,  ..., -2.1741e-01,\n",
      "          -4.7505e-01, -1.2819e+00]],\n",
      "\n",
      "        [[-8.1196e-01, -5.1145e-01,  7.6192e+00,  ..., -2.6243e-01,\n",
      "          -2.5271e-01, -1.2620e+00],\n",
      "         [-8.6409e-01, -7.9642e-01,  8.0776e+00,  ..., -1.7210e-01,\n",
      "          -4.2621e-01, -1.0708e+00],\n",
      "         [-6.7341e-01, -6.1111e-01,  8.1629e+00,  ..., -2.6159e-02,\n",
      "           5.5311e-02, -1.0031e+00],\n",
      "         ...,\n",
      "         [-9.2308e-01, -7.6396e-01,  8.3974e+00,  ..., -2.6454e-01,\n",
      "          -3.2468e-01, -1.2589e+00],\n",
      "         [-8.5056e-01, -7.7598e-01,  8.4656e+00,  ..., -3.4886e-01,\n",
      "          -4.2369e-01, -1.3399e+00],\n",
      "         [-9.9402e-01, -8.3604e-01,  8.4216e+00,  ..., -3.3848e-01,\n",
      "          -4.3611e-01, -1.3616e+00]],\n",
      "\n",
      "        [[-9.1993e-01, -4.9035e-01,  7.5953e+00,  ..., -2.0172e-01,\n",
      "          -3.6427e-01, -1.3054e+00],\n",
      "         [-6.9008e-01, -5.8346e-01,  8.0915e+00,  ..., -9.7044e-02,\n",
      "          -5.3622e-03, -1.3579e+00],\n",
      "         [-8.5111e-01, -7.7573e-01,  8.3097e+00,  ..., -2.6807e-01,\n",
      "          -3.2484e-01, -1.2326e+00],\n",
      "         ...,\n",
      "         [-7.8136e-01, -8.4222e-01,  8.3967e+00,  ..., -3.0015e-01,\n",
      "          -2.8761e-01, -1.2171e+00],\n",
      "         [-9.4923e-01, -8.2355e-01,  8.4015e+00,  ..., -2.4946e-01,\n",
      "          -1.7003e-01, -1.1541e+00],\n",
      "         [-8.7590e-01, -7.9198e-01,  8.3198e+00,  ..., -2.8305e-01,\n",
      "          -5.9636e-01, -1.0736e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.7187e-01, -4.7820e-01,  7.6495e+00,  ..., -2.1083e-01,\n",
      "          -3.6777e-01, -1.3836e+00],\n",
      "         [-6.2337e-01, -6.7754e-01,  8.0754e+00,  ..., -1.3800e-01,\n",
      "          -2.5552e-01, -1.0522e+00],\n",
      "         [-6.2728e-01, -8.6443e-01,  8.2446e+00,  ..., -1.3668e-01,\n",
      "          -4.3903e-01, -1.2770e+00],\n",
      "         ...,\n",
      "         [-7.7018e-01, -8.7110e-01,  8.3704e+00,  ..., -3.0660e-01,\n",
      "          -3.7262e-01, -1.3350e+00],\n",
      "         [-8.8494e-01, -9.4281e-01,  8.4697e+00,  ..., -2.5419e-01,\n",
      "          -3.8008e-01, -1.1763e+00],\n",
      "         [-9.2516e-01, -9.0007e-01,  8.4622e+00,  ..., -2.7398e-01,\n",
      "          -4.8625e-01, -1.1196e+00]],\n",
      "\n",
      "        [[-8.3145e-01, -5.3505e-01,  7.6414e+00,  ..., -1.3356e-01,\n",
      "          -4.2843e-01, -1.3168e+00],\n",
      "         [-6.1950e-01, -7.2345e-01,  8.1971e+00,  ..., -2.0628e-01,\n",
      "          -1.7069e-01, -9.8936e-01],\n",
      "         [-7.8292e-01, -5.3793e-01,  8.2038e+00,  ..., -1.0697e-01,\n",
      "          -2.6225e-01, -1.1692e+00],\n",
      "         ...,\n",
      "         [-8.4562e-01, -9.0910e-01,  8.4507e+00,  ..., -3.1940e-01,\n",
      "          -3.0049e-01, -1.2168e+00],\n",
      "         [-8.9821e-01, -8.1475e-01,  8.3830e+00,  ..., -2.4241e-01,\n",
      "          -4.2498e-01, -1.0673e+00],\n",
      "         [-9.2051e-01, -7.8318e-01,  8.4199e+00,  ..., -2.2313e-01,\n",
      "          -2.5958e-01, -1.1473e+00]],\n",
      "\n",
      "        [[-7.3792e-01, -6.7506e-01,  7.5336e+00,  ..., -2.0542e-01,\n",
      "          -4.3589e-01, -1.4636e+00],\n",
      "         [-5.8979e-01, -6.2881e-01,  8.0673e+00,  ..., -1.8227e-01,\n",
      "          -1.9488e-01, -1.1931e+00],\n",
      "         [-7.8896e-01, -7.0344e-01,  8.1629e+00,  ..., -3.0645e-01,\n",
      "          -1.0368e-01, -1.2286e+00],\n",
      "         ...,\n",
      "         [-9.6505e-01, -9.1661e-01,  8.3950e+00,  ..., -3.5786e-01,\n",
      "          -3.4893e-01, -1.2255e+00],\n",
      "         [-8.4426e-01, -8.2301e-01,  8.3904e+00,  ..., -2.9362e-01,\n",
      "          -3.4801e-01, -1.1297e+00],\n",
      "         [-7.9066e-01, -7.9837e-01,  8.3912e+00,  ..., -1.5433e-01,\n",
      "          -3.0773e-01, -1.3298e+00]]], device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [  210, 19888, 11228,  ...,   348,   103,    26],\n",
      "        [   48,     2,  4666,  ...,   483, 13407,   857],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs.tr tensor([[[-7.1115e-01, -5.8468e-01,  7.5689e+00,  ..., -3.8915e-01,\n",
      "          -3.2984e-01, -1.4253e+00],\n",
      "         [-8.1196e-01, -5.1145e-01,  7.6192e+00,  ..., -2.6243e-01,\n",
      "          -2.5271e-01, -1.2620e+00],\n",
      "         [-9.1993e-01, -4.9035e-01,  7.5953e+00,  ..., -2.0172e-01,\n",
      "          -3.6427e-01, -1.3054e+00],\n",
      "         ...,\n",
      "         [-7.7187e-01, -4.7820e-01,  7.6495e+00,  ..., -2.1083e-01,\n",
      "          -3.6777e-01, -1.3836e+00],\n",
      "         [-8.3145e-01, -5.3505e-01,  7.6414e+00,  ..., -1.3356e-01,\n",
      "          -4.2843e-01, -1.3168e+00],\n",
      "         [-7.3792e-01, -6.7506e-01,  7.5336e+00,  ..., -2.0542e-01,\n",
      "          -4.3589e-01, -1.4636e+00]],\n",
      "\n",
      "        [[-8.2277e-01, -7.7271e-01,  8.1723e+00,  ..., -4.8633e-02,\n",
      "          -3.0011e-01, -1.3747e+00],\n",
      "         [-8.6409e-01, -7.9642e-01,  8.0776e+00,  ..., -1.7210e-01,\n",
      "          -4.2621e-01, -1.0708e+00],\n",
      "         [-6.9008e-01, -5.8346e-01,  8.0915e+00,  ..., -9.7044e-02,\n",
      "          -5.3622e-03, -1.3579e+00],\n",
      "         ...,\n",
      "         [-6.2337e-01, -6.7754e-01,  8.0754e+00,  ..., -1.3800e-01,\n",
      "          -2.5552e-01, -1.0522e+00],\n",
      "         [-6.1950e-01, -7.2345e-01,  8.1971e+00,  ..., -2.0628e-01,\n",
      "          -1.7069e-01, -9.8936e-01],\n",
      "         [-5.8979e-01, -6.2881e-01,  8.0673e+00,  ..., -1.8227e-01,\n",
      "          -1.9488e-01, -1.1931e+00]],\n",
      "\n",
      "        [[-8.6104e-01, -6.6254e-01,  8.3198e+00,  ..., -2.3967e-01,\n",
      "          -3.5523e-01, -1.2415e+00],\n",
      "         [-6.7341e-01, -6.1111e-01,  8.1629e+00,  ..., -2.6159e-02,\n",
      "           5.5311e-02, -1.0031e+00],\n",
      "         [-8.5111e-01, -7.7573e-01,  8.3097e+00,  ..., -2.6807e-01,\n",
      "          -3.2484e-01, -1.2326e+00],\n",
      "         ...,\n",
      "         [-6.2728e-01, -8.6443e-01,  8.2446e+00,  ..., -1.3668e-01,\n",
      "          -4.3903e-01, -1.2770e+00],\n",
      "         [-7.8292e-01, -5.3793e-01,  8.2038e+00,  ..., -1.0697e-01,\n",
      "          -2.6225e-01, -1.1692e+00],\n",
      "         [-7.8896e-01, -7.0344e-01,  8.1629e+00,  ..., -3.0645e-01,\n",
      "          -1.0368e-01, -1.2286e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.6965e-01, -8.3657e-01,  8.3348e+00,  ..., -2.0144e-01,\n",
      "          -3.9403e-01, -1.3299e+00],\n",
      "         [-9.2308e-01, -7.6396e-01,  8.3974e+00,  ..., -2.6454e-01,\n",
      "          -3.2468e-01, -1.2589e+00],\n",
      "         [-7.8136e-01, -8.4222e-01,  8.3967e+00,  ..., -3.0015e-01,\n",
      "          -2.8761e-01, -1.2171e+00],\n",
      "         ...,\n",
      "         [-7.7018e-01, -8.7110e-01,  8.3704e+00,  ..., -3.0660e-01,\n",
      "          -3.7262e-01, -1.3350e+00],\n",
      "         [-8.4562e-01, -9.0910e-01,  8.4507e+00,  ..., -3.1940e-01,\n",
      "          -3.0049e-01, -1.2168e+00],\n",
      "         [-9.6505e-01, -9.1661e-01,  8.3950e+00,  ..., -3.5786e-01,\n",
      "          -3.4893e-01, -1.2255e+00]],\n",
      "\n",
      "        [[-9.9744e-01, -7.0581e-01,  8.4010e+00,  ..., -2.3453e-01,\n",
      "          -4.5423e-01, -1.2452e+00],\n",
      "         [-8.5056e-01, -7.7598e-01,  8.4656e+00,  ..., -3.4886e-01,\n",
      "          -4.2369e-01, -1.3399e+00],\n",
      "         [-9.4923e-01, -8.2355e-01,  8.4015e+00,  ..., -2.4946e-01,\n",
      "          -1.7003e-01, -1.1541e+00],\n",
      "         ...,\n",
      "         [-8.8494e-01, -9.4281e-01,  8.4697e+00,  ..., -2.5419e-01,\n",
      "          -3.8008e-01, -1.1763e+00],\n",
      "         [-8.9821e-01, -8.1475e-01,  8.3830e+00,  ..., -2.4241e-01,\n",
      "          -4.2498e-01, -1.0673e+00],\n",
      "         [-8.4426e-01, -8.2301e-01,  8.3904e+00,  ..., -2.9362e-01,\n",
      "          -3.4801e-01, -1.1297e+00]],\n",
      "\n",
      "        [[-9.1758e-01, -8.3134e-01,  8.4289e+00,  ..., -2.1741e-01,\n",
      "          -4.7505e-01, -1.2819e+00],\n",
      "         [-9.9402e-01, -8.3604e-01,  8.4216e+00,  ..., -3.3848e-01,\n",
      "          -4.3611e-01, -1.3616e+00],\n",
      "         [-8.7590e-01, -7.9198e-01,  8.3198e+00,  ..., -2.8305e-01,\n",
      "          -5.9636e-01, -1.0736e+00],\n",
      "         ...,\n",
      "         [-9.2516e-01, -9.0007e-01,  8.4622e+00,  ..., -2.7398e-01,\n",
      "          -4.8625e-01, -1.1196e+00],\n",
      "         [-9.2051e-01, -7.8318e-01,  8.4199e+00,  ..., -2.2313e-01,\n",
      "          -2.5958e-01, -1.1473e+00],\n",
      "         [-7.9066e-01, -7.9837e-01,  8.3912e+00,  ..., -1.5433e-01,\n",
      "          -3.0773e-01, -1.3298e+00]]], device='cuda:0',\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([10.6214, 11.2530, 11.1472,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0', grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(2.5944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n",
      "n_samples: 448\n",
      "-------Y: tensor([[   1, 1752, 2555,  ...,    0,    0,    0],\n",
      "        [   1, 5464,  312,  ...,    0,    0,    0],\n",
      "        [   1,   35,   92,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,   10,   10,  ...,    0,    0,    0],\n",
      "        [   1,   13,   91,  ...,    0,    0,    0],\n",
      "        [   1, 1802, 1230,  ...,    0,    0,    0]])\n",
      "Y[63]: tensor([   1, 1802, 1230, 1011,    2,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "-------T: tensor([[    1,    17,    46,  ...,     0,     0,     0],\n",
      "        [    1,  1212,  3774,  ...,     0,     0,     0],\n",
      "        [    1,     3,  2058,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,   901,   420,  ...,     0,     0,     0],\n",
      "        [    1, 11180,     7,  ...,     0,     0,     0],\n",
      "        [    1,   497,     4,  ...,     0,     0,     0]])\n",
      "T[63]: tensor([    1,   497,     4,  3655,  2180,     4,  4789,   236,     4,   130,\n",
      "           74,     3,     3, 14900,     3,     4,     3,     4,  3409,     3,\n",
      "            3,  1223,     4,    15,     4,  3409,   930,     3, 13223,  1223,\n",
      "            2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[ 0.1218, -1.7218,  0.1274,  ...,  0.9104, -2.0166,  0.8873],\n",
      "         [ 0.5714, -1.3321,  0.2910,  ...,  0.8346, -1.8830,  1.4281],\n",
      "         [-0.1598, -1.4065, -0.1300,  ...,  0.6074, -2.5172,  1.3198],\n",
      "         ...,\n",
      "         [ 0.3078, -1.2965, -0.0537,  ...,  0.3176, -1.6904,  1.2583],\n",
      "         [ 0.0500, -1.4336,  0.0600,  ...,  0.4858, -1.5812,  1.0372],\n",
      "         [ 0.0994, -1.0436,  0.1544,  ...,  0.6482, -1.9297,  0.9568]],\n",
      "\n",
      "        [[ 0.5244, -1.2592,  0.1001,  ...,  0.9585, -1.8535,  0.5716],\n",
      "         [ 0.7951, -1.3088,  0.7517,  ...,  1.1484, -1.5644,  0.9882],\n",
      "         [ 0.5881, -1.1376, -0.0363,  ...,  1.1002, -1.7483,  1.2234],\n",
      "         ...,\n",
      "         [ 0.2445, -1.3315, -0.0591,  ...,  0.3726, -1.7560,  0.9604],\n",
      "         [ 0.3115, -0.7824,  0.2437,  ...,  0.3746, -1.6271,  1.1236],\n",
      "         [ 0.2792, -1.0451,  0.2281,  ...,  0.4479, -1.9266,  1.1980]],\n",
      "\n",
      "        [[ 0.1063, -1.9194,  0.0242,  ...,  1.0439, -1.9589,  0.8988],\n",
      "         [ 0.5992, -1.2416, -0.1257,  ...,  0.8235, -1.4968,  0.8887],\n",
      "         [ 0.8227, -1.5946,  0.3220,  ...,  1.1173, -1.4877,  1.2875],\n",
      "         ...,\n",
      "         [ 0.4748, -1.1694, -0.1362,  ...,  0.4923, -1.4609,  1.2411],\n",
      "         [ 0.0749, -0.9799,  0.1149,  ...,  0.6017, -1.7266,  0.9286],\n",
      "         [ 0.5312, -0.9873,  0.2112,  ...,  0.3978, -1.5641,  1.0352]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0677, -1.9058, -0.0854,  ...,  1.0144, -1.9584,  0.7755],\n",
      "         [ 0.7603, -1.2114,  0.1272,  ...,  0.7987, -1.8397,  1.1684],\n",
      "         [ 0.2774, -2.3941,  0.3194,  ...,  0.8651, -2.4165,  0.9520],\n",
      "         ...,\n",
      "         [ 0.4312, -1.0071, -0.0490,  ...,  0.6410, -1.7472,  1.0026],\n",
      "         [ 0.4659, -1.0856, -0.0964,  ...,  0.2716, -1.3879,  0.7957],\n",
      "         [ 0.1007, -1.1113,  0.3796,  ...,  0.3732, -1.5765,  1.1723]],\n",
      "\n",
      "        [[ 0.3234, -1.8114,  0.0155,  ...,  0.8887, -1.7525,  0.7425],\n",
      "         [ 0.5594, -1.4586,  0.1235,  ...,  0.6171, -1.6815,  0.7948],\n",
      "         [ 0.3556, -1.1694,  0.2364,  ...,  0.2431, -0.8488,  1.4674],\n",
      "         ...,\n",
      "         [ 0.4248, -1.0221, -0.1631,  ...,  0.6093, -1.9559,  0.9512],\n",
      "         [ 0.1224, -1.2591,  0.0438,  ...,  0.3161, -1.7135,  1.2447],\n",
      "         [ 0.3050, -0.9681,  0.2821,  ...,  0.4716, -1.5646,  1.1499]],\n",
      "\n",
      "        [[ 0.1089, -1.8881, -0.1586,  ...,  0.9994, -1.9073,  0.7585],\n",
      "         [ 0.5661, -1.2837, -0.1180,  ...,  0.5851, -1.1952,  1.0765],\n",
      "         [ 0.7041, -2.1209,  0.1017,  ...,  1.2661, -2.0530,  1.3857],\n",
      "         ...,\n",
      "         [ 0.3672, -1.4410, -0.0521,  ...,  0.4558, -1.7180,  1.1736],\n",
      "         [-0.1676, -1.4327,  0.1217,  ...,  0.3810, -1.7472,  0.9623],\n",
      "         [ 0.0401, -1.0820,  0.1839,  ...,  0.1718, -1.9005,  1.0712]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[-0.9880, -0.5901,  7.8319,  ..., -0.4328, -0.5520, -1.3862],\n",
      "         [-0.7730, -0.8466,  8.3533,  ..., -0.2269, -0.5237, -1.4310],\n",
      "         [-0.8683, -0.8761,  8.4976,  ..., -0.1393, -0.3016, -1.2632],\n",
      "         ...,\n",
      "         [-0.9987, -0.9607,  8.5560,  ..., -0.4353, -0.5066, -1.1707],\n",
      "         [-1.0019, -0.9322,  8.6784,  ..., -0.2906, -0.4505, -1.2808],\n",
      "         [-0.8423, -0.9048,  8.5965,  ..., -0.3696, -0.5865, -1.1246]],\n",
      "\n",
      "        [[-0.9422, -0.6308,  7.7686,  ..., -0.3663, -0.3841, -1.3718],\n",
      "         [-0.8343, -0.6616,  8.3538,  ..., -0.0955, -0.3233, -1.3317],\n",
      "         [-0.8122, -0.7061,  8.4170,  ..., -0.2509, -0.3166, -1.2421],\n",
      "         ...,\n",
      "         [-0.9933, -1.0265,  8.5374,  ..., -0.4284, -0.4808, -1.3175],\n",
      "         [-0.9042, -0.9123,  8.7020,  ..., -0.4049, -0.4293, -1.4170],\n",
      "         [-0.8440, -0.8911,  8.5806,  ..., -0.2742, -0.4483, -1.2129]],\n",
      "\n",
      "        [[-0.8848, -0.6653,  7.6034,  ..., -0.2769, -0.5090, -1.2730],\n",
      "         [-0.9509, -0.6751,  8.1431,  ..., -0.1078, -0.3447, -1.1900],\n",
      "         [-0.5844, -0.5686,  8.3439,  ..., -0.1141, -0.3452, -1.4351],\n",
      "         ...,\n",
      "         [-0.8612, -0.9729,  8.5278,  ..., -0.3562, -0.5301, -1.0713],\n",
      "         [-0.9753, -0.8841,  8.5894,  ..., -0.4311, -0.5650, -1.3303],\n",
      "         [-0.9331, -0.8569,  8.5619,  ..., -0.1049, -0.6002, -1.2054]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8799, -0.7125,  7.7584,  ..., -0.2806, -0.4969, -1.2316],\n",
      "         [-0.8210, -0.6522,  8.6137,  ..., -0.0244, -0.2646, -0.9650],\n",
      "         [-0.7680, -0.8177,  8.7915,  ..., -0.2540, -0.3692, -1.0147],\n",
      "         ...,\n",
      "         [-0.8889, -1.0220,  8.6491,  ..., -0.4166, -0.4406, -1.2739],\n",
      "         [-0.9655, -0.8606,  8.5795,  ..., -0.4328, -0.6182, -1.0819],\n",
      "         [-1.0192, -0.9150,  8.6070,  ..., -0.2596, -0.5821, -1.2636]],\n",
      "\n",
      "        [[-0.7949, -0.7127,  7.6592,  ..., -0.3637, -0.5021, -1.3135],\n",
      "         [-0.6091, -0.5675,  8.4065,  ..., -0.1902, -0.3134, -1.2556],\n",
      "         [-0.8619, -1.0450,  8.2992,  ..., -0.1824, -0.3804, -1.1953],\n",
      "         ...,\n",
      "         [-0.9974, -0.9754,  8.5439,  ..., -0.2829, -0.5035, -1.2637],\n",
      "         [-0.9268, -1.0212,  8.5901,  ..., -0.2783, -0.4348, -1.2601],\n",
      "         [-0.8961, -1.0846,  8.6184,  ..., -0.3570, -0.4370, -1.1176]],\n",
      "\n",
      "        [[-0.9908, -0.7697,  7.8620,  ..., -0.2942, -0.4348, -1.2132],\n",
      "         [-0.8680, -0.7645,  8.2411,  ..., -0.2385, -0.4623, -1.1734],\n",
      "         [-0.7567, -0.7494,  8.3119,  ..., -0.0420, -0.3286, -1.3601],\n",
      "         ...,\n",
      "         [-0.9264, -0.8916,  8.6485,  ..., -0.4039, -0.4337, -1.3728],\n",
      "         [-1.0204, -0.8443,  8.6438,  ..., -0.2631, -0.5724, -1.3054],\n",
      "         [-0.8984, -0.7779,  8.6213,  ..., -0.3508, -0.4751, -1.1881]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [1752, 5464,   35,  ...,   10,   13, 1802],\n",
      "        [2555,  312,   92,  ...,   10,   91, 1230],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0],\n",
      "        [   0,    0,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n",
      "outs.tr tensor([[[-0.9880, -0.5901,  7.8319,  ..., -0.4328, -0.5520, -1.3862],\n",
      "         [-0.9422, -0.6308,  7.7686,  ..., -0.3663, -0.3841, -1.3718],\n",
      "         [-0.8848, -0.6653,  7.6034,  ..., -0.2769, -0.5090, -1.2730],\n",
      "         ...,\n",
      "         [-0.8799, -0.7125,  7.7584,  ..., -0.2806, -0.4969, -1.2316],\n",
      "         [-0.7949, -0.7127,  7.6592,  ..., -0.3637, -0.5021, -1.3135],\n",
      "         [-0.9908, -0.7697,  7.8620,  ..., -0.2942, -0.4348, -1.2132]],\n",
      "\n",
      "        [[-0.7730, -0.8466,  8.3533,  ..., -0.2269, -0.5237, -1.4310],\n",
      "         [-0.8343, -0.6616,  8.3538,  ..., -0.0955, -0.3233, -1.3317],\n",
      "         [-0.9509, -0.6751,  8.1431,  ..., -0.1078, -0.3447, -1.1900],\n",
      "         ...,\n",
      "         [-0.8210, -0.6522,  8.6137,  ..., -0.0244, -0.2646, -0.9650],\n",
      "         [-0.6091, -0.5675,  8.4065,  ..., -0.1902, -0.3134, -1.2556],\n",
      "         [-0.8680, -0.7645,  8.2411,  ..., -0.2385, -0.4623, -1.1734]],\n",
      "\n",
      "        [[-0.8683, -0.8761,  8.4976,  ..., -0.1393, -0.3016, -1.2632],\n",
      "         [-0.8122, -0.7061,  8.4170,  ..., -0.2509, -0.3166, -1.2421],\n",
      "         [-0.5844, -0.5686,  8.3439,  ..., -0.1141, -0.3452, -1.4351],\n",
      "         ...,\n",
      "         [-0.7680, -0.8177,  8.7915,  ..., -0.2540, -0.3692, -1.0147],\n",
      "         [-0.8619, -1.0450,  8.2992,  ..., -0.1824, -0.3804, -1.1953],\n",
      "         [-0.7567, -0.7494,  8.3119,  ..., -0.0420, -0.3286, -1.3601]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9987, -0.9607,  8.5560,  ..., -0.4353, -0.5066, -1.1707],\n",
      "         [-0.9933, -1.0265,  8.5374,  ..., -0.4284, -0.4808, -1.3175],\n",
      "         [-0.8612, -0.9729,  8.5278,  ..., -0.3562, -0.5301, -1.0713],\n",
      "         ...,\n",
      "         [-0.8889, -1.0220,  8.6491,  ..., -0.4166, -0.4406, -1.2739],\n",
      "         [-0.9974, -0.9754,  8.5439,  ..., -0.2829, -0.5035, -1.2637],\n",
      "         [-0.9264, -0.8916,  8.6485,  ..., -0.4039, -0.4337, -1.3728]],\n",
      "\n",
      "        [[-1.0019, -0.9322,  8.6784,  ..., -0.2906, -0.4505, -1.2808],\n",
      "         [-0.9042, -0.9123,  8.7020,  ..., -0.4049, -0.4293, -1.4170],\n",
      "         [-0.9753, -0.8841,  8.5894,  ..., -0.4311, -0.5650, -1.3303],\n",
      "         ...,\n",
      "         [-0.9655, -0.8606,  8.5795,  ..., -0.4328, -0.6182, -1.0819],\n",
      "         [-0.9268, -1.0212,  8.5901,  ..., -0.2783, -0.4348, -1.2601],\n",
      "         [-1.0204, -0.8443,  8.6438,  ..., -0.2631, -0.5724, -1.3054]],\n",
      "\n",
      "        [[-0.8423, -0.9048,  8.5965,  ..., -0.3696, -0.5865, -1.1246],\n",
      "         [-0.8440, -0.8911,  8.5806,  ..., -0.2742, -0.4483, -1.2129],\n",
      "         [-0.9331, -0.8569,  8.5619,  ..., -0.1049, -0.6002, -1.2054],\n",
      "         ...,\n",
      "         [-1.0192, -0.9150,  8.6070,  ..., -0.2596, -0.5821, -1.2636],\n",
      "         [-0.8961, -1.0846,  8.6184,  ..., -0.3570, -0.4370, -1.1176],\n",
      "         [-0.8984, -0.7779,  8.6213,  ..., -0.3508, -0.4751, -1.1881]]],\n",
      "       device='cuda:0', grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([10.0446,  9.4407,  9.8988,  ...,  0.0000,  0.0000,  0.0000],\n",
      "       device='cuda:0', grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(2.7976, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n",
      "n_samples: 512\n",
      "-------Y: tensor([[    1,    18,  3165,  ...,     0,     0,     0],\n",
      "        [    1,    32,    18,  ...,     0,     0,     0],\n",
      "        [    1,    90,    29,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,  3071,     2,  ...,     0,     0,     0],\n",
      "        [    1,    23, 20329,  ...,     0,     0,     0],\n",
      "        [    1,   103,    77,  ...,     0,     0,     0]])\n",
      "Y[63]: tensor([    1,   103,    77, 15778,     5,   206,   194,     9,     2,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "-------T: tensor([[   1,  669,    3,  ...,    0,    0,    0],\n",
      "        [   1, 2482, 2198,  ...,    0,    0,    0],\n",
      "        [   1,   18, 3329,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  311,    4,  ...,    0,    0,    0],\n",
      "        [   1,   18,   12,  ...,    0,    0,    0],\n",
      "        [   1,   21,  126,  ...,    0,    0,    0]])\n",
      "T[63]: tensor([    1,    21,   126, 25118,     3,    20,    11,     4,   124,    13,\n",
      "          473,   150,     4,    19,    33,   577,     3,     6, 23291,  2977,\n",
      "         2246,    12,    33,   116,   184,     5,    11,    11,    11,     4,\n",
      "           53,    84,     5,    71, 11991,     4,    51,     6,   387,  1402,\n",
      "        24354,     4,   121,    94,     3,     4,  1128,  1098,  3634,  4877,\n",
      "        20048,     4,    77, 15778,     5,  1280,     6,    66,     3,     2,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[-0.1555, -1.6718, -0.0896,  ...,  1.0246, -1.9908,  0.7755],\n",
      "         [ 0.8215, -1.5521, -0.0671,  ...,  0.6974, -1.6125,  0.8487],\n",
      "         [ 0.4895, -1.2663, -0.1020,  ...,  0.8482, -1.3571,  0.8071],\n",
      "         ...,\n",
      "         [ 0.2295, -1.2215, -0.0316,  ...,  0.2409, -1.9062,  1.0311],\n",
      "         [ 0.2355, -0.9043,  0.0773,  ...,  0.6283, -1.6538,  1.1526],\n",
      "         [ 0.1437, -1.3678,  0.0927,  ...,  0.6052, -1.5990,  1.2003]],\n",
      "\n",
      "        [[ 0.1055, -1.6613, -0.0621,  ...,  0.6407, -1.5916,  0.9581],\n",
      "         [ 0.7476, -1.5908,  0.1842,  ...,  0.5743, -1.5012,  1.1038],\n",
      "         [ 0.7054, -1.4958,  0.0206,  ...,  0.8492, -2.0379,  1.0487],\n",
      "         ...,\n",
      "         [ 0.2641, -1.1573, -0.2452,  ...,  0.5153, -1.7377,  1.0894],\n",
      "         [ 0.3500, -0.9368,  0.0697,  ...,  0.6757, -1.7344,  1.0566],\n",
      "         [ 0.2249, -0.7225,  0.2937,  ...,  0.7813, -1.4109,  0.9728]],\n",
      "\n",
      "        [[ 0.0455, -1.6589, -0.1394,  ...,  0.5482, -1.4696,  0.8911],\n",
      "         [ 1.1190, -1.3946, -0.1753,  ...,  0.9186, -2.0998,  1.0897],\n",
      "         [ 0.2127, -1.6868, -0.1380,  ...,  0.7635, -2.0792,  1.1478],\n",
      "         ...,\n",
      "         [ 0.2891, -1.1936, -0.1514,  ...,  0.6105, -1.7581,  0.7370],\n",
      "         [ 0.4338, -1.1718, -0.0307,  ...,  0.5650, -1.6849,  0.8860],\n",
      "         [ 0.1768, -1.1972,  0.1430,  ...,  0.6126, -1.8902,  1.2555]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0805, -1.7518, -0.1944,  ...,  1.0131, -1.8829,  0.8522],\n",
      "         [ 0.9756, -1.1098, -0.0663,  ...,  1.0416, -1.8413,  1.1064],\n",
      "         [ 0.4819, -1.9690, -0.1936,  ...,  1.0315, -1.8017,  1.0001],\n",
      "         ...,\n",
      "         [ 0.2960, -1.0987, -0.0820,  ...,  0.5233, -1.6888,  0.9364],\n",
      "         [ 0.3658, -1.0662,  0.1487,  ...,  0.6722, -1.5616,  1.1821],\n",
      "         [ 0.1971, -0.6320,  0.1380,  ...,  0.5786, -1.8700,  1.2186]],\n",
      "\n",
      "        [[ 0.0402, -1.4033, -0.0829,  ...,  0.4407, -1.7339,  0.8748],\n",
      "         [ 1.3619, -1.2180, -0.1158,  ...,  1.1993, -2.1151,  0.7682],\n",
      "         [ 0.8188, -2.0985, -0.3630,  ...,  0.7674, -1.5878,  0.8021],\n",
      "         ...,\n",
      "         [ 0.1006, -1.0424, -0.0946,  ...,  0.6162, -1.5863,  1.1104],\n",
      "         [ 0.4182, -1.0616,  0.1171,  ...,  0.5984, -1.7213,  1.1224],\n",
      "         [ 0.5248, -1.1216, -0.0550,  ...,  0.7329, -1.5005,  0.9204]],\n",
      "\n",
      "        [[ 0.1339, -1.8490,  0.0140,  ...,  1.1424, -1.4786,  0.8158],\n",
      "         [ 0.5780, -1.4022, -0.0855,  ...,  0.5220, -1.9338,  0.9940],\n",
      "         [ 0.3552, -2.1247,  0.2460,  ...,  1.0155, -1.8117,  0.9857],\n",
      "         ...,\n",
      "         [ 0.3313, -1.2087,  0.0059,  ...,  0.5024, -1.7422,  1.1779],\n",
      "         [ 0.2290, -1.0125,  0.0557,  ...,  0.4642, -1.9184,  1.1828],\n",
      "         [ 0.1297, -1.0032,  0.2591,  ...,  0.4029, -1.8694,  0.7288]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[-0.9384, -0.6422,  7.4560,  ..., -0.3177, -0.6019, -1.5821],\n",
      "         [-0.9086, -0.8306,  7.9956,  ..., -0.3950, -0.5257, -1.3291],\n",
      "         [-0.7866, -0.8418,  8.3591,  ..., -0.1474, -0.3537, -1.4434],\n",
      "         ...,\n",
      "         [-0.8710, -1.0219,  8.5683,  ..., -0.5666, -0.4820, -1.1829],\n",
      "         [-0.9697, -0.8754,  8.5294,  ..., -0.4429, -0.5747, -1.3424],\n",
      "         [-0.8612, -0.9675,  8.5129,  ..., -0.4256, -0.5920, -1.2718]],\n",
      "\n",
      "        [[-0.9055, -0.7426,  7.5809,  ..., -0.3006, -0.6425, -1.4742],\n",
      "         [-0.8091, -0.9680,  8.3867,  ..., -0.3715, -0.3371, -1.5240],\n",
      "         [-1.0467, -0.8638,  8.1783,  ..., -0.4050, -0.3204, -1.3048],\n",
      "         ...,\n",
      "         [-0.9688, -1.0913,  8.5355,  ..., -0.4019, -0.5155, -1.2224],\n",
      "         [-0.8928, -0.9818,  8.5891,  ..., -0.4143, -0.5154, -1.1654],\n",
      "         [-0.8474, -0.8421,  8.4839,  ..., -0.4072, -0.5158, -1.4427]],\n",
      "\n",
      "        [[-0.9346, -0.7331,  7.7067,  ..., -0.4901, -0.6573, -1.4298],\n",
      "         [-0.7365, -0.7158,  8.1937,  ..., -0.2815, -0.4100, -1.4083],\n",
      "         [-0.8588, -0.7637,  8.2964,  ..., -0.1561, -0.4750, -1.2201],\n",
      "         ...,\n",
      "         [-0.9230, -0.9786,  8.4371,  ..., -0.4507, -0.4948, -1.2917],\n",
      "         [-1.0768, -0.9155,  8.4954,  ..., -0.4214, -0.5151, -1.3682],\n",
      "         [-0.9021, -1.0069,  8.5345,  ..., -0.2885, -0.6597, -1.3358]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.7277, -0.7673,  7.5618,  ..., -0.4352, -0.5138, -1.3892],\n",
      "         [-0.9715, -0.6993,  8.1827,  ..., -0.3181, -0.3823, -1.3645],\n",
      "         [-0.7006, -0.6596,  8.3094,  ..., -0.2384, -0.3423, -0.9984],\n",
      "         ...,\n",
      "         [-0.8706, -0.9366,  8.5106,  ..., -0.4876, -0.4918, -1.1990],\n",
      "         [-0.9518, -0.9029,  8.4482,  ..., -0.5116, -0.5564, -1.3067],\n",
      "         [-0.9541, -0.8561,  8.4856,  ..., -0.4493, -0.5303, -1.3592]],\n",
      "\n",
      "        [[-0.8630, -0.6126,  7.6388,  ..., -0.4273, -0.4799, -1.3841],\n",
      "         [-0.7724, -0.7788,  8.2944,  ..., -0.3772, -0.5244, -1.3282],\n",
      "         [-0.8277, -0.7933,  8.2698,  ..., -0.3389, -0.2728, -1.2364],\n",
      "         ...,\n",
      "         [-0.8589, -0.9902,  8.5089,  ..., -0.4480, -0.4593, -1.2973],\n",
      "         [-0.8565, -0.9847,  8.5263,  ..., -0.4052, -0.6221, -1.3512],\n",
      "         [-0.9461, -0.8224,  8.4594,  ..., -0.3511, -0.5064, -1.2857]],\n",
      "\n",
      "        [[-0.8208, -0.6321,  7.6755,  ..., -0.2244, -0.6481, -1.4578],\n",
      "         [-0.9480, -0.7235,  8.2057,  ..., -0.3140, -0.4212, -1.2247],\n",
      "         [-0.8241, -0.9512,  8.3808,  ..., -0.4148, -0.6899, -1.1651],\n",
      "         ...,\n",
      "         [-0.9530, -1.0089,  8.4692,  ..., -0.4278, -0.5862, -1.2489],\n",
      "         [-0.8927, -0.9223,  8.4024,  ..., -0.4597, -0.5381, -1.2952],\n",
      "         [-0.9734, -0.9115,  8.4870,  ..., -0.4065, -0.7115, -1.2519]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [   18,    32,    90,  ...,  3071,    23,   103],\n",
      "        [ 3165,    18,    29,  ...,     2, 20329,    77],\n",
      "        ...,\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0],\n",
      "        [    0,     0,     0,  ...,     0,     0,     0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n",
      "outs.tr tensor([[[-0.9384, -0.6422,  7.4560,  ..., -0.3177, -0.6019, -1.5821],\n",
      "         [-0.9055, -0.7426,  7.5809,  ..., -0.3006, -0.6425, -1.4742],\n",
      "         [-0.9346, -0.7331,  7.7067,  ..., -0.4901, -0.6573, -1.4298],\n",
      "         ...,\n",
      "         [-0.7277, -0.7673,  7.5618,  ..., -0.4352, -0.5138, -1.3892],\n",
      "         [-0.8630, -0.6126,  7.6388,  ..., -0.4273, -0.4799, -1.3841],\n",
      "         [-0.8208, -0.6321,  7.6755,  ..., -0.2244, -0.6481, -1.4578]],\n",
      "\n",
      "        [[-0.9086, -0.8306,  7.9956,  ..., -0.3950, -0.5257, -1.3291],\n",
      "         [-0.8091, -0.9680,  8.3867,  ..., -0.3715, -0.3371, -1.5240],\n",
      "         [-0.7365, -0.7158,  8.1937,  ..., -0.2815, -0.4100, -1.4083],\n",
      "         ...,\n",
      "         [-0.9715, -0.6993,  8.1827,  ..., -0.3181, -0.3823, -1.3645],\n",
      "         [-0.7724, -0.7788,  8.2944,  ..., -0.3772, -0.5244, -1.3282],\n",
      "         [-0.9480, -0.7235,  8.2057,  ..., -0.3140, -0.4212, -1.2247]],\n",
      "\n",
      "        [[-0.7866, -0.8418,  8.3591,  ..., -0.1474, -0.3537, -1.4434],\n",
      "         [-1.0467, -0.8638,  8.1783,  ..., -0.4050, -0.3204, -1.3048],\n",
      "         [-0.8588, -0.7637,  8.2964,  ..., -0.1561, -0.4750, -1.2201],\n",
      "         ...,\n",
      "         [-0.7006, -0.6596,  8.3094,  ..., -0.2384, -0.3423, -0.9984],\n",
      "         [-0.8277, -0.7933,  8.2698,  ..., -0.3389, -0.2728, -1.2364],\n",
      "         [-0.8241, -0.9512,  8.3808,  ..., -0.4148, -0.6899, -1.1651]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8710, -1.0219,  8.5683,  ..., -0.5666, -0.4820, -1.1829],\n",
      "         [-0.9688, -1.0913,  8.5355,  ..., -0.4019, -0.5155, -1.2224],\n",
      "         [-0.9230, -0.9786,  8.4371,  ..., -0.4507, -0.4948, -1.2917],\n",
      "         ...,\n",
      "         [-0.8706, -0.9366,  8.5106,  ..., -0.4876, -0.4918, -1.1990],\n",
      "         [-0.8589, -0.9902,  8.5089,  ..., -0.4480, -0.4593, -1.2973],\n",
      "         [-0.9530, -1.0089,  8.4692,  ..., -0.4278, -0.5862, -1.2489]],\n",
      "\n",
      "        [[-0.9697, -0.8754,  8.5294,  ..., -0.4429, -0.5747, -1.3424],\n",
      "         [-0.8928, -0.9818,  8.5891,  ..., -0.4143, -0.5154, -1.1654],\n",
      "         [-1.0768, -0.9155,  8.4954,  ..., -0.4214, -0.5151, -1.3682],\n",
      "         ...,\n",
      "         [-0.9518, -0.9029,  8.4482,  ..., -0.5116, -0.5564, -1.3067],\n",
      "         [-0.8565, -0.9847,  8.5263,  ..., -0.4052, -0.6221, -1.3512],\n",
      "         [-0.8927, -0.9223,  8.4024,  ..., -0.4597, -0.5381, -1.2952]],\n",
      "\n",
      "        [[-0.8612, -0.9675,  8.5129,  ..., -0.4256, -0.5920, -1.2718],\n",
      "         [-0.8474, -0.8421,  8.4839,  ..., -0.4072, -0.5158, -1.4427],\n",
      "         [-0.9021, -1.0069,  8.5345,  ..., -0.2885, -0.6597, -1.3358],\n",
      "         ...,\n",
      "         [-0.9541, -0.8561,  8.4856,  ..., -0.4493, -0.5303, -1.3592],\n",
      "         [-0.9461, -0.8224,  8.4594,  ..., -0.3511, -0.5064, -1.2857],\n",
      "         [-0.9734, -0.9115,  8.4870,  ..., -0.4065, -0.7115, -1.2519]]],\n",
      "       device='cuda:0', grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([7.6806, 9.8533, 9.8402,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',\n",
      "       grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(2.8339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n",
      "n_samples: 576\n",
      "-------Y: tensor([[   1,   48,    2,  ...,    0,    0,    0],\n",
      "        [   1, 1249,   10,  ...,   24, 1046,    2],\n",
      "        [   1,   63,    2,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,  841,    2,  ...,    0,    0,    0],\n",
      "        [   1, 5373,  956,  ...,    0,    0,    0],\n",
      "        [   1,   89,   62,  ...,    0,    0,    0]])\n",
      "Y[63]: tensor([ 1, 89, 62,  7,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0])\n",
      "-------T: tensor([[   1, 2501,   14,  ...,    0,    0,    0],\n",
      "        [   1,   73, 1627,  ...,    0,    0,    0],\n",
      "        [   1,  159, 1591,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,   24,  121,  ...,    0,    0,    0],\n",
      "        [   1,  362,    6,  ...,    0,    0,    0],\n",
      "        [   1,   85,    3,  ...,    0,    0,    0]])\n",
      "T[63]: tensor([    1,    85,     3,     4, 10888,    14,     4,    16,   265,     4,\n",
      "        11120,     6, 22664,     7,     4,    89,    62,     9,     7,     4,\n",
      "          685,   221,     4,   238,     4,    15,     2,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "Y size: torch.Size([64, 20])\n",
      "T size: torch.Size([64, 100])\n",
      "encode text: tensor([[[-0.0219, -1.7374, -0.3362,  ...,  1.2466, -1.8394,  0.8192],\n",
      "         [ 0.5709, -1.6601,  0.0120,  ...,  0.8629, -1.2315,  1.0613],\n",
      "         [ 0.8334, -1.5167, -0.0457,  ...,  1.1866, -2.0649,  0.9081],\n",
      "         ...,\n",
      "         [ 0.4941, -1.2046, -0.1786,  ...,  0.7432, -1.5951,  0.7788],\n",
      "         [ 0.1156, -1.0118,  0.0244,  ...,  0.6170, -1.5110,  1.1077],\n",
      "         [ 0.2400, -1.3455,  0.0228,  ...,  0.7685, -1.8133,  0.7358]],\n",
      "\n",
      "        [[ 0.1800, -1.6018, -0.3015,  ...,  1.1871, -1.9276,  0.8603],\n",
      "         [ 0.8854, -1.2431, -0.0890,  ...,  0.5696, -1.8359,  1.0709],\n",
      "         [ 0.4791, -1.6237, -0.1183,  ...,  0.7828, -1.8984,  0.4343],\n",
      "         ...,\n",
      "         [ 0.3950, -1.0968, -0.1293,  ...,  0.6869, -1.7208,  1.0795],\n",
      "         [ 0.4795, -1.1111, -0.1245,  ...,  0.6509, -1.7732,  1.1822],\n",
      "         [ 0.2543, -0.8330,  0.1993,  ...,  0.5129, -1.5486,  0.8750]],\n",
      "\n",
      "        [[ 0.0856, -1.8455, -0.0941,  ...,  0.9528, -2.0578,  0.5245],\n",
      "         [ 0.8749, -1.5594, -0.1122,  ...,  1.2735, -1.4482,  0.9746],\n",
      "         [ 0.5779, -1.3175, -0.2627,  ...,  0.7962, -1.8576,  1.1264],\n",
      "         ...,\n",
      "         [ 0.2824, -1.1622, -0.3080,  ...,  0.7904, -1.6947,  1.0242],\n",
      "         [ 0.5180, -1.1637,  0.0284,  ...,  0.7776, -1.7186,  0.7685],\n",
      "         [ 0.1886, -1.0735,  0.1010,  ...,  0.5733, -1.7816,  1.1421]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0089, -1.6671, -0.1877,  ...,  0.9185, -1.6522,  0.5730],\n",
      "         [ 0.2394, -1.7499,  0.0260,  ...,  0.6764, -2.0147,  1.0903],\n",
      "         [ 0.7195, -1.2389, -0.1405,  ...,  1.0582, -1.8130,  1.1025],\n",
      "         ...,\n",
      "         [ 0.3741, -1.1364, -0.1053,  ...,  0.6947, -1.8658,  0.9749],\n",
      "         [ 0.1355, -1.2167,  0.0455,  ...,  0.7277, -1.6564,  1.0087],\n",
      "         [ 0.1013, -0.6528,  0.1068,  ...,  0.6279, -1.8267,  0.9950]],\n",
      "\n",
      "        [[ 0.2169, -1.7312, -0.2368,  ...,  1.0896, -1.9432,  0.5537],\n",
      "         [ 0.6716, -1.5366, -0.3017,  ...,  1.1747, -1.6275,  0.7666],\n",
      "         [ 0.6000, -1.9752, -0.3599,  ...,  0.9688, -2.2011,  1.2379],\n",
      "         ...,\n",
      "         [ 0.3631, -1.0169, -0.1211,  ...,  0.5244, -1.9353,  1.0157],\n",
      "         [ 0.2537, -1.0452,  0.1923,  ...,  0.3433, -1.4350,  0.9875],\n",
      "         [ 0.0501, -0.9595,  0.1194,  ...,  0.5665, -1.7223,  0.9148]],\n",
      "\n",
      "        [[-0.0082, -1.7800, -0.2498,  ...,  1.3485, -1.9022,  0.8732],\n",
      "         [ 0.9160, -1.5596,  0.2050,  ...,  1.1462, -1.6496,  1.1370],\n",
      "         [ 0.4953, -1.4758, -0.1808,  ...,  0.8667, -1.6385,  0.9433],\n",
      "         ...,\n",
      "         [ 0.3992, -1.0072, -0.1637,  ...,  0.7792, -1.9187,  0.9852],\n",
      "         [ 0.2188, -0.9372, -0.0072,  ...,  0.6644, -1.8239,  1.1580],\n",
      "         [ 0.4679, -1.1345,  0.0703,  ...,  0.3443, -1.7397,  0.9656]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([64, 100, 512])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: tensor([[[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 0, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 0,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]], device='cuda:0', dtype=torch.uint8) torch.Size([64, 19, 19])\n",
      "64 19\n",
      "outs: tensor([[[-0.8931, -0.7773,  7.2543,  ..., -0.4958, -0.4551, -1.4068],\n",
      "         [-1.0853, -0.8830,  7.8044,  ..., -0.3927, -0.6299, -1.3918],\n",
      "         [-0.7316, -0.8204,  7.9643,  ..., -0.4804, -0.2738, -1.1519],\n",
      "         ...,\n",
      "         [-1.0355, -0.9900,  8.0702,  ..., -0.5221, -0.7322, -1.3824],\n",
      "         [-0.8787, -0.9386,  8.0790,  ..., -0.6100, -0.7047, -1.3700],\n",
      "         [-0.9447, -0.9683,  8.2078,  ..., -0.5800, -0.5460, -1.4197]],\n",
      "\n",
      "        [[-0.8749, -0.7995,  7.2219,  ..., -0.3320, -0.5444, -1.5007],\n",
      "         [-0.8750, -0.9264,  7.7966,  ..., -0.5494, -0.4543, -1.2443],\n",
      "         [-0.8438, -0.9152,  8.1775,  ..., -0.4914, -0.5142, -1.1485],\n",
      "         ...,\n",
      "         [-0.9889, -0.9511,  8.2221,  ..., -0.4143, -0.6264, -1.3585],\n",
      "         [-0.9059, -0.8019,  8.1129,  ..., -0.3737, -0.4543, -1.3618],\n",
      "         [-0.9864, -0.9797,  8.1717,  ..., -0.6359, -0.6680, -1.3214]],\n",
      "\n",
      "        [[-0.9381, -0.7343,  7.2425,  ..., -0.4544, -0.5226, -1.4300],\n",
      "         [-0.7635, -0.5561,  7.8924,  ..., -0.4370, -0.4083, -1.3161],\n",
      "         [-0.7598, -0.8230,  7.9342,  ..., -0.2975, -0.3703, -1.0870],\n",
      "         ...,\n",
      "         [-0.8841, -1.0422,  8.1676,  ..., -0.5406, -0.5266, -1.2307],\n",
      "         [-0.8641, -0.8998,  8.0826,  ..., -0.4642, -0.6861, -1.2274],\n",
      "         [-0.9760, -0.7697,  8.1599,  ..., -0.4195, -0.5017, -1.3072]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0006, -0.9175,  7.2307,  ..., -0.4601, -0.5911, -1.4409],\n",
      "         [-0.8960, -0.8800,  7.7789,  ..., -0.3356, -0.3760, -1.2783],\n",
      "         [-0.9219, -0.7837,  7.8331,  ..., -0.4097, -0.3629, -1.2403],\n",
      "         ...,\n",
      "         [-1.0328, -0.9977,  8.1876,  ..., -0.4884, -0.6738, -1.3234],\n",
      "         [-0.9536, -0.9974,  8.2595,  ..., -0.6168, -0.6013, -1.3472],\n",
      "         [-1.0497, -0.9122,  8.1824,  ..., -0.4736, -0.6754, -1.2466]],\n",
      "\n",
      "        [[-0.9386, -0.7292,  7.0127,  ..., -0.4016, -0.6447, -1.3433],\n",
      "         [-0.8718, -0.9200,  7.7685,  ..., -0.3947, -0.5590, -1.3164],\n",
      "         [-0.9950, -0.8583,  7.8267,  ..., -0.4204, -0.5869, -1.4647],\n",
      "         ...,\n",
      "         [-0.9784, -1.0149,  8.0725,  ..., -0.5083, -0.4891, -1.2627],\n",
      "         [-1.0690, -0.9491,  8.1504,  ..., -0.6083, -0.6797, -1.3914],\n",
      "         [-0.8892, -0.9882,  8.1393,  ..., -0.4175, -0.5661, -1.3385]],\n",
      "\n",
      "        [[-0.8267, -0.7722,  7.4113,  ..., -0.5445, -0.5577, -1.4709],\n",
      "         [-0.8612, -0.8055,  7.8152,  ..., -0.5684, -0.5099, -1.2689],\n",
      "         [-0.8754, -0.9259,  7.9211,  ..., -0.4175, -0.5481, -1.2784],\n",
      "         ...,\n",
      "         [-0.9258, -1.0142,  8.1417,  ..., -0.5889, -0.5588, -1.2865],\n",
      "         [-0.9911, -0.8711,  8.1980,  ..., -0.4923, -0.6436, -1.2393],\n",
      "         [-0.9444, -1.0552,  8.0526,  ..., -0.4443, -0.5245, -1.3029]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>) torch.Size([64, 19, 30005])\n",
      "Y.t() tensor([[   1,    1,    1,  ...,    1,    1,    1],\n",
      "        [  48, 1249,   63,  ...,  841, 5373,   89],\n",
      "        [   2,   10,    2,  ...,    2,  956,   62],\n",
      "        ...,\n",
      "        [   0,   24,    0,  ...,    0,    0,    0],\n",
      "        [   0, 1046,    0,  ...,    0,    0,    0],\n",
      "        [   0,    2,    0,  ...,    0,    0,    0]], device='cuda:0')\n",
      "torch.Size([20, 64])\n",
      "--------------------\n",
      "outs.tr tensor([[[-0.8931, -0.7773,  7.2543,  ..., -0.4958, -0.4551, -1.4068],\n",
      "         [-0.8749, -0.7995,  7.2219,  ..., -0.3320, -0.5444, -1.5007],\n",
      "         [-0.9381, -0.7343,  7.2425,  ..., -0.4544, -0.5226, -1.4300],\n",
      "         ...,\n",
      "         [-1.0006, -0.9175,  7.2307,  ..., -0.4601, -0.5911, -1.4409],\n",
      "         [-0.9386, -0.7292,  7.0127,  ..., -0.4016, -0.6447, -1.3433],\n",
      "         [-0.8267, -0.7722,  7.4113,  ..., -0.5445, -0.5577, -1.4709]],\n",
      "\n",
      "        [[-1.0853, -0.8830,  7.8044,  ..., -0.3927, -0.6299, -1.3918],\n",
      "         [-0.8750, -0.9264,  7.7966,  ..., -0.5494, -0.4543, -1.2443],\n",
      "         [-0.7635, -0.5561,  7.8924,  ..., -0.4370, -0.4083, -1.3161],\n",
      "         ...,\n",
      "         [-0.8960, -0.8800,  7.7789,  ..., -0.3356, -0.3760, -1.2783],\n",
      "         [-0.8718, -0.9200,  7.7685,  ..., -0.3947, -0.5590, -1.3164],\n",
      "         [-0.8612, -0.8055,  7.8152,  ..., -0.5684, -0.5099, -1.2689]],\n",
      "\n",
      "        [[-0.7316, -0.8204,  7.9643,  ..., -0.4804, -0.2738, -1.1519],\n",
      "         [-0.8438, -0.9152,  8.1775,  ..., -0.4914, -0.5142, -1.1485],\n",
      "         [-0.7598, -0.8230,  7.9342,  ..., -0.2975, -0.3703, -1.0870],\n",
      "         ...,\n",
      "         [-0.9219, -0.7837,  7.8331,  ..., -0.4097, -0.3629, -1.2403],\n",
      "         [-0.9950, -0.8583,  7.8267,  ..., -0.4204, -0.5869, -1.4647],\n",
      "         [-0.8754, -0.9259,  7.9211,  ..., -0.4175, -0.5481, -1.2784]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0355, -0.9900,  8.0702,  ..., -0.5221, -0.7322, -1.3824],\n",
      "         [-0.9889, -0.9511,  8.2221,  ..., -0.4143, -0.6264, -1.3585],\n",
      "         [-0.8841, -1.0422,  8.1676,  ..., -0.5406, -0.5266, -1.2307],\n",
      "         ...,\n",
      "         [-1.0328, -0.9977,  8.1876,  ..., -0.4884, -0.6738, -1.3234],\n",
      "         [-0.9784, -1.0149,  8.0725,  ..., -0.5083, -0.4891, -1.2627],\n",
      "         [-0.9258, -1.0142,  8.1417,  ..., -0.5889, -0.5588, -1.2865]],\n",
      "\n",
      "        [[-0.8787, -0.9386,  8.0790,  ..., -0.6100, -0.7047, -1.3700],\n",
      "         [-0.9059, -0.8019,  8.1129,  ..., -0.3737, -0.4543, -1.3618],\n",
      "         [-0.8641, -0.8998,  8.0826,  ..., -0.4642, -0.6861, -1.2274],\n",
      "         ...,\n",
      "         [-0.9536, -0.9974,  8.2595,  ..., -0.6168, -0.6013, -1.3472],\n",
      "         [-1.0690, -0.9491,  8.1504,  ..., -0.6083, -0.6797, -1.3914],\n",
      "         [-0.9911, -0.8711,  8.1980,  ..., -0.4923, -0.6436, -1.2393]],\n",
      "\n",
      "        [[-0.9447, -0.9683,  8.2078,  ..., -0.5800, -0.5460, -1.4197],\n",
      "         [-0.9864, -0.9797,  8.1717,  ..., -0.6359, -0.6680, -1.3214],\n",
      "         [-0.9760, -0.7697,  8.1599,  ..., -0.4195, -0.5017, -1.3072],\n",
      "         ...,\n",
      "         [-1.0497, -0.9122,  8.1824,  ..., -0.4736, -0.6754, -1.2466],\n",
      "         [-0.8892, -0.9882,  8.1393,  ..., -0.4175, -0.5661, -1.3385],\n",
      "         [-0.9444, -1.0552,  8.0526,  ..., -0.4443, -0.5245, -1.3029]]],\n",
      "       device='cuda:0', grad_fn=<TransposeBackward0>)\n",
      "torch.Size([19, 64, 30005])\n",
      "--------------------\n",
      "OSIZE: torch.Size([1216, 30005])\n",
      "YSIZE: torch.Size([1216])\n",
      "Loss: tensor([8.9812, 9.5418, 9.6881,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0',\n",
      "       grad_fn=<NllLossBackward>) torch.Size([1216])\n",
      "-----loss: tensor(2.1807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "******************************\n",
      "n_samples: 640\n"
     ]
    }
   ],
   "source": [
    "# args = set_parser()\n",
    "args = Args(\"train\")\n",
    "config = Config(args, data_path=\"../data\")\n",
    "\n",
    "print(\"mode:\", args.mode)\n",
    "\n",
    "if args.mode == 'train':\n",
    "    train(config)\n",
    "else:\n",
    "    test_set = get_dataset(config.test_path, config.w2i_vocabs, config, is_train=False)\n",
    "    model = Model(n_emb=args.n_emb, n_hidden=args.n_hidden, vocab_size=args.vocab_size,\n",
    "              dropout=args.dropout, d_ff=args.d_ff, n_head=args.n_head, n_block=args.n_block)\n",
    "    model_dict = torch.load(args.restore)\n",
    "    model.load_state_dict(model_dict)\n",
    "    model.to(device)\n",
    "    test(test_set, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Y 是真是值在训练和测试的时候都只有一句话；\n",
    "- T 是上下文评论，训练4-8句话；测试只有4句话？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode: test\n",
      "starting load...\n",
      "loading time: 0.14416289329528809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda2/envs/pt-tf-env/lib/python3.6/site-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting testing...\n",
      "-------Y: tensor([[   1,  238,    2,  ...,    0,    0,    0],\n",
      "        [   1,  260,    2,  ...,    0,    0,    0],\n",
      "        [   1,  351,    2,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [   1,   72, 2685,  ...,    0,    0,    0],\n",
      "        [   1, 2509,  102,  ...,    0,    0,    0],\n",
      "        [   1,    3,   13,  ...,    0,    0,    0]])\n",
      "Y[10]: tensor([    1, 22693,   175, 19758, 12896, 12291,   175,   807,     3,  3143,\n",
      "            2,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
      "-------T: tensor([   1, 2743,  137, 1152,    6,    9,  126,  703,    8,    4,  137,    4,\n",
      "        2310,  489, 5968,    4,    3,    2,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0])\n",
      "T[10]: tensor(137)\n",
      "data: {'candidate': {'2333': 2, '23333': 2, '233333': 2, '666': 2, '6666': 2, '66666': 2, '666666': 2, '888888888': 3, 'FFF': 3, 'bgm 走心 小 卖家 尊重 一下 个人 喜欢 说唱': 3, 'naruto - ナ ル ト - の 登場 人物': 1, 'up 主 心机 boy ， 故意 不 给 字幕 ？': 3, 'ylzh': 3, '▇': 1, '一般 吧 ， 长 的 也 就 那样': 3, '一陀猫': 3, '七年级 下车 第二十八 课 ， 河 中 石兽 预备 起 ！': 3, '不管 什么 族 的 ， 都 是 我们 国 的': 3, '为什么 让 我 想起 了 泰哥 。 。 。 。': 3, '为什么 ， 只有 我 喜欢 番茄 味 吗 。': 3, '人家 怎么 了 吃 的 都 是 正常 东西 啊 凭 什么 被 你 拿 出来 婊': 3, '从前 那个 一碗 泡面 也 吃不完 的 小丸子 呢': 3, '他 是 谁 呀 。': 3, '你 不是 样 一个 人 : D': 3, '你们 可以 想象 下 西瓜 冰箱 放久 了 的 味道': 3, '俄语 真心 难 … …': 3, '前方 高能': 2, '十级 什么 鬼 A 叔 英皇 演奏 级': 3, '卧槽': 2, '口音 贼': 3, '只要 三 三': 3, '可丽饼 不是 可乐 饼': 3, '可以 试试 用 马桶 腌制 ， 味道 更加 浓厚 美味': 3, '哈哈哈': 2, '哈哈哈 哈哈': 2, '哈哈哈 哈哈哈': 2, '哈哈哈 ， 我 16 都 178 了': 3, '哈哈哈哈': 2, '哈哈哈哈 哈哈哈': 2, '啊 买 噶': 3, '因为 你们 台湾人 不 炒房': 3, '在 现场': 2, '坏小子 演技 不错': 3, '太极 八卦 连环 掌': 3, '好听': 2, '好好看 的 手 ！ ！': 3, '妈 了 烫': 3, '对不起 ， 我要 左下角 的 小熊': 3, '封面 giao 哥': 3, '小孩 也 是 醉 了 ， 我 的话 干脆 下车': 3, '居 老师 如果 你 看到 我 请 记住 我 爱 您 ！': 3, '山东 口音 都 出来 啦 23333': 3, '庄周 ， 你 的 鲲': 3, '库科奇 ， 是 谁 ？': 3, '底子 蛮 好 啊': 3, '当然 喜欢 吃鸣 人 啦': 3, '很 像 千玺 w': 3, '怪不得 女人 ， 记性 好 ！ 😁': 3, '我 就 喜欢 看 弹幕': 3, '我 的 外号 叫二牛 。 。 。': 3, '我们 可 曾 为了 感受 到 你 的 恨意 而 远行': 1, '我们 曾 为了 感受 到 你 的 恨 而 远行': 1, '我薇': 3, '暂停 看 就 暂停 看别 挡 ok ?': 3, '桥头 排骨 是 香': 3, '没 弹幕 ！': 3, '没 毛病 ， 勇太六花 的 ， ， ，': 3, '泪目': 2, '洗 干净 ， 直接 煲汤': 3, '浪费 了': 3, '火钳 刘明': 2, '爆头 讲究': 3, '猪蹄 吧 猪 爪': 3, '玩完 儿真 丢人': 3, '生日快乐': 2, '白丝 JK 川川子 是 我 的 ！': 3, '看 他 比划 感觉 在 奇酷 比 那里 就 长度 合适 了': 3, '看 的 我 痔疮 疼': 3, '真的 别 在 歌 房里 吃 东西 啊 人家 以后 进来 唱歌 的 闻 着 一股 味': 3, '真香': 2, '石花 汤 是 甜 的 啊 ， 完全 不 一样 好 嘛': 3, '绝壁 毛子': 3, '美美 美 !': 3, '老 香洲 ？': 3, '胸让 我 来 握': 3, '虾 之 大': 3, '表白 万万': 3, '袁国': 3, '詹皇 需要 怀疑 ？': 3, '走 好 ， 主子': 3, '赵本山 二胡 ， 葫芦丝 ， 三弦 ， 都 厉害': 3, '这 不是 康康舞': 3, '这 是 硬 拉 不是 举重 ... 别 这么 无知 好 嘛': 3, '这个 笑声 哈哈哈': 3, '这么 大 … …': 3, '这是 博人传 65 集': 3, '这是 库里 之前 用 的 么': 3, '这是 替身 植物 !': 3, '这猫 太 喜欢 咬人 了 要 我 就 直接 打': 3, '高伊恒 你 看看': 3}, 'comment': ['我们 曾 为了 感受 到 你 的 恨 而 远行', '▇', '▇', 'naruto - ナ ル ト - の 登場 人物', '我们 可 曾 为了 感受 到 你 的 恨意 而 远行'], 'context': '背负着 火影 之名 ， 我 不能 输 ！ <&&&> 火影 <&&&> 飞雷 神 二段 <&&&> Didwegetthisfarjusttofeelyourhate', 'time': 200, 'video': 470}\n",
      "****************************************\n",
      "ids: tensor([78, 20, 76, 16, 61, 80, 32, 92, 10, 24, 57, 60, 90, 11, 49, 98, 21, 50,\n",
      "         9, 63, 19, 27, 23, 17, 31, 36, 51, 96, 14, 97, 72, 47, 75, 64, 68, 52,\n",
      "        46, 53, 40, 73, 43, 56, 88, 66, 55, 18, 25, 86, 59, 91, 81, 89, 22, 45,\n",
      "        84, 71, 77, 30, 54, 42, 58, 93, 82, 39,  8, 29, 48, 13, 94, 83, 65, 95,\n",
      "        69, 99, 85, 79, 35,  1, 38, 34,  0, 74,  2, 37, 44, 33, 70,  4, 26,  6,\n",
      "         5, 28,  3, 67, 41, 12, 62, 15,  7, 87], device='cuda:0')\n",
      "ids size torch.Size([100])\n",
      "comments: ['2333', '23333', '233333', '666', '6666', '66666', '666666', '888888888', 'FFF', 'bgm 走心 小 卖家 尊重 一下 个人 喜欢 说唱', 'naruto - ナ ル ト - の 登場 人物', 'up 主 心机 boy ， 故意 不 给 字幕 ？', 'ylzh', '▇', '一般 吧 ， 长 的 也 就 那样', '一陀猫', '七年级 下车 第二十八 课 ， 河 中 石兽 预备 起 ！', '不管 什么 族 的 ， 都 是 我们 国 的', '为什么 让 我 想起 了 泰哥 。 。 。 。', '为什么 ， 只有 我 喜欢 番茄 味 吗 。', '人家 怎么 了 吃 的 都 是 正常 东西 啊 凭 什么 被 你 拿 出来 婊', '从前 那个 一碗 泡面 也 吃不完 的 小丸子 呢', '他 是 谁 呀 。', '你 不是 样 一个 人 : D', '你们 可以 想象 下 西瓜 冰箱 放久 了 的 味道', '俄语 真心 难 … …', '前方 高能', '十级 什么 鬼 A 叔 英皇 演奏 级', '卧槽', '口音 贼', '只要 三 三', '可丽饼 不是 可乐 饼', '可以 试试 用 马桶 腌制 ， 味道 更加 浓厚 美味', '哈哈哈', '哈哈哈 哈哈', '哈哈哈 哈哈哈', '哈哈哈 ， 我 16 都 178 了', '哈哈哈哈', '哈哈哈哈 哈哈哈', '啊 买 噶', '因为 你们 台湾人 不 炒房', '在 现场', '坏小子 演技 不错', '太极 八卦 连环 掌', '好听', '好好看 的 手 ！ ！', '妈 了 烫', '对不起 ， 我要 左下角 的 小熊', '封面 giao 哥', '小孩 也 是 醉 了 ， 我 的话 干脆 下车', '居 老师 如果 你 看到 我 请 记住 我 爱 您 ！', '山东 口音 都 出来 啦 23333', '庄周 ， 你 的 鲲', '库科奇 ， 是 谁 ？', '底子 蛮 好 啊', '当然 喜欢 吃鸣 人 啦', '很 像 千玺 w', '怪不得 女人 ， 记性 好 ！ 😁', '我 就 喜欢 看 弹幕', '我 的 外号 叫二牛 。 。 。', '我们 可 曾 为了 感受 到 你 的 恨意 而 远行', '我们 曾 为了 感受 到 你 的 恨 而 远行', '我薇', '暂停 看 就 暂停 看别 挡 ok ?', '桥头 排骨 是 香', '没 弹幕 ！', '没 毛病 ， 勇太六花 的 ， ， ，', '泪目', '洗 干净 ， 直接 煲汤', '浪费 了', '火钳 刘明', '爆头 讲究', '猪蹄 吧 猪 爪', '玩完 儿真 丢人', '生日快乐', '白丝 JK 川川子 是 我 的 ！', '看 他 比划 感觉 在 奇酷 比 那里 就 长度 合适 了', '看 的 我 痔疮 疼', '真的 别 在 歌 房里 吃 东西 啊 人家 以后 进来 唱歌 的 闻 着 一股 味', '真香', '石花 汤 是 甜 的 啊 ， 完全 不 一样 好 嘛', '绝壁 毛子', '美美 美 !', '老 香洲 ？', '胸让 我 来 握', '虾 之 大', '表白 万万', '袁国', '詹皇 需要 怀疑 ？', '走 好 ， 主子', '赵本山 二胡 ， 葫芦丝 ， 三弦 ， 都 厉害', '这 不是 康康舞', '这 是 硬 拉 不是 举重 ... 别 这么 无知 好 嘛', '这个 笑声 哈哈哈', '这么 大 … …', '这是 博人传 65 集', '这是 库里 之前 用 的 么', '这是 替身 植物 !', '这猫 太 喜欢 咬人 了 要 我 就 直接 打', '高伊恒 你 看看']\n",
      "comments[id]: 真的 别 在 歌 房里 吃 东西 啊 人家 以后 进来 唱歌 的 闻 着 一股 味\n",
      "comments[id]: 人家 怎么 了 吃 的 都 是 正常 东西 啊 凭 什么 被 你 拿 出来 婊\n",
      "comments[id]: 看 他 比划 感觉 在 奇酷 比 那里 就 长度 合适 了\n",
      "comments[id]: 七年级 下车 第二十八 课 ， 河 中 石兽 预备 起 ！\n",
      "comments[id]: 我们 曾 为了 感受 到 你 的 恨 而 远行\n",
      "comments[id]: 石花 汤 是 甜 的 啊 ， 完全 不 一样 好 嘛\n",
      "comments[id]: 可以 试试 用 马桶 腌制 ， 味道 更加 浓厚 美味\n",
      "comments[id]: 这 是 硬 拉 不是 举重 ... 别 这么 无知 好 嘛\n",
      "comments[id]: naruto - ナ ル ト - の 登場 人物\n",
      "comments[id]: 你们 可以 想象 下 西瓜 冰箱 放久 了 的 味道\n",
      "comments[id]: 怪不得 女人 ， 记性 好 ！ 😁\n",
      "comments[id]: 我们 可 曾 为了 感受 到 你 的 恨意 而 远行\n",
      "comments[id]: 赵本山 二胡 ， 葫芦丝 ， 三弦 ， 都 厉害\n",
      "comments[id]: up 主 心机 boy ， 故意 不 给 字幕 ？\n",
      "comments[id]: 小孩 也 是 醉 了 ， 我 的话 干脆 下车\n",
      "comments[id]: 这猫 太 喜欢 咬人 了 要 我 就 直接 打\n",
      "comments[id]: 从前 那个 一碗 泡面 也 吃不完 的 小丸子 呢\n",
      "comments[id]: 居 老师 如果 你 看到 我 请 记住 我 爱 您 ！\n",
      "comments[id]: bgm 走心 小 卖家 尊重 一下 个人 喜欢 说唱\n",
      "comments[id]: 暂停 看 就 暂停 看别 挡 ok ?\n",
      "comments[id]: 为什么 ， 只有 我 喜欢 番茄 味 吗 。\n",
      "comments[id]: 十级 什么 鬼 A 叔 英皇 演奏 级\n",
      "comments[id]: 你 不是 样 一个 人 : D\n",
      "comments[id]: 不管 什么 族 的 ， 都 是 我们 国 的\n",
      "comments[id]: 可丽饼 不是 可乐 饼\n",
      "comments[id]: 哈哈哈 ， 我 16 都 178 了\n",
      "comments[id]: 山东 口音 都 出来 啦 23333\n",
      "comments[id]: 这是 库里 之前 用 的 么\n",
      "comments[id]: 一般 吧 ， 长 的 也 就 那样\n",
      "comments[id]: 这是 替身 植物 !\n",
      "comments[id]: 猪蹄 吧 猪 爪\n",
      "comments[id]: 对不起 ， 我要 左下角 的 小熊\n",
      "comments[id]: 白丝 JK 川川子 是 我 的 ！\n",
      "comments[id]: 桥头 排骨 是 香\n",
      "comments[id]: 洗 干净 ， 直接 煲汤\n",
      "comments[id]: 庄周 ， 你 的 鲲\n",
      "comments[id]: 妈 了 烫\n",
      "comments[id]: 库科奇 ， 是 谁 ？\n",
      "comments[id]: 因为 你们 台湾人 不 炒房\n",
      "comments[id]: 玩完 儿真 丢人\n",
      "comments[id]: 太极 八卦 连环 掌\n",
      "comments[id]: 很 像 千玺 w\n",
      "comments[id]: 詹皇 需要 怀疑 ？\n",
      "comments[id]: 没 毛病 ， 勇太六花 的 ， ， ，\n",
      "comments[id]: 当然 喜欢 吃鸣 人 啦\n",
      "comments[id]: 为什么 让 我 想起 了 泰哥 。 。 。 。\n",
      "comments[id]: 俄语 真心 难 … …\n",
      "comments[id]: 表白 万万\n",
      "comments[id]: 我 的 外号 叫二牛 。 。 。\n",
      "comments[id]: 这 不是 康康舞\n",
      "comments[id]: 绝壁 毛子\n",
      "comments[id]: 走 好 ， 主子\n",
      "comments[id]: 他 是 谁 呀 。\n",
      "comments[id]: 好好看 的 手 ！ ！\n",
      "comments[id]: 胸让 我 来 握\n",
      "comments[id]: 爆头 讲究\n",
      "comments[id]: 看 的 我 痔疮 疼\n",
      "comments[id]: 只要 三 三\n",
      "comments[id]: 底子 蛮 好 啊\n",
      "comments[id]: 坏小子 演技 不错\n",
      "comments[id]: 我 就 喜欢 看 弹幕\n",
      "comments[id]: 这个 笑声 哈哈哈\n",
      "comments[id]: 美美 美 !\n",
      "comments[id]: 啊 买 噶\n",
      "comments[id]: FFF\n",
      "comments[id]: 口音 贼\n",
      "comments[id]: 封面 giao 哥\n",
      "comments[id]: ▇\n",
      "comments[id]: 这么 大 … …\n",
      "comments[id]: 老 香洲 ？\n",
      "comments[id]: 没 弹幕 ！\n",
      "comments[id]: 这是 博人传 65 集\n",
      "comments[id]: 浪费 了\n",
      "comments[id]: 高伊恒 你 看看\n",
      "comments[id]: 虾 之 大\n",
      "comments[id]: 真香\n",
      "comments[id]: 哈哈哈 哈哈哈\n",
      "comments[id]: 23333\n",
      "comments[id]: 哈哈哈哈 哈哈哈\n",
      "comments[id]: 哈哈哈 哈哈\n",
      "comments[id]: 2333\n",
      "comments[id]: 生日快乐\n",
      "comments[id]: 233333\n",
      "comments[id]: 哈哈哈哈\n",
      "comments[id]: 好听\n",
      "comments[id]: 哈哈哈\n",
      "comments[id]: 火钳 刘明\n",
      "comments[id]: 6666\n",
      "comments[id]: 前方 高能\n",
      "comments[id]: 666666\n",
      "comments[id]: 66666\n",
      "comments[id]: 卧槽\n",
      "comments[id]: 666\n",
      "comments[id]: 泪目\n",
      "comments[id]: 在 现场\n",
      "comments[id]: ylzh\n",
      "comments[id]: 我薇\n",
      "comments[id]: 一陀猫\n",
      "comments[id]: 888888888\n",
      "comments[id]: 袁国\n",
      "prediction candidate: ['真的 别 在 歌 房里 吃 东西 啊 人家 以后 进来 唱歌 的 闻 着 一股 味', '人家 怎么 了 吃 的 都 是 正常 东西 啊 凭 什么 被 你 拿 出来 婊', '看 他 比划 感觉 在 奇酷 比 那里 就 长度 合适 了', '七年级 下车 第二十八 课 ， 河 中 石兽 预备 起 ！', '我们 曾 为了 感受 到 你 的 恨 而 远行', '石花 汤 是 甜 的 啊 ， 完全 不 一样 好 嘛', '可以 试试 用 马桶 腌制 ， 味道 更加 浓厚 美味', '这 是 硬 拉 不是 举重 ... 别 这么 无知 好 嘛', 'naruto - ナ ル ト - の 登場 人物', '你们 可以 想象 下 西瓜 冰箱 放久 了 的 味道', '怪不得 女人 ， 记性 好 ！ 😁', '我们 可 曾 为了 感受 到 你 的 恨意 而 远行', '赵本山 二胡 ， 葫芦丝 ， 三弦 ， 都 厉害', 'up 主 心机 boy ， 故意 不 给 字幕 ？', '小孩 也 是 醉 了 ， 我 的话 干脆 下车', '这猫 太 喜欢 咬人 了 要 我 就 直接 打', '从前 那个 一碗 泡面 也 吃不完 的 小丸子 呢', '居 老师 如果 你 看到 我 请 记住 我 爱 您 ！', 'bgm 走心 小 卖家 尊重 一下 个人 喜欢 说唱', '暂停 看 就 暂停 看别 挡 ok ?', '为什么 ， 只有 我 喜欢 番茄 味 吗 。', '十级 什么 鬼 A 叔 英皇 演奏 级', '你 不是 样 一个 人 : D', '不管 什么 族 的 ， 都 是 我们 国 的', '可丽饼 不是 可乐 饼', '哈哈哈 ， 我 16 都 178 了', '山东 口音 都 出来 啦 23333', '这是 库里 之前 用 的 么', '一般 吧 ， 长 的 也 就 那样', '这是 替身 植物 !', '猪蹄 吧 猪 爪', '对不起 ， 我要 左下角 的 小熊', '白丝 JK 川川子 是 我 的 ！', '桥头 排骨 是 香', '洗 干净 ， 直接 煲汤', '庄周 ， 你 的 鲲', '妈 了 烫', '库科奇 ， 是 谁 ？', '因为 你们 台湾人 不 炒房', '玩完 儿真 丢人', '太极 八卦 连环 掌', '很 像 千玺 w', '詹皇 需要 怀疑 ？', '没 毛病 ， 勇太六花 的 ， ， ，', '当然 喜欢 吃鸣 人 啦', '为什么 让 我 想起 了 泰哥 。 。 。 。', '俄语 真心 难 … …', '表白 万万', '我 的 外号 叫二牛 。 。 。', '这 不是 康康舞', '绝壁 毛子', '走 好 ， 主子', '他 是 谁 呀 。', '好好看 的 手 ！ ！', '胸让 我 来 握', '爆头 讲究', '看 的 我 痔疮 疼', '只要 三 三', '底子 蛮 好 啊', '坏小子 演技 不错', '我 就 喜欢 看 弹幕', '这个 笑声 哈哈哈', '美美 美 !', '啊 买 噶', 'FFF', '口音 贼', '封面 giao 哥', '▇', '这么 大 … …', '老 香洲 ？', '没 弹幕 ！', '这是 博人传 65 集', '浪费 了', '高伊恒 你 看看', '虾 之 大', '真香', '哈哈哈 哈哈哈', '23333', '哈哈哈哈 哈哈哈', '哈哈哈 哈哈', '2333', '生日快乐', '233333', '哈哈哈哈', '好听', '哈哈哈', '火钳 刘明', '6666', '前方 高能', '666666', '66666', '卧槽', '666', '泪目', '在 现场', 'ylzh', '我薇', '一陀猫', '888888888', '袁国']\n",
      "data candidate: {'2333': 2, '23333': 2, '233333': 2, '666': 2, '6666': 2, '66666': 2, '666666': 2, '888888888': 3, 'FFF': 3, 'bgm 走心 小 卖家 尊重 一下 个人 喜欢 说唱': 3, 'naruto - ナ ル ト - の 登場 人物': 1, 'up 主 心机 boy ， 故意 不 给 字幕 ？': 3, 'ylzh': 3, '▇': 1, '一般 吧 ， 长 的 也 就 那样': 3, '一陀猫': 3, '七年级 下车 第二十八 课 ， 河 中 石兽 预备 起 ！': 3, '不管 什么 族 的 ， 都 是 我们 国 的': 3, '为什么 让 我 想起 了 泰哥 。 。 。 。': 3, '为什么 ， 只有 我 喜欢 番茄 味 吗 。': 3, '人家 怎么 了 吃 的 都 是 正常 东西 啊 凭 什么 被 你 拿 出来 婊': 3, '从前 那个 一碗 泡面 也 吃不完 的 小丸子 呢': 3, '他 是 谁 呀 。': 3, '你 不是 样 一个 人 : D': 3, '你们 可以 想象 下 西瓜 冰箱 放久 了 的 味道': 3, '俄语 真心 难 … …': 3, '前方 高能': 2, '十级 什么 鬼 A 叔 英皇 演奏 级': 3, '卧槽': 2, '口音 贼': 3, '只要 三 三': 3, '可丽饼 不是 可乐 饼': 3, '可以 试试 用 马桶 腌制 ， 味道 更加 浓厚 美味': 3, '哈哈哈': 2, '哈哈哈 哈哈': 2, '哈哈哈 哈哈哈': 2, '哈哈哈 ， 我 16 都 178 了': 3, '哈哈哈哈': 2, '哈哈哈哈 哈哈哈': 2, '啊 买 噶': 3, '因为 你们 台湾人 不 炒房': 3, '在 现场': 2, '坏小子 演技 不错': 3, '太极 八卦 连环 掌': 3, '好听': 2, '好好看 的 手 ！ ！': 3, '妈 了 烫': 3, '对不起 ， 我要 左下角 的 小熊': 3, '封面 giao 哥': 3, '小孩 也 是 醉 了 ， 我 的话 干脆 下车': 3, '居 老师 如果 你 看到 我 请 记住 我 爱 您 ！': 3, '山东 口音 都 出来 啦 23333': 3, '庄周 ， 你 的 鲲': 3, '库科奇 ， 是 谁 ？': 3, '底子 蛮 好 啊': 3, '当然 喜欢 吃鸣 人 啦': 3, '很 像 千玺 w': 3, '怪不得 女人 ， 记性 好 ！ 😁': 3, '我 就 喜欢 看 弹幕': 3, '我 的 外号 叫二牛 。 。 。': 3, '我们 可 曾 为了 感受 到 你 的 恨意 而 远行': 1, '我们 曾 为了 感受 到 你 的 恨 而 远行': 1, '我薇': 3, '暂停 看 就 暂停 看别 挡 ok ?': 3, '桥头 排骨 是 香': 3, '没 弹幕 ！': 3, '没 毛病 ， 勇太六花 的 ， ， ，': 3, '泪目': 2, '洗 干净 ， 直接 煲汤': 3, '浪费 了': 3, '火钳 刘明': 2, '爆头 讲究': 3, '猪蹄 吧 猪 爪': 3, '玩完 儿真 丢人': 3, '生日快乐': 2, '白丝 JK 川川子 是 我 的 ！': 3, '看 他 比划 感觉 在 奇酷 比 那里 就 长度 合适 了': 3, '看 的 我 痔疮 疼': 3, '真的 别 在 歌 房里 吃 东西 啊 人家 以后 进来 唱歌 的 闻 着 一股 味': 3, '真香': 2, '石花 汤 是 甜 的 啊 ， 完全 不 一样 好 嘛': 3, '绝壁 毛子': 3, '美美 美 !': 3, '老 香洲 ？': 3, '胸让 我 来 握': 3, '虾 之 大': 3, '表白 万万': 3, '袁国': 3, '詹皇 需要 怀疑 ？': 3, '走 好 ， 主子': 3, '赵本山 二胡 ， 葫芦丝 ， 三弦 ， 都 厉害': 3, '这 不是 康康舞': 3, '这 是 硬 拉 不是 举重 ... 别 这么 无知 好 嘛': 3, '这个 笑声 哈哈哈': 3, '这么 大 … …': 3, '这是 博人传 65 集': 3, '这是 库里 之前 用 的 么': 3, '这是 替身 植物 !': 3, '这猫 太 喜欢 咬人 了 要 我 就 直接 打': 3, '高伊恒 你 看看': 3}\n",
      "r1=0.0, r5=100.0, r10=100.0, mr=5.0, mrr=0.2\n",
      "testing time: 0.05911993980407715\n"
     ]
    }
   ],
   "source": [
    "# args = set_parser()\n",
    "args = Args(\"test\")\n",
    "args.restore = \"../ckpt/best_checkpoint.pt\"\n",
    "config = Config(args, data_path=\"../data\")\n",
    "\n",
    "print(\"mode:\", args.mode)\n",
    "\n",
    "if args.mode == 'train':\n",
    "    train(config)\n",
    "else:\n",
    "    test_set = get_dataset(config.test_path, config.w2i_vocabs, config, is_train=False)\n",
    "    model = Model(n_emb=args.n_emb, n_hidden=args.n_hidden, vocab_size=args.vocab_size,\n",
    "              dropout=args.dropout, d_ff=args.d_ff, n_head=args.n_head, n_block=args.n_block)\n",
    "    model_dict = torch.load(args.restore)\n",
    "    model.load_state_dict(model_dict)\n",
    "    model.to(device)\n",
    "    test(test_set, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
